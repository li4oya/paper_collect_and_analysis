[
    {
        "title": "Zero-Knowledge Proofs of Training for Deep Neural Networks",
        "authors": "Abbaszadeh, Kasra; Pappas, Christodoulos; Katz, Jonathan; Papadopoulos, Dimitrios",
        "keywords": "Zero-Knowledge Proof (零知识证明) - 用于验证知识而不泄露信息\nDeep Neural Networks (深度神经网络) - 多层结构模型实现复杂模式识别\nGradient Descent Algorithm (梯度下降算法) - 优化模型参数的核心方法\n选定的主题标签名称",
        "abstract": "A zero-knowledge proof of training (zkPoT) enables a party to prove that they have correctly trained a committed model based on a committed dataset without revealing any additional information about the model or the dataset. An ideal zkPoT should offer provable security and privacy guarantees, succinct proof size and verifier runtime, and practical prover efficiency. In this work, we present Kaizen, a zkPoT targeted for deep neural networks (DNNs) that achieves all these goals at once. Our construction enables a prover to iteratively train their model via (mini-batch) gradient descent, where the number of iterations need not be fixed in advance; at the end of each iteration, the prover generates a commitment to the trained model parameters attached with a succinct zkPoT, attesting to the correctness of the executed iterations. The proof size and verifier time are independent of the number of iterations.Our construction relies on two building blocks. First, we propose an optimized GKR-style (sumcheck-based) proof system for the gradient-descent algorithm with concretely efficient prover cost; this allows the prover to generate a proof for each iteration. We then show how to recursively compose these proofs across multiple iterations to attain succinctness. As of independent interest, we propose a generic framework for efficient recursive composition of GKR-style proofs, along with aggregatable polynomial commitments.Benchmarks indicate that Kaizen can handle the training of complex models such as VGG-11 with 10 million parameters and batch size 16. The prover runtime is 15 minutes per iteration, which is 24x faster than generic recursive proofs, with prover memory overhead 27x lower. The proof size is 1.63 megabytes, and the verifier runtime is only 130 milliseconds, where both are independent of the number of iterations and the size of the dataset.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670316",
        "pub_year": "2024",
        "theme_label": "密码学及应用"
    },
    {
        "title": "Jager: Automated Telephone Call Traceback",
        "authors": "Adei, David; Madathil, Varun; Prasad, Sathvik; Reaves, Bradley; Scafuro, Alessandra",
        "keywords": "Call Traceback (电话追踪) - 快速定位电话滥用源头\nPrivacy Preservation (隐私保护) - 加密保障通话隐私安全\nWitness Encryption (见证加密) - 利用密码实现安全追溯",
        "abstract": "Unsolicited telephone calls that facilitate fraud or unlawful telemarketing continue to overwhelm network users and the regulators who prosecute them. The first step in prosecuting phone abuse is traceback - identifying the call originator. This fundamental investigative task currently requires hours of manual effort per call. In this paper, we introduce Jager, a distributed secure call traceback system. Jager can trace a call in a few seconds, even with partial deployment, while cryptographically preserving the privacy of call parties, carrier trade secrets like peers and call volume, and limiting the threat of bulk analysis. We establish definitions and requirements of secure traceback, then develop a suite of protocols that meet these requirements using witness encryption, oblivious pseudorandom functions, and group signatures. We prove these protocols secure in the universal composibility framework. We then demonstrate that Jager has low compute and bandwidth costs per call, and these costs scale linearly with call volume. Jager provides an efficient, secure, privacy-preserving system to revolutionize telephone abuse investigation with minimal costs to operators.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690290",
        "pub_year": "2024",
        "theme_label": "网络与系统安全"
    },
    {
        "title": "Evaluations of Machine Learning Privacy Defenses are Misleading",
        "authors": "Aerni, Michael; Zhang, Jie; Tramer, Florian",
        "keywords": "Machine Learning Privacy (机器学习隐私) - 保护数据隐私的机器学习方法\nMembership Inference Attacks (成员推理攻击) - 推断数据是否参与模型训练\nDifferential Privacy (差分隐私) - 提供严格隐私保障的数学框架\n选定的主题标签名称",
        "abstract": "Empirical defenses for machine learning privacy forgo the provable guarantees of differential privacy in the hope of achieving higher utility while resisting realistic adversaries. We identify severe pitfalls in existing empirical privacy evaluations (based on membership inference attacks) that result in misleading conclusions. In particular, we show that prior evaluations fail to characterize the privacy leakage of the most vulnerable samples, use weak attacks, and avoid comparisons with practical differential privacy baselines. In 5 case studies of empirical privacy defenses, we find that prior evaluations underestimate privacy leakage by an order of magnitude. Under our stronger evaluation, none of the empirical defenses we study are competitive with a properly tuned, high-utility DPSGD baseline (with vacuous provable guarantees).",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690194",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Secure Sorting and Selection via Function Secret Sharing",
        "authors": "Agarwal, Amit; Boyle, Elette; Chandran, Nishanth; Gilboa, Niv; Gupta, Divya; Ishai, Yuval; Kelkar, Mahimna; Ma, Yiping",
        "keywords": "Function Secret Sharing (函数秘密共享) - 利用函数分片实现安全计算\nSecure Computation (安全计算) - 多方协作计算保护隐私\nSecret Sharing (秘密共享) - 数据分片存储保障安全性\n选定的主题标签名称",
        "abstract": "We revisit the problem of concretely efficient secure computation of sorting and selection (e.g., maximum, median, or top-k) on secretshared data, focusing on the case of security against a single semihonest party. Previous solutions either have a high communication overhead or many rounds of interaction, even when allowing inputindependent preprocessing.We propose a suite of 2-party and 3-party offline-online protocols that exploit the efficient aggregation feature of function secret sharing to minimize the online communication and rounds. In particular, most of our protocols are optimal in terms of both online communication and online rounds up to small constant factors.We compare the performance of our protocols with prior works for different input parameters (number of items, bit length of items, batch size) and system parameters (CPU cores, network) and obtain up to 14x improvement in online run time for sorting and selection under some settings.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690359",
        "pub_year": "2024",
        "theme_label": "6.2 安全多方计算"
    },
    {
        "title": "Peeking through the window: Fingerprinting Browser Extensions through Page-Visible Execution Traces and Interactions",
        "authors": "Agarwal, Shubham; Fass, Aurore; Stock, Ben",
        "keywords": "Browser Fingerprinting (浏览器指纹识别) - 通过页面行为追踪扩展\nExtension Security (扩展安全性) - 防护机制存在缺陷\nJavaScript Namespace Pollution (JavaScript 命名空间污染) - 扩展代码干扰全局环境",
        "abstract": "Browser extensions are third-party add-ons that provide myriads of features to their users while browsing on the Web. Extensions often interact with the websites a user visits and perform various operations such as DOM-based manipulation, script injections, and so on. However, this also enables nefarious websites to track their visitors by fingerprinting extensions. Researchers in the past have shown that extensions are susceptible to fingerprinting based on the resources they include, the styles they deploy, or the DOM-based modifications they perform. Fortunately, the current extension ecosystem contains safeguards against many such known issues through appropriate defense mechanisms.We present the first study to investigate the fingerprinting characteristics of extension-injected code in pages' JavaScript namespace and through other observable side-effects like changed cookies. Doing so, we find that many extensions inject JavaScript that pollutes the applications' global namespace by registering variables. It also enables the attacker application to monitor the execution of the injected code by overwriting the JavaScript APIs and capturing execution traces through the stacktrace, the set of APIs invoked, etc. Further, extensions also store data on the client side and perform event-driven functionalities that aid in attribution. Through our tests, we find 2,747 Chrome and 572 Firefox extensions to be susceptible to fingerprinting. Unfortunately, none of the existing defense mechanisms prevent extensions from being fingerprinted through our proposed vectors. Therefore, we also suggest potential measures for developers and browser vendors to safeguard the extension ecosystem against such fingerprinting attempts.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670339",
        "pub_year": "2024",
        "theme_label": "网络与系统安全"
    },
    {
        "title": "Poster: FlashGuard: Real-time Disruption of Non-Price Flash Loan Attacks in DeFi",
        "authors": "Alhaidari, Abdulrahman; Palanisamy, Balaji; Krishnamurthy, Prashant",
        "keywords": "Flash Loan Attacks (闪贷攻击) - 利用区块链原子性实施的金融攻击\nReal-time Detection (实时检测) - 在攻击发生前及时识别威胁\nSmart Contract Security (智能合约安全) - 保障去中心化应用逻辑安全\n选定的主题标签名称",
        "abstract": "Flash loan attacks threaten decentralized finance (DeFi) protocols, which constitute a Total Value Locked (TVL) of more than $106 billion. These attacks exploit the atomicity property in blockchains to drain funds within a single block. Existing research overlooks the mitigation of non-price flash loan attacks, which mostly exploit zero-day vulnerabilities. These attacks are challenging to detect as they are highly time-sensitive and each instance of the attack is complex and has a unique pattern. To address this challenge, we present FlashGuard, a runtime detection and mitigation framework for non-price flash loan attacks. FlashGuard communicates directly with the miners and bypasses the public mempool, where attack transactions usually reside. We utilize the temporary time window where transactions are visible in the mempool but not yet confirmed. Once the attack is detected, FlashGuard dispatches a dusting counter-transaction for the victim contract to the miners directly within the same block to disrupt the attack's atomicity and change the smart contract state. This forces the malicious transaction to revert. FlashGuard ensures that the series of operations that are required for a non-price flash loan attack cannot be completed atomically, leading to a failure of the attack. Our evaluation using 20 historical attacks that exploited protocol vulnerabilities shows an outstanding detection rate for FlashGuard with minimal false positives, and effective attack disruption and indicates that FlashGuard could have rescued about $405.71 million in losses.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691385",
        "pub_year": "2024",
        "theme_label": "8.2 智能合约及安全"
    },
    {
        "title": "Unbundle-Rewrite-Rebundle: Runtime Detection and Rewriting of Privacy-Harming Code in JavaScript Bundles",
        "authors": "Ali, Mir Masood; Snyder, Peter; Kanich, Chris; Haddadi, Hamed",
        "keywords": "JavaScript Bundles (JavaScript代码包) - 用于网页功能的脚本打包技术\nPrivacy-Harming Code (隐私危害代码) - 对用户隐私构成威胁的代码段\nRuntime Rewriting (运行时重写) - 在执行期间修改代码以保护隐私",
        "abstract": "This work presents Unbundle-Rewrite-Rebundle (URR), a system for detecting privacy-harming portions of bundled JavaScript code and rewriting that code at runtime to remove the privacy-harming behavior without breaking the surrounding code or overall application. URR is a novel solution to the problem of JavaScript bundles, where websites pre-compile multiple code units into a single file, making it impossible for content filters and ad-blockers to differentiate between desired and unwanted resources. Where traditional content filtering tools rely on URLs, URR analyzes the code at the AST level, and replaces harmful AST sub-trees with privacy-and-functionality maintaining alternatives.We present an open-sourced implementation of URR as a Firefox extension and evaluate it against JavaScript bundles generated by the most popular bundling system (Webpack) deployed on the Tranco 10k. We evaluate URR by precision (1.00), recall (0.95), and speed (0.43s per script) when detecting and rewriting three representative privacy-harming libraries often included in JavaScript bundles, and find URR to be an effective approach to a large-and-growing blind spot unaddressed by current privacy tools.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690262",
        "pub_year": "2024",
        "theme_label": "信息内容安全"
    },
    {
        "title": "The Privacy-Utility Trade-off in the Topics API",
        "authors": "Alvim, Mario S.; Fernandes, Natasha; McIver, Annabelle; Nunes, Gabriel H.",
        "keywords": "Topics API (主题API) - 用于广告兴趣识别的浏览器接口\n隐私-效用权衡 (Privacy-Utility Trade-off) - 平衡数据效用与用户隐私\n差分隐私 (Differential Privacy) - 严格隐私保护数学模型",
        "abstract": "The ongoing deprecation of third-party cookies by web browser vendors has sparked the proposal of alternative methods to support more privacy-preserving personalized advertising on web browsers and applications. The Topics API is being proposed by Google to provide third-parties with coarse-grained advertising topics that the page visitor might currently be interested in. In this paper, we analyze the re-identification risks for individual Internet users and the utility provided to advertising companies by the Topics API, i.e. learning the most popular topics and distinguishing between real and random topics. We provide theoretical results dependent only on the API parameters that can be readily applied to evaluate the privacy and utility implications of future API updates, including novel general upper-bounds that account for adversaries with access to unknown, arbitrary side information, the value of the differential privacy parameter is an element of, and experimental results on real-world data that validate our theoretical model.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670368",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Block Ciphers in Idealized Models: Automated Proofs and New Security Results",
        "authors": "Ambrona, Miguel; Farshim, Pooya; Harasser, Patrick",
        "keywords": "Block Cipher (分组密码) - 加密算法核心结构\nIdealized Model (理想化模型) - 安全分析理论框架\nAutomated Proof (自动化证明) - 形式化验证新方法\n选定的主题标签名称",
        "abstract": "We develop and implement AlgoROM, a tool to systematically analyze the security of a wide class of symmetric primitives in idealized models of computation. The schemes thatwe consider are those that can be expressed over an alphabet consisting of XOR and function symbols for hash functions, permutations, or block ciphers.We implement our framework in OCaml and apply it to a number of prominent constructions, which include the Luby-Rackoff (LR), key-alternating Feistel (KAF), and iterated Even-Mansour (EM) ciphers, as well as substitution-permutation networks (SPN). The security models we consider are (S)PRP, and strengthenings thereof under related-key (RK), key-dependent message (KD), and more generally key-correlated (KC) attacks.Using AlgoROM, we are able to reconfirm a number of classical and previously established security theorems, and in one case we identify a gap in a proof from the literature (Connolly et al., ToSC'19). However, most results that we prove with AlgoROM are new. In particular, we obtain new positive results for LR, KAF, EM, and SPN in the above models. Our results better reflect the configurations actually implemented in practice, as they use a single idealized primitive. In contrast to many existing tools, our automated proofs do not operate in symbolic models, but rather in the standard probabilistic model for cryptography.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690222",
        "pub_year": "2024",
        "theme_label": "2.2.1 密码体制安全模型"
    },
    {
        "title": "Conditional Encryption with Applications to Secure Personalized Password Typo Correction",
        "authors": "Ameri, Mohammad Hassan; Blocki, Jeremiah",
        "keywords": "Conditional Encryption (条件加密) - 基于条件控制的加密机制\nHomomorphic Encryption (同态加密) - 支持密文计算的加密方式\nPassword Typo Correction (密码容错校正) - 安全纠正密码输入错误的技术",
        "abstract": "We introduce the notion of a conditional encryption scheme as an extension of public key encryption. In addition to the standard public key algorithms (KeyGen, Enc, Dec) for key generation, encryption and decryption, a conditional encryption scheme for a binary predicate.. adds a new conditional encryption algorithm CEnc. The conditional encryption algorithm c = CEnc(pk) (c(1), m(2), m(3)) takes as input the public encryption key pk, a ciphertext c(1) = Enc(pk) (m(1)) for an unknown message m(1), a control message m(2) and a payload message m(3) and outputs a conditional ciphertext c. Intuitively, if P (m(1), m(2)) = 1 then the conditional ciphertext.. should decrypt to the payload message m(3). On the other hand if P(m(1), m(2)) = 0 then the ciphertext should not leak any information about the control message m(2) or the payload message m(3) even if the attacker already has the secret decryption key sk. We formalize the notion of conditional encryption secrecy and provide concretely efficient constructions for a set of predicates relevant to password typo correction. Our practical constructions utilize the Paillier partially homomorphic encryption scheme as well as Shamir Secret Sharing. We prove that our constructions are secure and demonstrate how to use conditional encryption to improve the security of personalized password typo correction systems such as TypTop. We implement a C++ library for our practically efficient conditional encryption schemes and evaluate the performance empirically. We also update the implementation of TypTop to utilize conditional encryption for enhanced security guarantees and evaluate the performance of the updated implementation.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690374",
        "pub_year": "2024",
        "theme_label": "密码学及应用"
    },
    {
        "title": "Blocking Tracking JavaScript at the Function Granularity",
        "authors": "Amjad, Abdul Haddi; Munir, Shaoor; Shafiq, Zubair; Gulzar, Muhammad Ali",
        "keywords": "Function-level tracking detection (函数级跟踪检测) - 细粒度识别脚本跟踪行为\nSurrogate script generation (代理脚本生成) - 替代脚本以保留功能去除追踪\nDynamic execution context analysis (动态执行上下文分析) - 分析运行时调用关系识别恶意行为\n选定的主题标签名称",
        "abstract": "Modern websites extensively rely on JavaScript to implement both functionality and tracking. Existing privacy-enhancing content blocking tools struggle against mixed scripts, which simultaneously implement both functionality and tracking. Blocking such scripts would break functionality, and not blocking them would allow tracking. We propose NoT.js, a fine-grained JavaScript blocking tool that operates at the function-level granularity. NoT.js's strengths lie in analyzing the dynamic execution context, including the call stack and calling context of each JavaScript function, and then encoding this context to build a rich graph representation. NoT.js trains a supervised machine learning classifier on a webpage's graph representation to first detect tracking at the function-level and then automatically generates surrogate scripts that preserve functionality while removing tracking. Our evaluation of NoT.js on the top-10K websites demonstrates that it achieves high precision (94%) and recall (98%) in detecting tracking functions, outperforming the state-of-the-art while being robust against off-the-shelf JavaScript obfuscation. Fine-grained detection of tracking functions allows NoT.js to automatically generate surrogate scripts, which our evaluation shows that successfully remove tracking functions without causing major breakage. Our deployment of NoT.js shows that mixed scripts are present on 62.3% of the top-10K websites, with 70.6% of the mixed scripts being third-party that engage in tracking activities such as cookie ghostwriting.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670329",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Poster: How Do Visually Impaired Users Navigate Accessibility Challenges in an Ad-Driven Web?",
        "authors": "Amjad, Abdul Haddi; Gulzar, Muhammad Ali",
        "keywords": "Web Accessibility (网页可访问性) - 提升残障用户网络使用体验\nThird-Party Advertisements (第三方广告) - 广告内容影响网站合规性\nWCAG Compliance (WCAG合规性) - 评估网页内容无障碍标准",
        "abstract": "Website accessibility is crucial for inclusiveness and regulatory compliance. While third-party advertisements (ads) are essential for funding free web services, they pose significant accessibility challenges. When developers lease space to ad-serving technologies like DoubleClick, they lose control over the accessibility of ad content. Even highly accessible websites can have their adherence to Web Content Accessibility Guidelines (WCAG) undermined by third-party ads. We conduct an investigation into the accessibility of ads across 430K website elements, including nearly 100K ad elements. Our study aims to evaluate the prevalence of inaccessible ads and their impact on overall website accessibility. Our findings reveal that 67% of websites experience increased accessibility violations due to ads, with common issues including Focus Visible (WCAG 2.4.7) and On Input (WCAG 3.2.2). Ad-serving technologies such as Taboola, DoubleClick, and RevContent frequently serve ads that do not meet WCAG standards. Inaccessible ads can significantly increase privacy risks for users with disabilities, as these ads may force them to engage with potentially unsafe or misleading content without proper accessibility features to protect their information.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691389",
        "pub_year": "2024",
        "theme_label": "人的安全行为与管理"
    },
    {
        "title": "Precio: Private Aggregate Measurement via Oblivious Shuffling",
        "authors": "Anderson, Erik; Chase, Melissa; Durak, F. Betul; Laine, Kim; Weng, Chenkai",
        "keywords": "Secure Aggregation (安全聚合) - 隐私保护下的数据汇总\nDifferential Privacy (差分隐私) - 数据统计中的隐私保障\nOblivious Shuffling (无感知洗牌) - 隐私计算中的数据重排\n选定的主题标签名称",
        "abstract": "We introduce Precio, a new secure aggregation method for computing layered histograms and sums over secret shared data in a client-server setting. Precio is motivated by ad conversion measurement scenarios, where online advertisers and ad networks want to measure the performance of ad campaigns without requiring privacy-invasive techniques, such as third-party cookies.Precio has linear (time and communication) complexity in the number of data points and guarantees differentially private outputs. We formally analyze its security and privacy and present a thorough performance evaluation. The protocol supports much larger domains than Prio. It supports much more flexible aggregates than the DPF-based solution and in some settings has up to four orders of magnitude better performance.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670280",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Defying the Odds: Solana's Unexpected Resilience in Spite of the Security Challenges Faced by Developers",
        "authors": "Andreina, Sebastien; Cloosters, Tobias; Davi, Lucas; Giesen, Jens-Rene; Gutfleisch, Marco; Karame, Ghassan; Naiakshina, Alena; Naji, Houda",
        "keywords": "Smart Contract Security (智能合约安全) - 保障合约代码安全性\nDeveloper Behavior Analysis (开发者行为分析) - 研究开发过程中的安全决策\nBlockchain Frameworks Evaluation (区块链框架评估) - 分析框架对安全性的影响",
        "abstract": "Solana gained considerable attention as one of the most popular blockchain platforms for deploying decentralized applications. Compared to Ethereum, however, we observe a lack of research on how Solana smart contract developers handle security, what challenges they encounter, and how this affects the overall security of the ecosystem. To address this, we conducted the first comprehensive study on the Solana platform consisting of a 90-minute Solana smart contract code review task with 35 participants followed by interviews with a subset of seven participants. Our study shows, quite alarmingly, that none of the participants could detect all important security vulnerabilities in a code review task and that 83 % of the participants are likely to release vulnerable smart contracts. Our study also sheds light on the root causes of developers' challenges with Solana smart contract development, suggesting the need for better security guidance and resources. In spite of these challenges, our automated analysis on currently deployed Solana smart contracts surprisingly suggests that the prevalence of vulnerabilities-especially those pointed out as the most challenging in our developer study-is below 0.3%. We explore the causes of this counter-intuitive resilience and show that frameworks, such as Anchor, are aiding Solana developers in deploying secure contracts.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670333",
        "pub_year": "2024",
        "theme_label": "8.2 智能合约及安全"
    },
    {
        "title": "Practical Post-Quantum Signatures for Privacy",
        "authors": "Argo, Sven; Gueneysu, Tim; Jeudy, Corentin; Land, Georg; Roux-Langlois, Adeline; Sanders, Olivier",
        "keywords": "Post-Quantum Cryptography (后量子密码学) - 研究抗量子计算的密码机制\nBlind Signatures (盲签名) - 实现匿名与隐私保护的签名技术\nAnonymous Credentials (匿名凭证) - 提供身份匿名认证的安全系统",
        "abstract": "The transition to post-quantum cryptography has been an enormous challenge and effort for cryptographers over the last decade, with impressive results such as the future NIST standards. However, the latter has so far only considered central cryptographic mechanisms (signatures or KEM) and not more advanced ones, e.g., targeting privacy-preserving applications. Of particular interest is the family of solutions called blind signatures, group signatures and anonymous credentials, for which standards already exist, and which are deployed in billions of devices. Such a family does not have, at this stage, an efficient post-quantum counterpart although very recent works improved this state of affairs by offering two different alternatives: either one gets a system with rather large elements but a security proved under standard assumptions or one gets a more efficient system at the cost of ad-hoc interactive assumptions or weaker security models. Moreover, all these works have only considered size complexity without implementing the quite complex building blocks their systems are composed of. In other words, the practicality of such systems is still very hard to assess, which is a problem if one envisions a post-quantum transition for the corresponding systems/standards.In this work, we propose a construction of so-called signature with efficient protocols (SEP), which is the core of such privacy-preserving solutions. By revisiting the approach by Jeudy et al. (Crypto 2023) we manage to get the best of the two alternatives mentioned above, namely short sizes with no compromise on security. To demonstrate this, we plug our SEP in an anonymous credential system, achieving credentials of less than 80 KB. In parallel, we fully implemented our system, and in particular the complex zero-knowledge framework of Lyubashevsky et al. (Crypto'22), which has, to our knowledge, not be done so far. Our work thus not only improves the state-of-the-art on privacy-preserving solutions, but also significantly improves the understanding of efficiency and implications for deployment in real-world systems.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670297",
        "pub_year": "2024",
        "theme_label": "密码学及应用"
    },
    {
        "title": "Demo: Towards Reproducible Evaluations of ML-Based IDS Using Data-Driven Approaches",
        "authors": "Ayoubi, Solayman; Tixeuil, Sebastien; Blanc, Gregory; Jmila, Houda",
        "keywords": "Machine Learning-based Intrusion Detection (基于机器学习的入侵检测) - 基于ML模型识别网络攻击\nEvaluation Framework (评估框架) - 标准化评测ML-IDSS性能\nData-Driven Approach (数据驱动方法) - 依赖真实数据优化检测效果\n选定的主题标签名称",
        "abstract": "Network-based Intrusion Detection Systems (NIDS) are crucial in cybersecurity, but evaluation methodologies are outdated and lack standardization, resulting in incomplete and unreliable assessments. To address these issues, we first proposed a comprehensive evaluation framework for Machine Learning-based Intrusion Detection Systems [1]. This framework accounts for the unique aspects, strengths, and weaknesses of ML algorithms. However, the initial proposition lacked practicality, as it presented an abstract methodology without a substantive solution. In this paper, we present a demo of FREIDA a precise and concrete implementation of our framework, featuring an easy-to-use graphical interface. We also outline FREIDA's evaluation methodology and demonstrate its application in evaluating IDS using a dataset from the literature.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691368",
        "pub_year": "2024",
        "theme_label": "3.8.2 系统安全测评"
    },
    {
        "title": "AirGapAgent: Protecting Privacy-Conscious Conversational Agents",
        "authors": "Bagdasarian, Eugene; Yi, Ren; Ghalebikesabi, Sahra; Kairouz, Peter; Gruteser, Marco; Oh, Sewoong; Balle, Borja; Ramage, Daniel",
        "keywords": "Contextual Integrity (情境完整性) - 隐私保护的核心理论\nAirGapAgent (空气间隙代理) - 限制数据访问的隐私代理\nContext Hijacking Attack (上下文劫持攻击) - 操纵上下文窃取隐私",
        "abstract": "The growing use of large language model (LLM)-based conversational agents to manage sensitive user data raises significant privacy concerns. While these agents excel at understanding and acting on context, this capability can be exploited by malicious actors. We introduce a novel threat model where adversarial third-party apps manipulate the context of interaction to trick LLM-based agents into revealing private information not relevant to the task at hand. Grounded in the framework of contextual integrity, we introduce AirGapAgent, a privacy-conscious agent designed to prevent unintended data leakage by restricting the agent's access to only the data necessary for a specific task. Extensive experiments using Gemini, GPT, and Mistral models as agents validate our approach's effectiveness in mitigating this form of context hijacking while maintaining core agent functionality. For example, we show that a single-query context hijacking attack on a Gemini Ultra agent reduces its ability to protect user data from 94% to 45%, while an AirGapAgent achieves 97% protection, rendering the same attack ineffective.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690350",
        "pub_year": "2024",
        "theme_label": "人工智能安全"
    },
    {
        "title": "Mithridates: Auditing and Boosting Backdoor Resistance of Machine Learning Pipelines",
        "authors": "Bagdasarian, Eugene; Shmatikov, Vitaly",
        "keywords": "Backdoor Resistance (后门鲁棒性) - 防御训练数据中毒攻击的能力\nTraining Pipeline Audit (训练流程审计) - 评估机器学习流程安全性\nHyperparameter Optimization (超参数优化) - 平衡模型准确率与安全性的配置搜索",
        "abstract": "Machine learning (ML) models trained on data from potentially untrusted sources are vulnerable to poisoning. A small, maliciously crafted subset of the training inputs can cause the model to learn a backdoor task (e.g., misclassify inputs with a certain feature) in addition to its main task. Recent research proposed many hypothetical backdoor attacks whose efficacy depends on the configuration and training hyperparameters of the target model. At the same time, state-of-the-art defenses require massive changes to the existing ML pipelines and protect only against some attacks.Given the variety of potential backdoor attacks, ML engineers who are not security experts have no way to measure how vulnerable their current training pipelines are, nor do they have a practical way to compare training configurations so as to pick the more resistant ones. Deploying a defense may not be a realistic option, either. It requires evaluating and choosing from among dozens of research papers, completely re-engineering the pipeline as required by the chosen defense, and then repeating the process if the defense disrupts normal model training (while providing theoretical protection against an unknown subset of hypothetical threats).In this paper, we aim to provide ML engineers with pragmatic tools to audit the backdoor resistance of their training pipelines and to compare different training configurations, to help choose the one that best balances accuracy and security.First, we propose a universal, attack-agnostic resistance metric based on the minimum number of training inputs that must be compromised before the model learns any backdoor.Second, we design, implement, and evaluate Mithridates, a multistage approach that integrates backdoor resistance into the training-configuration search. ML developers already rely on hyperparameter search to find configurations that maximize the model's accuracy. Mithridates extends this tool to also order configurations based on their backdoor resistance. We demonstrate that Mithridates discovers configurations whose resistance to multiple types of backdoor attacks increases by 3-5x with only a slight impact on accuracy. We also discuss extensions to AutoML and federated learning.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690337",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "ALCHEMY: Data-Free Adversarial Training",
        "authors": "Bai, Yijie; Ma, Zhongming; Chen, Yanjiao; Deng, Jiangyi; Pang, Shengyuan; Liu, Yan; Xu, Wenyuan",
        "keywords": "Adversarial Training (对抗训练) - 提升模型抗攻击能力\nData-Free Learning (无数据学习) - 无需原始数据的模型训练\nModel Robustness (模型鲁棒性) - 增强模型稳定性与安全性",
        "abstract": "Machine learning models have become integral to various aspects of daily life, prompting increased vulnerability to adversarial attacks. Adversarial training is one of the most promising and practical methods to enhance model robustness. Existing adversarial training methods, however, assume access to the original training data. But nowadays, more and more users directly download models from the open-source model platforms or tech companies, but the original training datasets are usually unreleased because of commercial interests or privacy. In such scenarios, the user cannot utilize the former adversarial training methods to improve model robustness because of the lack of original training datasets.Thus, we present the first exploration of a data-free adversarial training framework, ALCHEMY, which seeks to enhance model robustness without requiring access to the original training data. By addressing the notable challenges of reconstructing high-quality training data with robust features and improving the adversarial robustness to the inaccessible original dataset, our approach achieves the goals of both high accuracy maintenance and robustness improvement. Comprehensive experiments on four datasets compared with five baselines, demonstrate ALCHEMY's high effectiveness. With no access to any training dataset, the average robustness improvement with ALCHEMY is effective in most attack scenarios. Additional evaluations underscore the framework's stability under different settings and discuss future research directions.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670395",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "zkLogin: Privacy-Preserving Blockchain Authentication with Existing Credentials",
        "authors": "Baldimtsi, Foteini; Chalkias, Konstantinos Kryptos; Ji, Yan; Lindstrom, Jonas; Maram, Deepak; Ben Riva; Roy, Arnab; Sedaghat, Mahdi; Wang, Joy",
        "keywords": "Zero-Knowledge Proof (零知识证明) - 隐私保护的身份验证技术\nBlockchain Authentication (区块链认证) - 基于链的身份验证机制\nDigital Identity Reuse (数字身份复用) - 利用现有身份进行认证\n选定的主题标签名称",
        "abstract": "For many users, a private key based wallet serves as the primary entry point to blockchains. Commonly recommended wallet authentication methods, such as mnemonics or hardware wallets, can be cumbersome. This difficulty in user onboarding has significantly hindered the adoption of blockchain-based applications.We develop zkLogin, a novel technique that leverages identity tokens issued by popular platforms (any OpenID Connect enabled platform e.g., Google, Facebook, etc.) to authenticate transactions. At the heart of zkLogin lies a signature scheme allowing the signer to sign using their existing OpenID accounts and nothing else. This improves the user experience significantly as users do not need to remember a new secret and can reuse their existing accounts.zkLogin provides strong security and privacy guarantees. Unlike prior works, zkLogin's security relies solely on the underlying platform's authentication mechanism without the need for any additional trusted parties (e.g., trusted hardware or oracles). As the name suggests, zkLogin leverages zero-knowledge proofs (ZKP) to ensure that the sensitive link between a user's off-chain and on-chain identities is hidden, even from the platform itself.zkLogin enables a number of important applications outside blockchains. It allows billions of users to produce verifiable digital content leveraging their existing digital identities, e.g., email address. For example, a journalist can use zkLogin to sign a news article with their email address, allowing verification of the article's authorship by any party.We have implemented and deployed zkLogin on the Sui blockchain as an additional alternative to traditional digital signature-based addresses. Due to the ease of web3 on-boarding just with social login, many hundreds of thousands of zkLogin accounts have already been generated in various industries such as gaming, DeFi, direct payments, NFT collections, sports racing, cultural heritage, and many more.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690356",
        "pub_year": "2024",
        "theme_label": "身份认证与管理"
    },
    {
        "title": "Poster: PGPNet: Classify APT Malware Using Prediction-Guided Prototype Network",
        "authors": "Bao, Huaifeng; Li, Wenhao; Li, Zhaoxuan; Miao, Han; Wang, Wen; Liu, Feng",
        "keywords": "Prediction-Guided Prototype Network (预测引导原型网络) - 元学习架构分类方法\nAPT Malware Classification (APT恶意软件分类) - 高级持续威胁分组识别\nAuxiliary Task Learning (辅助任务学习) - 多任务优化特征表示\n选定的主题标签名称",
        "abstract": "As the popularity of Advanced Persistent Threat (APT) grows, APT malware group classification has attracted more attention recently. However, most of previous methods use simple classifiers for group classification, ignoring the bias caused by the sparse number of revealed malware and the differences in functionality distribution of most groups. In this paper, we propose a Prediction-Guided Prototype Network (PGPNet) that could quickly adapt to new classification tasks with limited supervised samples based on the meta-learning architecture. Adding malware functionality classification as an auxiliary task is beneficial for feature learning, and the bias of distribution differences is eliminated by intervening the predicted results into the group classifier. Experimental results on a APT malware dataset show that PGPNet successfully exploits the contextual information and predictions of the auxiliary task and achieves state-of-the-art performance.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691396",
        "pub_year": "2024",
        "theme_label": "3.7 恶意代码分析与防护"
    },
    {
        "title": "No Peer, no Cry: Network Application Fuzzing via Fault Injection",
        "authors": "Bars, Nils; Schloegel, Moritz; Schiller, Nico; Bernhard, Lukas; Holz, Thorsten",
        "keywords": "Network Application Fuzzing (网络应用模糊测试) - 通过故障注入发现漏洞\nFault Injection (故障注入) - 引发异常状态以检测缺陷\nStateful Communication Testing (有状态通信测试) - 验证协议交互安全性\n选定的主题标签名称",
        "abstract": "Network-facing applications are commonly exposed to all kinds of attacks, especially when connected to the internet. As a result, web servers like Nginx or client applications such as curl make every effort to secure and harden their code to rule out memory safety violations. One would expect this to include regular fuzz testing, as fuzzing has proven to be one of the most successful approaches to uncovering bugs in software. Yet, surprisingly little research has focused on fuzzing network applications. When studying the underlying reasons, we find that the interactive nature of communication, its statefulness, and the protection of exchanged messages (e.g., via encryption or cryptographic signatures) render typical fuzzers ineffective. Attempts to replay recorded messages or modify them on the fly only work for specific targets and often lead to early termination of communication.In this paper, we discuss these challenges in detail, highlighting how the focus of existing work on protocol state space promises little relief. We propose a fundamentally different approach that relies on fault injection rather than modifying messages. Effectively, we force one of the communication peers into a weird state where its output no longer matches the expectations of the target peer, potentially uncovering bugs. Importantly, this weird peer can still properly encrypt/sign the protocol message, overcoming a fundamental challenge of current fuzzers. In effect, we leave the communication system intact but introduce small corruptions. Since we can turn either the server or the client into the weird peer, our approach is the first that can effectively test client-side network applications. In an extensive evaluation of 16 targets, we show that our prototype FUZZTRUCTION-NET significantly outperforms other fuzzers in terms of coverage and bugs found. Overall, FUZZTRUCTION-NET uncovered 23 new bugs in well-tested software, such as the web servers Nginx and Apache HTTPd and the OpenSSH client.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690274",
        "pub_year": "2024",
        "theme_label": "3.8.1 漏洞挖掘与逆向分析"
    },
    {
        "title": "Testing Side-channel Security of Cryptographic Implementations against Future Microarchitectures",
        "authors": "Barthe, Gilles; Boehme, Marcel; Cauligi, Sunjay; Chuengsatiansup, Chitchanok; Genkin, Daniel; Guarnieri, Marco; Mateos Romero, David; Schwabe, Peter; Wu, David; Yarom, Yuval",
        "keywords": "Side-channel Security (侧信道安全) - 防范通过非内容途径泄密\nMicroarchitectural Optimizations (微架构优化) - 提升性能可能引入风险\nCryptographic Implementations (密码实现) - 安全性受硬件变化影响\n选定的主题标签名称",
        "abstract": "How will future microarchitectures impact the security of existing cryptographic implementations? As we cannot keep reducing the size of transistors, chip vendors have started developing new microarchitectural optimizations to speed up computation. A recent study (Sanchez Vicarte et al., ISCA 2021) suggests that these optimizations might open the Pandora's box of microarchitectural attacks. However, there is little guidance on how to evaluate the security impact of future optimization proposals. To help chip vendors explore the impact of microarchitectural optimizations on cryptographic implementations, we develop (i) an expressive domain-specific language, called LmSpec, that allows them to specify the leakage model for the given optimization and (ii) a testing framework, called LmTest, to automatically detect leaks under the specified leakage model within the given implementation. Using this framework, we conduct an empirical study of 18 proposed microarchitectural optimizations on 25 implementations of eight cryptographic primitives in five popular libraries. We find that every implementation would contain secret-dependent leaks, sometimes sufficient to recover a victim's secret key, if these optimizations were realized. Ironically, some leaks are possible only because of coding idioms used to prevent leaks under the standard constant-time model.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670319",
        "pub_year": "2024",
        "theme_label": "2.4 密码工程技术"
    },
    {
        "title": "RANsacked: A Domain-Informed Approach for Fuzzing LTE and 5G RAN-Core Interfaces",
        "authors": "Bennett, Nathaniel; Zhu, Weidong; Simon, Benjamin; Kennedy, Ryon; Enck, William; Traynor, Patrick; Butler, Kevin R. B.",
        "keywords": "Fuzzing (模糊测试) - 针对输入的自动化漏洞挖掘\nRAN-Core Interfaces (无线接入网-核心网接口) - 5G/LTE网络关键通信路径\nASN.1 Specifications (抽象语法标记一规范) - 定义通信协议数据结构的标准",
        "abstract": "Cellular network infrastructure serves as the backbone of modern mobile wireless communication. As such, cellular cores must be proactively secured against external threats to ensure reliable service. Compromised base station attacks against the core are a rising threat to cellular networks, while user device inputs have long been considered as an attack vector; despite this, few techniques exist to comprehensively test RAN-Core interfaces against malicious input. In this work, we devise a fuzzing framework that performantly fuzzes cellular interfaces accessible from a base station or user device, overcoming several challenges in fuzzing specific to LTE/5G network components. We also introduce ASNFuzzGen, a tool that compiles ASN.1 specifications into structure-aware fuzzing modules, thereby facilitating effective fuzzing exploration of complex cellular protocols. We run fuzzing campaigns against seven open-source and commercial cores and discover 119 vulnerabilities, with 93 CVEs assigned. Our results reveal common implementation mistakes across several cores that lead to vulnerabilities, and the successful coordination of patches for these vulnerabilities across several vendors demonstrates the practical impact ASNFuzzGen has on hardening user-exposed cellular systems.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670320",
        "pub_year": "2024",
        "theme_label": "网络通信安全 (含 5/6G)"
    },
    {
        "title": "New Secret Keys for Enhanced Performance in (T)FHE",
        "authors": "Bergerat, Loris; Chillotti, Ilaria; Ligier, Damien; Orfila, Jean-Baptiste; Roux-Langlois, Adeline; Tap, Samuel",
        "keywords": "Fully Homomorphic Encryption (全同态加密) - 加密数据直接计算技术\nSecret Key Optimization (秘密密钥优化) - 提升加密效率与安全性\nCryptosystem Performance (密码系统性能) - 改进算法运行效率",
        "abstract": "Fully Homomorphic Encryption has known impressive improvements in the last 15 years, going from a technology long thought to be impossible to an existing family of encryption schemes able to solve a plethora of practical use cases related to the privacy of sensitive information. Recent results mainly focus on improving techniques within the traditionally defined framework of GLWE-based schemes, but the recent CPU implementation improvements are mainly incremental. To keep improving this technology, one solution is to modify the aforementioned framework, by using slightly different hardness assumptions.In this paper, we identify two limitations with (T)FHE: (i) there is no fine-grained control over the size of a GLWE secret key, which is traditionally composed of j polynomials with N = 2(alpha) > 1 coefficients; (ii) for security reasons one cannot use a noise variance smaller than a certain sigma(mi)n so, for all ciphertext modulus q is an element of N, there exists an integer n(plateau) such that, with any secret key of size k . N >= n(plateau), one cannot control their level of security, resulting in unnecessary big security levels.To overcome the aforementioned limitations, we introduce two new types of secret keys for GLWE-based cryptosystems, that can be used separately or together. We explain why these new secret keys are as secure as the traditional ones and we detail all the improvements that they bring to existing FHE algorithms alongside new algorithms especially efficient with these new keys. We provide many comparisons with state-of-the-art TFHE techniques with traditional secret keys, and some benchmarks showing computational speed-ups between 1.3 and 2.4 while keeping the same level of security and failure probability (correctness). Furthermore, the size of the key switching and bootstrapping keys is also reduced with this contribution by factors ranging from 1.5 to 2.7.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670376",
        "pub_year": "2024",
        "theme_label": "6.3 同态加密"
    },
    {
        "title": "Understanding Routing-Induced Censorship Changes Globally",
        "authors": "Bhaskar, Abhishek; Pearce, Paul",
        "keywords": "Internet Censorship (互联网审查) - 研究网络内容限制机制\nECMP Routing (等价多路径路由) - 分析路由导致的审查差异\nMeasurement Methodology (测量方法论) - 提升审查测量可靠性",
        "abstract": "Internet censorship is pervasive, with significant effort dedicated to understanding what is censored, and where. Prior censorship measurements however have identified significant inconsistencies in their results; experiments show unexplained non-deterministic behaviors thought to be caused by censor load, end-host geographic diversity, or incomplete censorship-inconsistencies which impede reliable, repeatable and correct understanding of global censorship. In this work we investigate the extent to which Equal-cost Multi-path (ECMP) routing is the cause for these inconsistencies, developing methods to measure and compensate for them.We find ECMP routing significantly changes observed censorship across protocols, censor mechanisms, and in 17 countries. We identify that previously observed non-determinism or regional variations are attributable to measurements between fixed end-hosts taking different routes based on Flow-ID; i.e., choice of intra-subnet source IP or ephemeral source port changes observed censorship. By developing new route-stable censorship measurement methods that allow consistent measurement of DNS, HTTP, and HTTPS censorship, we find ECMP routing yields censorship changes across 42% of IPs and 51% of ASes, but that impact is not uniform. We also develop an application-level traceroute tool to construct network paths using specific censored packets, thus identifying numerous causes of differences, ranging from likely failed infrastructure, to routes to the same end-host taking geographically diverse paths which experience differences in censorship en-route. Finally, we examine our results in the context of prior global measurement studies, exploring the applicability of our findings to prior observed variations, and then demonstrating how specific experiments from two studies could be impacted by, and specific results are explainable by, ECMP routing. Our work points to methods for improving future studies, reducing inconsistencies and increasing repeatability.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670336",
        "pub_year": "2024",
        "theme_label": "网络通信安全 (含 5/6G)"
    },
    {
        "title": "The Illusion of Randomness: An Empirical Analysis of Address Space Layout Randomization Implementations",
        "authors": "Binosi, Lorenzo; Barzasi, Gregorio; Carminati, Michele; Zanero, Stefano; Polino, Mario",
        "keywords": "Address Space Layout Randomization (地址空间布局随机化) - 内存布局防御机制\nOperating System Security (操作系统安全) - 系统防护能力评估\nEntropy Reduction Analysis (熵减分析) - 随机性削弱研究",
        "abstract": "Address Space Layout Randomization (ASLR) is a crucial defense mechanism employed by modern operating systems to mitigate exploitation by randomizing processes' memory layouts. However, the stark reality is that real-world implementations of ASLR are imperfect and subject to weaknesses that attackers can exploit. This work evaluates the effectiveness of ASLR on major desktop platforms, including Linux, MacOS, and Windows, by examining the variability in the placement of memory objects across various processes, threads, and system restarts. In particular, we collect samples of memory object locations, conduct statistical analyses to measure the randomness of these placements and examine the memory layout to find any patterns among objects that could decrease this randomness. The results show that while some systems, like Linux distributions, provide robust randomization, others, like Windows and MacOS, often fail to adequately randomize key areas like executable code and libraries. Moreover, we find a significant entropy reduction in the entropy of libraries after the Linux 5.18 version and identify correlation paths that an attacker could leverage to reduce exploitation complexity significantly. Ultimately, we rank the identified weaknesses based on severity and validate our entropy estimates with a proof-of-concept attack. In brief, this paper provides the first comprehensive evaluation of ASLR effectiveness across different operating systems and highlights opportunities for Operating System (OS) vendors to strengthen ASLR implementations.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690239",
        "pub_year": "2024",
        "theme_label": "系统安全测评"
    },
    {
        "title": "Sui Lutris: A Blockchain Combining Broadcast and Consensus",
        "authors": "Blackshear, Sam; Chursin, Andrey; Danezis, George; Kichidis, Anastasios; Kokoris-Kogias, Lefteris; Li, Xun; Logan, Mark; Menon, Ashok; Nowacki, Todd; Sonnino, Alberto; William, Brandon; Zhang, Lu",
        "keywords": "Consensusless Agreement (无共识协议) - 无需共识的分布式一致性\nHybrid Blockchain Architecture (混合区块链架构) - 结合广播与共识的链结构\nSub-Second Finality (亚秒级最终性) - 交易确认延迟低于一秒",
        "abstract": "Lutris is the first smart-contract platform to sustainably achieve sub-second finality. It achieves this significant decrease by employing consensusless agreement not only for simple payments but for a large variety of transactions. Unlike prior work, Sui Lutris neither compromises expressiveness nor throughput and can run perpetually without restarts. Sui Lutris achieves this by safely integrating consensuless agreement with a high-throughput consensus protocol that is invoked out of the critical finality path but ensures that when a transaction is at risk of inconsistent concurrent accesses, its settlement is delayed until the total ordering is resolved. Building such a hybrid architecture is especially delicate during reconfiguration events, where the system needs to preserve the safety of the consensusless path without compromising the long-term liveness of potentially misconfigured clients. We thus develop a novel reconfiguration protocol, the first to provably show the safe and efficient reconfiguration of a consensusless blockchain. Sui Lutris is currently running in production and underpins the Sui smart-contract platform. Combined with the use of Objects instead of accounts it enables the safe execution of smart contracts that expose objects as a first-class resource. In our experiments Sui Lutris achieves latency lower than 0.5 seconds for throughput up to 5,000 certificates per second (150k ops/s with transaction blocks), compared to the state-of-the-art real-world consensus latencies of 3 seconds. Furthermore, it gracefully handles validators crash-recovery and does not suffer visible performance degradation during reconfiguration.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670286",
        "pub_year": "2024",
        "theme_label": "区块链及安全"
    },
    {
        "title": "Cryptography and Computer Security: A View From the Year 2100",
        "authors": "Boneh, Dan",
        "keywords": "Cryptography (密码学) - 研究信息加密与解密技术\nComputer Security (计算机安全) - 保障计算系统免受攻击与破坏\nFuture Perspective (未来视角) - 展望长期技术发展与趋势\n选定的主题标签名称",
        "abstract": "nan",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690378",
        "pub_year": "2024",
        "theme_label": "2、密码学及应用"
    },
    {
        "title": "Poster: TAPChecker: Model Checking in Trigger-Action Rules Generation Using Large Language Models",
        "authors": "Bui, Huan; Lienerth, Harper; Fu, Chenglong; Sridhar, Meera",
        "keywords": "Trigger-Action Programming (触发-动作编程) - 智能家居自动化规则生成\nLarge Language Models (大型语言模型) - 用于生成TAP规则\nFormal Verification (形式化验证) - 验证规则安全性\n选定的主题标签名称",
        "abstract": "The integration of large language models (LLMs) in smart home systems holds significant promise for automating the generation of Trigger-Action Programming (TAP) rules, potentially streamlining smart home user experiences and enhancing convenience. However, LLMs lack of holistic view of smart home IoT deployments and may introduce TAP rules that result in hazards. This paper explores the application of LLM for generating TAP rules and applying formal verification to validate and ensure the safety of TAP rules generated by LLMs. By systematically analyzing and verifying these rules, we aim to identify and mitigate potential security vulnerabilities. Furthermore, we propose a feedback mechanism to refine the LLM's output, enhancing its reliability and safety in generating automation rules. Through this approach, we seek to bridge the gap between the efficiency of LLMs and the stringent security requirements of smart IoT systems, fostering a safer automation environment.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691416",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "RESPIRE: High-Rate PIR for Databases with Small Records",
        "authors": "Burton, Alexander; Menon, Samir Jordan; Wu, David J.",
        "keywords": "Private Information Retrieval (私有信息检索) - 隐私保护的数据查询方法\nHomomorphic Encryption (同态加密) - 支持密文计算的加密技术\nLattice-based Cryptography (基于格的密码学) - 抗量子的密码系统设计\n选定的主题标签名称",
        "abstract": "Private information retrieval (PIR) is a key building block in many privacy-preserving systems, and recent works have made significant progress on reducing the concrete computational costs of single-server PIR. However, existing constructions have high communication overhead, especially for databases with small records. In this work, we introduce Respire, a lattice-based PIR scheme tailored for databases of small records. To retrieve a single record from a database with over a million 256-byte records, the Respire protocol requires just 6.1 KB of online communication; this is a 5.9x reduction compared to the best previous lattice-based scheme. Moreover, Respire naturally extends to support batch queries. Compared to previous communication-efficient batch PIR schemes, Respire achieves a 3.4-7.1x reduction in total communication while maintaining comparable throughput (200-400 MB/s). The design of Respire relies on new query compression and response packing techniques based on ring switching in homomorphic encryption.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690328",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Poster: Kill Krill or Proxy RPKI",
        "authors": "Cattepoel, Louis; Mirdita, Donika; Schulmann, Haya; Waidner, Michael",
        "keywords": "Resource Public Key Infrastructure (资源公钥基础设施) - 路由安全认证机制\nPublication Point Security (发布点安全) - 存储与分发证书的安全性\nDenial-of-Service Vulnerability (拒绝服务漏洞) - 导致性能降级的攻击方式",
        "abstract": "Resource Public Key Infrastructure (RPKI), designed to protect Internet routing from hijacks, is gaining traction: over 50% of prefixes have digital certificates, at least 27% of Autonomous Systems actively validate certificates against BGP announcements, and filter invalid routing announcements. In this study, we present the first security analysis of Krill, the only public and open-source RPKI publication point software. Publication points are hosted by the five Regional Internet Registries across the globe, or by independent Internet operators that wish to manage their own RPKI repositories.Through a detailed investigation of Krill, involving API, command line, configuration parsings, and static code analysis, we identify significant vulnerabilities such as transient dependencies and Denial-of-Service (DoS) exploits. Our key findings reveal Krill's susceptibility to path traversal attacks in case of misconfigured Nginx proxies, and a DoS vulnerability stemming from the h2 rust library. We develop an attack vector that exploits the rust library vulnerability, which leads to a 350x performance degradation. Our results indicate that RPKI is not yet production-grade ready as its main component, the publication points - which host the RPKI objects, are vulnerable to information leaks and DoS attacks.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691390",
        "pub_year": "2024",
        "theme_label": "网络基础设施安全"
    },
    {
        "title": "μCFI: Formal Verification of Microarchitectural Control-flow Integrity",
        "authors": "Ceesay-Seitz, Katharina; Solt, Flavien; Razavi, Kaveh",
        "keywords": "Control-Flow Integrity (控制流完整性) - 保障程序执行路径不被篡改\nFormal Verification (形式化验证) - 数学证明系统满足安全属性\nMicroarchitectural Security (微架构安全) - 防止硬件层面信息泄露与攻击\n选定的主题标签名称",
        "abstract": "Formal verification of hardware often requires the creation of clock-cycle accurate properties that need tedious and error-prone adaptations for each design. Property violations further require attention from verification engineers to identify affected instructions. This oftentimes manual effort hinders the adoption of formal verification at scale. This paper introduces Microarchitectural Control-Flow Integrity (mu CFI), a new general security property that can capture multiple classes of vulnerabilities under different threat models, most notably the microarchitectural violation of constant-time execution and (micro-)architectural vulnerabilities that allow an attacker to hijack the (architectural) control flow. We show a novel approach for the verification of mu CFI using a single property that checks for information flows from instruction operands to the program counter by injecting taint at appropriate clock cycles. To check arbitrary sequences of instructions and associate property violations to a specific Instruction Under Verification (IUV), we propose techniques for declassifying tainted data when it is being written to registers and forwarded from the IUV through architecturally known paths. We show that our verification approach is low effort (e.g., requires tagging six signals) while capturing all interactions between unbounded sequences of instructions in the extended threat model of mu CFI. We verify four RISC-V CPUs against mu CFI and prove that mu CFI is satisfied in many cases while detecting five new security vulnerabilities (4 CVEs), three of which are in Ibex, which has already been checked by state-of-the-art verification approaches.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690344",
        "pub_year": "2024",
        "theme_label": "3.2 硬件安全"
    },
    {
        "title": "Call Me By My Name: Simple, Practical Private Information Retrieval for Keyword Queries",
        "authors": "Celi, Sofia; Davidson, Alex",
        "keywords": "Private Information Retrieval (私有信息检索) - 隐私保护的数据查询技术\nKeyword Search (关键词搜索) - 支持关键字的高效检索方法\nLearning With Errors (误差学习问题) - 基于格的密码学基础\n选定的主题标签名称",
        "abstract": "We introduce ChalametPIR: a single-server Private Information Retrieval (PIR) scheme supporting fast, low-bandwidth keyword queries, with a conceptually very simple design. In particular, we develop a generic framework for converting PIR schemes for index queries over flat arrays (based on Learning With Errors) into keyword PIR. This involves representing a key-value map using any probabilistic filter that permits reconstruction of elements from inclusion queries (e.g. Cuckoo filters). In particular, we make use of recently developed Binary Fuse filters to construct ChalametPIR, with minimal efficiency blow-up compared with state-of-the-art index-based schemes (all costs bounded by a factor of <= 1.08). Furthermore, we show that ChalametPIR achieves runtimes and financial costs that are factors of between 6x-11x and 3.75x-11.4x more efficient, respectively, than state-of-the-art keyword PIR approaches, for varying database configurations. Bandwidth costs are reduced or remain competitive, depending on the configuration. Finally, we believe that our application of Binary Fuse filters can have independent value towards developing efficient variants of related cryptographic primitives (e.g. private set intersection), that already benefit from using less efficient filter constructions.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670271",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Poster: YFuzz: Data-Driven Fuzzing",
        "authors": "Chang, Yuan; Huang, Chun-Chia; Mori, Tatsuya; Hsiao, Hsu-Chun",
        "keywords": "Fuzzing (模糊测试) - 通过输入变异发现漏洞\nValue State Coverage (值状态覆盖) - 覆盖变量值及执行顺序\nData-Driven Fuzzing (数据驱动模糊测试) - 利用运行时数据引导测试",
        "abstract": "Code coverage is an effective objective for guiding fuzzers to explore code and identify bugs, and it has been a key factor in the success of greybox fuzzing. However, code coverage has a critical limitation: coverage-guided fuzzers can miss bugs even when the associated code is covered. This limitation arises because merely executing the associated code is often insufficient to trigger a bug; specific conditions are usually also required. These conditions are not fully captured by code coverage, which focuses only on whether the code was executed.To address this problem, we propose a new objective: value state coverage, an additional dimension in coverage metrics that is orthogonal to code coverage. Value state is a combination of the values assigned to program variables and the order of their assignment, and by measuring the coverage of value states, we can guide a fuzzer to explore the triggering conditions of bugs. We also introduce Data-Driven Fuzzing, a novel fuzzing technique that focuses on value state coverage, and utilizes security-related variables, mutation strategies, and extreme values captured at run-time to effectively discover bugs. We implemented our approach in a prototype fuzzer named YFuzz. YFuzz has found 12 bugs in programs included in the OSS-Fuzz project, including 4 assigned CVEs, indicating that our approach is effective in finding bugs.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691420",
        "pub_year": "2024",
        "theme_label": "系统安全测评"
    },
    {
        "title": "VERITAS: Plaintext Encoders for Practical Verifiable Homomorphic Encryption",
        "authors": "Chatel, Sylvain; Knabenhans, Christian; Pyrgelis, Apostolos; Troncoso, Carmela; Hubaux, Jean-Pierre",
        "keywords": "Homomorphic Encryption (同态加密) - 支持密文直接计算\nVerifiable Computation (可验证计算) - 确保计算结果正确性\nPrivacy-Preserving Analytics (隐私保护分析) - 在加密数据上执行安全分析",
        "abstract": "Homomorphic encryption has become a practical solution for protecting the privacy of computations on sensitive data. However, existing homomorphic encryption pipelines do not guarantee the correctness of the computation result in the presence of a malicious adversary. We propose two plaintext encodings compatible with state-of-the-art fully homomorphic encryption schemes that enable practical client-verification of homomorphic computations while supporting all the operations required for modern privacy-preserving analytics. Based on these encodings, we introduce Veritas, a ready-to-use library for the verification of computations executed over encrypted data. Veritas is the first library that supports the verification of any homomorphic operation. We demonstrate its practicality for various applications and, in particular, we show that it enables verifiability of homomorphic analytics with less than 3x computation overhead compared to the homomorphic encryption baseline.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670282",
        "pub_year": "2024",
        "theme_label": "6.3 同态加密"
    },
    {
        "title": "BlueSWAT: A Lightweight State-Aware Security Framework for Bluetooth Low Energy",
        "authors": "Che, Xijia; He, Yi; Feng, Xuewei; Sun, Kun; Xu, Ke; Li, Qi",
        "keywords": "Bluetooth Low Energy (蓝牙低功耗) - 短距离无线通信技术\nSession-based Attacks (基于会话的攻击) - 利用会话流程漏洞进行攻击\nState-aware Security Framework (状态感知安全框架) - 基于状态监测的安全防护机制",
        "abstract": "Bluetooth Low Energy (BLE) is a short-range wireless communication technology for resource-constrained IoT devices. Unfortunately, BLE is vulnerable to session-based attacks, where previous packets construct exploitable conditions for subsequent packets to compromise connections. Defending against session-based attacks is challenging because each step in the attack sequence is legitimate when inspected individually. In this paper, we present BlueSWAT, a lightweight state-aware security framework for protecting BLE devices. To perform inspection on the session level rather than individual packets, BlueSWAT leverages a finite state machine (FSM) to monitor sequential actions of connections at runtime. Patterns of session-based attacks are modeled as malicious transition paths in the FSM. To overcome the heterogeneous IoT environment, we develop a lightweight eBPF framework to facilitate universal patch distribution across different BLE architectures and stacks, without requiring device reboot. We implement BlueSWAT on 5 real-world devices with different chips and stacks to demonstrate its cross-device adaptability. On our dataset with 101 real-world BLE vulnerabilities, BlueSWAT can mitigate 76.1% of session-based attacks, outperforming other defense frameworks. In our end-to-end application evaluation, BlueSWAT introduces an average of 0.073% memory overhead and negligible latency.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670397",
        "pub_year": "2024",
        "theme_label": "网络与系统安全"
    },
    {
        "title": "Poster: A Full-stack Secure Deletion Framework for Modern Computing Devices",
        "authors": "Chen, Bo; Rother, Caleb; Dafoe, Josh",
        "keywords": "Secure deletion (安全删除) - 数据彻底清除技术\nFull-stack design (全栈设计) - 覆盖软硬件整体架构\nData privacy protection (数据隐私保护) - 保障用户信息不泄露\n选定的主题标签名称",
        "abstract": "Secure data deletion is of critical importance for complying with retention regulations and safeguarding user privacy. In this work, we have proposed the first full-stack secure deletion design addressing both external storage and internal memory for secure deletion. Preliminary experimental results are provided to justify feasibility of the proposed design.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691369",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Manipulating OpenFlow Link Discovery Packet Forwarding for Topology Poisoning",
        "authors": "Chen, Mingming; La Porta, Thomas; Taylor, Teryl; Araujo, Frederico; Jaeger, Trent",
        "keywords": "Topology Poisoning (拓扑中毒) - 操纵网络拓扑信息以破坏管理\nOpenFlow (开放流协议) - SDN中控制数据转发的核心协议\nReinforcement Learning (强化学习) - 通过试错优化决策的AI方法",
        "abstract": "Software-defined networking (SDN) is a centralized, dynamic, and programmable network management technology that enables flexible traffic control and scalability. SDN facilitates network administration through a centralized view of the underlying physical topology; tampering with this topology view can result in catastrophic damage to network management and security. To underscore this issue, we introduce MARIONETTE, a new topology poisoning technique that manipulates OpenFlow link discovery packet forwarding to alter topology information. Our approach exposes an overlooked yet widespread attack vector, distinguishing itself from traditional link fabrication attacks that tamper, spoof, or relay discovery packets at the data plane. Unlike localized attacks observed in existing methods, our technique introduces a globalized topology poisoning attack that leverages control privileges. MARIONETTE implements a reinforcement learning algorithm to compute a poisoned topology target, and injects flow entries to achieve a long-lived stealthy attack. Our evaluation shows that MARIONETTE successfully attacks five open-source controllers and nine OpenFlow-based discovery protocols. MARIONETTE overcomes the state-of-the-art topology poisoning defenses, showcasing a new class of topology poisoning that initiates on the control plane. This security vulnerability was ethically disclosed to OpenDaylight, and CVE-2024-37018 has been assigned.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690345",
        "pub_year": "2024",
        "theme_label": "网络与系统安全"
    },
    {
        "title": "Evolving Network Security in the Era of Network Programmability",
        "authors": "Chen, Mingming",
        "keywords": "Software-Defined Networking (软件定义网络) - 网络架构与安全控制\nNetwork Security Policy (网络安全策略) - 安全规则与漏洞防护\nP4 Programming for Network Monitoring (P4编程用于网络监控) - 可编程数据面安全增强",
        "abstract": "Software-defined networking (SDN) is a centralized network architecture enabling dynamic, programmable, and flexible network management, which advances technologies like network security. However, it also introduces new vulnerabilities due to the segregation of data, control, and application planes, creating additional attack surfaces and security gaps from the increased complexity of programmability, flexibility, and scalability.To empower network security with SDN, we develop a coordinated sampling strategy using P4 programming for adaptive network monitoring. Additionally, we uncover a flow entry-induced topology poisoning attack to highlight security gaps from unplanned module integration. Finally, we propose to fortify the SDN control plane by generalizing SDN security policies and fuzzing it to uncover unknown vulnerabilities.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690859",
        "pub_year": "2024",
        "theme_label": "3.1 网络与系统安全体系结构"
    },
    {
        "title": "The Janus Interface: How Fine-Tuning in Large Language Models Amplifies the Privacy Risks",
        "authors": "Chen, Xiaoyi; Tang, Siyuan; Zhu, Rui; Yan, Shijun; Jin, Lei; Wang, Zihao; Su, Liya; Zhang, Zhikun; Wang, XiaoFeng; Tang, Haixu",
        "keywords": "Privacy Leakage (隐私泄露) - 大模型训练数据中的敏感信息暴露\nFine-Tuning Interface (微调接口) - 利用模型微调机制实施攻击的途径\nLanguage Model Attack (语言模型攻击) - 针对大语言模型的隐私提取攻击方法",
        "abstract": "The rapid advancements of large language models (LLMs) have raised public concerns about the privacy leakage of personally identifiable information (PII) within their extensive training datasets. Recent studies have demonstrated that an adversary could extract highly sensitive privacy data from the training data of LLMs with carefully designed prompts. However, these attacks suffer from the model's tendency to hallucinate and catastrophic forgetting (CF) in the pre-training stage, rendering the veracity of divulged PIIs negligible. In our research, we propose a novel attack, Janus, which exploits the fine-tuning interface to recover forgotten PIIs from the pre-training data in LLMs. We formalize the privacy leakage problem in LLMs and explain why forgotten PIIs can be recovered through empirical analysis on open-source language models. Based upon these insights, we evaluate the performance of Janus on both open-source language models and two latest LLMs, i.e., GPT-3.5-Turbo and LLaMA-2-7b. Our experiment results show that Janus amplifies the privacy risks by over 10 times in comparison with the baseline and significantly outperforms the state-of-the-art privacy extraction attacks including prefix attacks and in-context learning (ICL). Furthermore, our analysis validates that existing fine-tuning APIs provided by OpenAI and Azure AI Studio are susceptible to our Janus attack, allowing an adversary to conduct such an attack at a low cost.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690325",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Catch Me if You Can: Detecting Unauthorized Data Use in Training Deep Learning Models",
        "authors": "Chen, Zitao",
        "keywords": "Membership Inference (成员推理攻击) - 推断数据是否参与训练\nData Provenance Tracking (数据溯源追踪) - 追踪数据使用来源\nModel Memorization (模型记忆效应) - 模型对数据的记忆程度",
        "abstract": "The rise of deep learning (DL) has led to a surging demand for training data, which incentivizes the creators of DL models to trawl through the Internet for training materials. Meanwhile, users often have limited control over whether their data (e.g., facial images) are used to train DL models without their consent, which has engendered pressing concerns.In this work, we propose a technique that can support ordinary users to detect the unauthorized use of their data in training DL models. Our work is built upon membership inference (MI) attacks, a prominent class of attacks that aim to infer whether a sample was used to train the model, and it is known that the ability to perform accurate MI on a specific sample is directly related to how well the model memorizes it.Therefore, our idea is to guide the users to inject a small amount of targeted changes to their own data, which can be strongly memorized by the model trained on them. The users can then perform MI to detect whether the suspect model exhibits strong memorization effect on their specially-marked data. Preliminary results illustrate that our technique is able to support the users to reliably trace the provenance of their data with high true positive rate and low false positive rate.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690858",
        "pub_year": "2024",
        "theme_label": "人工智能安全"
    },
    {
        "title": "Attacks Against the IND-CPAD Security of Exact FHE Schemes",
        "authors": "Cheon, Jung Hee; Choe, Hyeongmin; Passelegue, Alain; Stehle, Damien; Suvanto, Elias",
        "keywords": "Fully Homomorphic Encryption (全同态加密) - 支持密文直接计算\nIND-CPA(D) Security (选择性密文不可区分性安全) - 抗选择性解密攻击\nCorrectness Vulnerability (正确性漏洞) - 利用解密错误实施攻击",
        "abstract": "A recent security model for fully homomorphic encryption (FHE), called IND-CPA(D) security and introduced by Li and Micciancio [Eurocrypt'21], strengthens IND-CPA security by giving the attacker access to a decryption oracle for ciphertexts for which it should know the underlying plaintexts. This includes ciphertexts that it (honestly) encrypted and those obtained from the latter by evaluating circuits that it chose. Li and Micciancio singled out the CKKS FHE scheme for approximate data [Asiacrypt'17] by giving an IND-CPA(D) attack on it and claiming that IND-CPA security and IND-CPA(D) security coincide for exact FHE schemes.We correct the widespread belief according to which IND-CPA(D) attacks are specific to approximate homomorphic computations. Indeed, the equivalency formally proved by Li and Micciancio assumes that the schemes have a negligible probability of incorrect decryption. However, almost all competitive implementations of exact FHE schemes give away strong correctness by analyzing correctness heuristically and allowing noticeable probabilities of incorrect decryption. We exploit this imperfect correctness to mount efficient non-adaptive indistinguishability and key-recovery attacks against all major exact FHE schemes. We illustrate their strength by implementing them for BFV using OpenFHE and simulating an attack for the default parameter set of the CGGI implementation of TFHE-rs (the attack experiment is too expensive to be run on commodity desktops, because of the cost of CGGI bootstrapping). Our attacks extend to CKKS for discrete data, and threshold versions of the exact FHE schemes, when the correctness is similarly loose.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690341",
        "pub_year": "2024",
        "theme_label": "密码学及应用"
    },
    {
        "title": "Quarantined-TreeKEM: A Continuous Group Key Agreement for MLS, Secure in Presence of Inactive Users",
        "authors": "Chevalier, Celine; Lebrun, Guirec; Martinelli, Ange; Taleb, Abdul Rahman",
        "keywords": "Continuous Group Key Agreement (连续群密钥协商) - 群组密钥动态更新机制\nPost-Compromise Security (抗泄露安全) - 密钥泄露后仍能保障安全\nSecret Sharing Scheme (秘密共享方案) - 分布存储密钥提升安全性",
        "abstract": "The recently standardized secure group messaging protocol Messaging Layer Security (MLS) is designed to ensure asynchronous communications within large groups, with an almost-optimal communication cost and the same security level as point-to-point secure messaging protocols such as Signal. In particular, the core sub-protocol of MLS, a Continuous Group Key Agreement (CGKA) called TreeKEM, must generate a common group key that respects the fundamental security properties of post-compromise security and forward secrecy which mitigate the effects of user corruption over time.Most research on CGKAs has focused on how to improve these two security properties. However, post-compromise security and forward secrecy require the active participation of respectively all compromised users and all users within the group. Inactive users - who remain offline for long periods - do not update anymore their encryption keys and therefore represent a vulnerability for the entire group. This issue has already been identified in the MLS standard, but no solution, other than expelling these inactive users after some disconnection time, has been found.We propose here a CGKA protocol based on TreeKEM and fully compatible with the MLS standard, that implements a quarantine mechanism for the inactive users in order to mitigate the risk induced by these users during their inactivity period and before they are removed from the group. That mechanism indeed updates the inactive users' encryption keys on their behalf and secures these keys with a secret sharing scheme. If some of the inactive users eventually reconnect, their quarantine stops and they are able to recover all the messages that were exchanged during their offline period. Our Quarantined-TreeKEM protocol thus increases the security of original TreeKEM, with a very limited - and sometimes negative - communication overhead.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690265",
        "pub_year": "2024",
        "theme_label": "密码学及应用"
    },
    {
        "title": "I Had Sort of a Sense that IWas Always BeingWatched ... Since I Was: Examining Interpersonal Discomfort From Continuous Location-Sharing Applications",
        "authors": "Childs, Kevin; Gibson, Cassidy; Crowder, Anna; Warren, Kevin; Stillman, Carson; Redmiles, Elissa M.; Jain, Eakta; Traynor, Patrick; Butler, Kevin R. B.",
        "keywords": "Continuous Location Sharing (连续位置共享) - 地理位置实时共享应用\nInterpersonal Discomfort (人际不适感) - 人际关系中的心理不安\nPrivacy Concerns (隐私担忧) - 对个人信息泄露的忧虑",
        "abstract": "Continuous location sharing (CLS) applications are widely used for safety and social convenience. However, these applications have privacy concerns that can be used for control and harm. To understand user concerns, we performed the largest user study of CLS application usage performed to date, with 1500 of 3000 users indicating they use CLS applications and 896 of these users completing surveys. From survey responses, we conducted 23 interviews with participants who had uncomfortable experiences. With these interviews, we perform thematic analysis grounded by sociological frameworks of power dynamics and social exchange theory. We observe that CLS application users face discomfort related to three primary categories that build on each other: (1) overstepped boundaries, (2) continued discomfort, and (3) lifestyle-impacting behaviors. With this foundational understanding, we suggest features that aim to reduce relationship imbalances that CLS applications enable. Our resulting study demonstrates that CLS applications contribute to interpersonal discomfort, highlighting the need for design changes.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690342",
        "pub_year": "2024",
        "theme_label": "人的安全行为与管理"
    },
    {
        "title": "Fast and Accurate Homomorphic Softmax Evaluation",
        "authors": "Cho, Wonhee; Hanrot, Guillaume; Kim, Taeseong; Park, Minje; Stehle, Damien",
        "keywords": "Homomorphic Encryption (同态加密) - 隐私保护下的密文计算\nNeural Network Inference (神经网络推理) - 加密数据上的模型推断\nSoftmax Function Evaluation (Softmax函数评估) - 神经网络关键激活函数计算\n选定的主题标签名称",
        "abstract": "Homomorphic encryption is one of the main solutions for building secure and privacy-preserving solutions for Machine Learning as a Service, a major challenge in a society where AI becomes more and more pervasive. This motivates the development of homomorphic algorithms for the main building blocks of AI, typically for the components of the various types of neural networks architectures.Among those components, we focus on the Softmax function, defined by Softmax(x) = (exp(x(i))/Sigma(n)(j=1) exp(x(j)))(1 <= i <= n). This function is deemed to be one of the most difficult to evaluate homomorphically, because of its multivariate nature and of the very large range of values for exp(x(i)). The available homomorphic algorithms remain restricted, especially in large dimensions, while important applications such as Large Language Models (LLM) require computing Softmax over large dimensional vectors. Our algorithm has strong scalability properties in terms of range and dimension while maintaining very good numerical accuracy. In terms of multiplicative depth of the computation (a suitable measure of cost for homomorphic algorithms), our algorithm achieves.. (log..) complexity for a fixed range of inputs, where.. is the Softmax dimension.Our algorithm is especially adapted to the situation where we must compute many Softmax at the same time, for instance, in the LLM situation. In that case, assuming that all Softmax calls are packed into m ciphtertexts, the asymptotic amortized multiplicative depth cost per ciphertext is, again over a fixed range, O(1 + m/N) for N the homomorphic ring degree (typically N = 2(16), so that we have N >> m in practice).The main ingredient of our algorithms is a normalize-and-square strategy, which manages to interlace the (numerically unstable) exponential computation over a large range and (very expensive) normalization, decomposing both in stabler and cheaper smaller steps.We have implemented our algorithms using the HEaaN implementation of the CKKS HE system. Comparing ourselves to the state of the art, our experiments show, in practice, a gain of a factor 2.5 to 8 compared to state of the art solutions.These experiments demonstrate good accuracy (around 16-bit precision in the worst case, around 20 on average) and support the linear behavior in the dimension. The many-ciphertexts version allows us to compute 8192 Softmax of dimension 256 in parallel in 486s (single-thread CPU), corresponding to an amortized 0.06s per Softmax call. All Softmax calls of the 32-layers LLaMa large language model (7B version) with context length 128 on an RTX-6000 GPU take around 1.5 minutes, and the final Softmax call in dimension 32768 for token generation takes less than 3 seconds. This suggests that near-practicality may be accessible with dedicated hardware.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670369",
        "pub_year": "2024",
        "theme_label": "6.3 同态加密"
    },
    {
        "title": "Poster: Privacy Norms for Fertility Data in the Roe v. Wade era",
        "authors": "Chown, Zander; Prasad, Aarathi",
        "keywords": "Fertility Data (生育数据) - 健康隐私信息\nPrivacy Norms (隐私规范) - 行为准则框架\nUser Concerns (用户担忧) - 数据安全感知",
        "abstract": "This poster presents results from a study to better understand the opinions and concerns actual or potential users of fertility-tracking apps have with regards to privacy and disclosure of their data. We expect these results will guide the creation of contextual norms that the apps should abide by to protect user privacy.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691406",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "A Causal Explainable Guardrails for Large Language Models",
        "authors": "Chu, Zhixuan; Wang, Yan; Li, Longfei; Wang, Zhibo; Qin, Zhan; Ren, Kui",
        "keywords": "Causal Analysis (因果分析) - 探究变量间因果关系\nAdversarial Learning (对抗学习) - 利用对抗样例提升鲁棒性\nBias Mitigation (偏差缓解) - 减少模型中的语义偏见",
        "abstract": "Large Language Models (LLMs) have shown impressive performance in natural language tasks, but their outputs can exhibit undesirable attributes or biases. Existing methods for steering LLMs toward desired attributes often assume unbiased representations and rely solely on steering prompts. However, the representations learned from pre-training can introduce semantic biases that influence the steering process, leading to suboptimal results. We propose LLMGuardrail, a novel framework that incorporates causal analysis and adversarial learning to obtain unbiased steering representations in LLMs. LLMGuardrail systematically identifies and blocks the confounding effects of biases, enabling the extraction of unbiased steering representations. Experiments demonstrate LLM-Guardrail's effectiveness in steering LLMs toward desired attributes while mitigating biases. Our work contributes to developing safe and reliable LLMs that align with desired attributes.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690217",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "On the Tight Security of the Double Ratchet",
        "authors": "Collins, Daniel; Riepel, Doreen; Tran, Si An Oliver",
        "keywords": "Double Ratchet (双棘轮协议) - 密钥协商与消息加密机制\nSecurity Bound (安全界) - 安全性证明的量化分析\nKey Encapsulation Mechanism (密钥封装机制) - 公钥加密中的密钥传输方案\n选定的主题标签名称",
        "abstract": "The Signal Protocol is a two-party secure messaging protocol used in applications such as Signal, WhatsApp, Google Messages and Facebook Messenger and is used by billions daily. It consists of two core components, one of which is the Double Ratchet protocol that has been the subject of a line of work that aims to understand and formalise exactly what security it provides. Existing models capture strong guarantees including resilience to state exposure in both forward security (protecting past secrets) and post-compromise security (restoring security), adaptive state corruptions, message injections and out-of-order message delivery. Due to this complexity, prior work has failed to provide security guarantees that do not degrade in the number of interactions, even in the single-session setting.Given the ubiquity of the Double Ratchet in practice, we explore tight security bounds for the Double Ratchet in the multi-session setting. To this end, we revisit the modelling of Alwen, Coretti and Dodis (EUROCRYPT 2019) who decompose the protocol into modular, abstract components, notably continuous key agreement (CKA) and forward-secure AEAD (FS-AEAD). To enable a tight security proof, we propose a CKA security model that provides one-way security under key checking attacks. We show that multisession security of the Double Ratchet can be tightly reduced to the multi-session security of CKA and FS-AEAD, capturing the same strong security guarantees as Alwen et al.Our result improves upon the bounds of Alwen et al. in the random oracle model. Even so, we are unable to provide a completely tight proof for the Double Ratchet based on standard Diffie-Hellman assumptions, and we conjecture it is not possible. We thus go a step further and analyse CKA based on key encapsulation mechanisms (KEMs). In contrast to previous works, our new analysis allows for tight constructions based on the DDH and post-quantum assumptions.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690360",
        "pub_year": "2024",
        "theme_label": "2.2.1 密码体制安全模型"
    },
    {
        "title": "Keeping Up with the KEMs: Stronger Security Notions for KEMs and Automated Analysis of KEM-based Protocols",
        "authors": "Cremers, Cas; Dax, Alexander; Medinger, Niklas",
        "keywords": "Key Encapsulation Mechanism (KEM) - 密钥封装机制\nSecurity Notions (安全概念) - 安全模型定义\nSymbolic Analysis (符号分析) - 协议自动验证",
        "abstract": "Key Encapsulation Mechanisms (KEMs) are a critical building block for hybrid encryption and modern security protocols, notably in the post-quantum setting. Given the asymmetric public key of a recipient, the primitive establishes a shared secret key between sender and recipient. In recent years, a large number of abstract designs and concrete implementations of KEMs have been proposed, e.g., in the context of the NIST process for post-quantum primitives.In this work, we (i) establish stronger security notions for KEMs, and (ii) develop a symbolic analysis method to analyze security protocols that use KEMs. First, we generalize existing security notions for KEMs in the computational setting, introduce several stronger security notions and prove their relations. Our new properties formalize in which sense outputs of the KEM uniquely determine, i.e., bind, other values. Our new binding properties can be used, e.g., to prove the absence of attacks that were not captured by prior security notions. Among these, we identify a new class of attacks that we coin re-encapsulation attacks.Second, we develop a family of fine-grained symbolic models that correspond to our hierarchy of computational security notions, and are suitable for the automated analysis of KEM-based security protocols. We encode our models as a library in the framework of the Tamarin prover. Given a KEM-based protocol, our approach can automatically derive the minimal binding properties required from the KEM; or, if also given a concrete KEM, can analyze if the protocol meets its security goals. In case studies, Tamarin automatically discovers, e.g., that the key exchange protocol proposed in the original Kyber paper [12] requires stronger properties from the KEM than were proven in [12].",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670283",
        "pub_year": "2024",
        "theme_label": "密码学及应用"
    },
    {
        "title": "Asynchronous Consensus without Trusted Setup or Public-Key Cryptography",
        "authors": "Das, Sourav; Duan, Sisi; Liu, Shengqi; Momose, Atsuki; Ren, Ling; Shoup, Victor",
        "keywords": "Asynchronous Consensus (异步共识) - 分布式系统达成一致\nByzantine Fault Tolerance (拜占庭容错) - 抵抗恶意节点的协议设计\nCryptographic Hash Functions (密码学哈希函数) - 安全通信的基础工具\n选定的主题标签名称",
        "abstract": "Byzantine consensus is a fundamental building block in distributed cryptographic problems. Despite decades of research, most existing asynchronous consensus protocols require a strong trusted setup and expensive public-key cryptography. In this paper, we study asynchronous Byzantine consensus protocols that do not rely on a trusted setup and do not use public-key cryptography such as digital signatures. We give an Asynchronous Common Subset (ACS) protocol whose security is only based on cryptographic hash functions modeled as a random oracle. Our protocol has O(kappa n(3)) total communication and runs in expected O(1) rounds. The fact that we use only cryptographic hash functions also means that our protocol is post-quantum secure. The minimal use of cryptography and the small number of rounds make our protocol practical. We implement our protocol and evaluate it in a geo-distributed setting with up to 128 machines. Our experimental evaluation shows that our protocol is more efficient than the only other setup-free consensus protocol that has been implemented to date. En route to our asynchronous consensus protocols, we also introduce new primitives called asynchronous secret key sharing and cover gather, which may be of independent interest.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670327",
        "pub_year": "2024",
        "theme_label": "8.1 共识机制及安全"
    },
    {
        "title": "Poster: A Secure Multiparty Computation Platform for Squeaky-Clean Data Rooms",
        "authors": "Dayama, Pankaj; Pandit, Vinayaka; Patranabis, Sikhar; Singh, Abhishek; Singh, Nitin",
        "keywords": "Secure Multiparty Computation (安全多方计算) - 多方协同计算隐私保护\nHomomorphic Encryption (同态加密) - 数据加密后仍可计算\nPrivacy-Preserving Data Collaboration (隐私保护数据协作) - 保障隐私的数据合作\n选定的主题标签名称",
        "abstract": "Modern approaches for multiparty secure collaboration must strike the right balance between rich analytics and requisite data privacy guarantees, especially in the face of new regulations. While cryptographic technologies such as fully homomorphic encryption (FHE) and secure multiparty computation (MPC) provide strong, provable security guarantees as standalone tools, deploying them in practice throws up a myriad of challenges, including usability constraints and lack of precise specification of privacy guarantees. In this work, we propose a novel framework for real-world deployment of cryptographic privacy preserving techniques that achieves the twin goals of practical usability in real-world setting and provable privacy guarantees from users' perspective. To this end, we formalize the notion of a secure computation platform (SCP) for privacy preserving data collaboration, and introduce a model for precise specification of privacy guarantees for multiparty workflows. We then describe abstractions of a set of cryptoprimitives, that are usable by non-experts in cryptography. We present two demo workflows that empirically validate our claims, and serve as potential building blocks for the development of squeaky-clean data rooms with practical performance and privacy guarantees.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691371",
        "pub_year": "2024",
        "theme_label": "6.2 安全多方计算"
    },
    {
        "title": "Poster: Byzantine Discrepancy Attacks against Calendar, Set-intersection and Nations",
        "authors": "Desmedt, Yvo; Kavousi, Alireza; Abadi, Aydin",
        "keywords": "Byzantine Attack (拜占庭攻击) - 分布式系统容错核心问题\nPrivate Set Intersection (私有集合交集) - 隐私保护下的集合运算\nCommunication Security (通信安全) - 保障信息传输过程安全",
        "abstract": "Nowadays Communication Security usually refers to digital communication and in particular via the Internet. We explain why the topic should be broadened to include any communication, in particular when done in person, e.g., with co-authors, colleagues, reporters, etc.Thousands of papers have been written on blockchain, and consensus. Despite this, the problem of Byzantine attack has been ignored in some important apps! One of these examples is (Outlook) Calendar. Moreover, the Byzantine attack can also be used in the political world. We explain how using it may undermine the security of nations. Finally, we observe that topics on which a lot of research has been done, such as Private Set Intersection have ignored the problem of Byzantine attacks.Although the Byzantine general problem is typically described in a peer-to-peer setting, we show that it can also occur in other scenarios.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691379",
        "pub_year": "2024",
        "theme_label": "网络与系统安全"
    },
    {
        "title": "Protoss Protocol for Tight Optimal Symmetric Security",
        "authors": "Di Giandomenico, Emanuele; Li, Yong; Schage, Sven",
        "keywords": "Balanced PAKE Protocol (平衡PAKE协议) - 密钥交换协议设计\nOptimal Communication Efficiency (最优通信效率) - 降低传输开销\nTight Security Reduction (紧密安全归约) - 提升安全性保障",
        "abstract": "We present Protoss, a new balanced PAKE protocol with optimal communication efficiency. Messages are only 160 bits long and the computational complexity is lower than all previous approaches. Our protocol is proven secure in the random oracle model and features a security proof in a strong security model with multiple parties and multiple sessions while allowing for generous attack queries including multiple Test-queries. Moreover, the proof is in the practically relevant single-bit model (that is harder to achieve than the multiple-bit model) and tightly reduces to the Strong Square Diffie-Hellman assumption (SSQRDH). This allows for very efficient, theoretically-sound instantiations and tight compositions with symmetric primitives.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690252",
        "pub_year": "2024",
        "theme_label": "密码学及应用"
    },
    {
        "title": "Poster: DoHunter: A feature fusion-based LLM for DoH tunnel detection",
        "authors": "Diao, Jiawen; Zhao, Shengmin; Xie, Jianguo; Xie, Rongna; Shi, Guozhen",
        "keywords": "DoH Tunnel Detection (DNS over HTTPS隧道检测) - 检测加密DNS中的隐蔽通信\nLLM-based Traffic Analysis (基于大语言模型的流量分析) - 利用LLM理解复杂加密流量模式\nFeature Fusion (特征融合) - 结合专家特征与模型提升检测精度\n选定的主题标签名称",
        "abstract": "DNS over HTTPS (DoH) reduces the risk of privacy leakage of DNS queries, but it also provides a covert communication channel for malicious activities. In this paper, we propose a method for malicious encrypted traffic identification, which harnesses the advanced context comprehension of Large Language Model (LLM) and incorporates expert features to detect anomalies. The evaluation results show that the method proposed in this paper can not only identify common and emerging malicious DoH tunnel tools such as dns2tcp, iodine, and dnstt, but also identify weaponized DoH traffic within a real APT attack, with a recall of 0.9995.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691400",
        "pub_year": "2024",
        "theme_label": "4.9 加密流量识别与密态对抗"
    },
    {
        "title": "Novel Privacy Attacks and Defenses Against Neural Networks",
        "authors": "Dibbo, Sayanton V.",
        "keywords": "Model Inversion Attack (模型反转攻击) - 通过模型推断训练数据\nPrivacy Defense (隐私防御) - 防御隐私泄露技术\nNeural Network Security (神经网络安全) - 保障模型隐私与安全\n选定的主题标签名称",
        "abstract": "This dissertation comprises five papers that focus on a novel paradigm of privacy attack, i.e., model inversion (MI) attack, where the adversarial goal is to infer or reconstruct training samples. In particular, these works are aligned with investigating MI privacy attacks, designing novel realistic MI attacks under restricted realistic capabilities, and introducing novel robust defense techniques against these attacks. At first, we focus on the systematization of MI attacks from the literature review (IEEE CSF). This opened up ways to investigate MI attacks on the tabular dataset. We developed novel MI attacks for inferring sensitive private training data, published in USENIX Security. Then, we worked on exploring MI attacks with limited adversarial capabilities (IEEE SaTML), i.e., when adversaries do not have access to the same data distributions as model training data. All these streams of work on privacy attack designing enabled the design of novel defenses against MI attacks. We have developed a novel sparse coding architecture (SCA), which shows 1.1-18.3 times more robustness against MI attacks while not significantly compromising model accuracy. This exciting work has just been published at ECCV 2024 this year and inspires us to improve the defense further by designing systematic techniques to drop highly sensitive features during training that can also provide provable privacy bounds.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690863",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Poster: libdebug, Build Your Own Debugger for a Better (Hello) World",
        "authors": "Digregorio, Gabriele; Bertolini, Roberto Alessandro; Panebianco, Francesco; Polino, Mario",
        "keywords": "Programmatic Debugging (程序化调试) - 自动化调试工具开发\nUserland Binary Analysis (用户态二进制分析) - 分析非内核级程序行为\nReverse Engineering Tool (逆向工程工具) - 支持安全与软件逆向分析\n选定的主题标签名称",
        "abstract": "Automated debugging, long pursued in a variety of fields from software engineering to cybersecurity, requires a framework that offers the building blocks for a programmable debugging workflow. However, existing debuggers are primarily tailored for human interaction, and those designed for programmatic debugging focus on kernel space, resulting in limited functionality in userland. To fill this gap, we introduce libdebug, a Python library for programmatic debugging of userland binary executables. libdebug offers a user-friendly API that enables developers to build custom debugging tools for various applications, including software engineering, reverse engineering, and software security. It is released as an open-source project, along with comprehensive documentation to encourage use and collaboration across the community. We demonstrate the versatility and performance of libdebug through case studies and benchmarks, all of which are publicly available. We find that the median latency of syscall and breakpoint handling in libdebug is 3 to 4 times lower compared to that of GDB.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691391",
        "pub_year": "2024",
        "theme_label": "3.8.1 漏洞挖掘与逆向分析"
    },
    {
        "title": "Understanding Implosion in Text-to-Image Generative Models",
        "authors": "Ding, Wenxin; Li, Cathy Y.; Shan, Shawn; Zhao, Ben Y.; Zheng, Haitao",
        "keywords": "Text-to-Image Generative Models (文本到图像生成模型) - 生成模型安全研究\nPoisoning Attacks (投毒攻击) - 恶意数据污染训练过程\nCross-Attention Mechanism (交叉注意力机制) - 多模态对齐与关联建模",
        "abstract": "Recent works show that text-to-image generative models are surprisingly vulnerable to a variety of poisoning attacks. Empirical results find that these models can be corrupted by altering associations between individual text prompts and associated visual features. Furthermore, a number of concurrent poisoning attacks can induce model implosion, where the model becomes unable to produce meaningful images for unpoisoned prompts. These intriguing findings highlight the absence of an intuitive framework to understand poisoning attacks on these models.In this work, we establish the first analytical framework on robustness of image generative models to poisoning attacks, by modeling and analyzing the behavior of the cross-attention mechanism in latent diffusion models. We model cross-attention training as an abstract problem of supervised graph alignment and formally quantify the impact of training data by the hardness of alignment, measured by an Alignment Difficulty (AD) metric. The higher the AD, the harder the alignment. We prove that AD increases with the number of individual prompts (or concepts) poisoned. As AD grows, the alignment task becomes increasingly difficult, yielding highly distorted outcomes that frequently map meaningful text prompts to undefined or meaningless visual representations. As a result, the generative model implodes and outputs random, incoherent images at large. We validate our analytical framework through extensive experiments, and we confirm and explain the unexpected (and unexplained) effect of model implosion while producing new, unforeseen insights. Our work provides a useful tool for studying poisoning attacks against diffusion models and their defenses.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690205",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Scalable Equi-Join Queries over Encrypted Database",
        "authors": "Du, Kai; Wang, Jianfeng; Wu, Jiaojiao; Wang, Yunling",
        "keywords": "Encrypted Database (加密数据库) - 支持加密数据的安全存储与查询\nEqui-Join Query (等值连接查询) - 实现多表安全高效数据关联\nScalable Join Protocol (可扩展连接协议) - 提升多表连接性能与适用性\n选定的主题标签名称",
        "abstract": "Secure join queries over encrypted databases, the most expressive class of SQL queries, have attracted extensive attention recently. The state-of-the-art JXT (Jutla et al. ASIACRYPT 2022) enables join queries on encrypted relational databases without pre-computing all possible joins. However, JXT can merely support join queries over two tables (in encrypted databases) with some high-entropy join attributes.In this paper, we propose an equi-join query protocol over two tables dubbed JXT+, that allows the join attributes with arbitrary names instead of JXT requiring the identical name for join attributes. JXT+ reduces the query complexity from.. (l(1) center dot l(2)) to.. (l(1)) as compared to JXT, where l(1) and l(2) denote the numbers of matching records in two tables respectively. Furthermore, we present JXT++, the first equi-join queries across three or more tables over encrypted databases without pre-computation. Specifically, JXT++ supports joins of arbitrary attributes, i.e., all attributes (even low-entropy) can be candidates for join, while JXT requires high-entropy join attributes. In addition, JXT++ can alleviate sub-query leakage on three or more tables, which hides the leakage from the matching records of two-table join.Finally, we implement and compare our proposed schemes with the state-of-the-art JXT. The experimental results demonstrate that both of our schemes are superior to JXT in search and storage costs. In particular, JXT+ (resp., JXT++) brings a saving of 49% (resp., 68%) in server storage cost and achieves a speedup of 51.7x (resp., 54.3x) in search latency.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690377",
        "pub_year": "2024",
        "theme_label": "密码学及应用"
    },
    {
        "title": "Non-Transferable Anonymous Tokens by Secret Binding",
        "authors": "Durak, F. Betul; Marco, Laurane; Talayhan, Abdullah; Vaudenay, Serge",
        "keywords": "Anonymous Tokens (匿名凭证) - 匿名访问控制机制\nNon-Transferability (不可转让性) - 防止凭证非法转移\nSecret Binding (秘密绑定) - 绑定身份与凭证\n选定的主题标签名称",
        "abstract": "Non-transferability (NT) is a security notion which ensures that credentials are only used by their intended owners. Despite its importance, it has not been formally treated in the context of anonymous tokens (AT) which are lightweight anonymous credentials. In this work, we consider a client who buys access tokens which are forbidden to be transferred although anonymously redeemed. We extensively study the trade-offs between privacy (obtained through anonymity) and security in AT through the notion of non-transferability. We formalise new security notions, design a suite of protocols with various flavors of NT, prove their security, and implement the protocols to assess their efficiency. Finally, we study the existing anonymous credentials which offer NT, and show that they cannot automatically be used as AT without security and complexity implications.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670338",
        "pub_year": "2024",
        "theme_label": "2.5 密码应用技术"
    },
    {
        "title": "Batching-Efficient RAM using Updatable Lookup Arguments",
        "authors": "Dutta, Moumita; Ganesh, Chaya; Patranabis, Sikhar; Prakash, Shubh; Singh, Nitin",
        "keywords": "RAM (随机存取存储器) - 可高效验证计算的内存模型\nLookup Arguments (查找论证) - 支持高效数据查询与更新\nSublinear Complexity (次线性复杂度) - 算法成本低于线性增长",
        "abstract": "RAM (random access memory) is an important primitive in verifiable computation. In this paper, we focus on realizing RAM with efficient batching property, i.e, proving a batch of.. updates on a RAM of size.. while incurring a cost that is sublinear in N. Classical approaches based on Merkle-trees or address ordered transcripts to model RAM correctness are either concretely inefficient, or incur linear overhead in the size of the RAM. Recent works explore cryptographic accumulators based on unknown-order groups (RSA, class-groups) to model the RAM state. While recent RSA accumulator based approaches offer significant improvement over classical methods, they incur linear overhead in the size of the accumulated set to compute witnesses, as well as prohibitive constant overheads.We realize a batching-efficient RAM with superior asymptotic and concrete costs as compared to existing approaches. Towards this: (i) we build on recent constructions of lookup arguments to allow efficient lookups even in presence of table updates, and (ii) we realize a variant of sub-vector relation addressed in prior works, which we call committed index lookup. We combine the two building blocks to realize batching-efficient RAM with sublinear dependence on size of the RAM. Our construction incurs an amortized proving cost of (O) over tilde (m log m + root mN) for a batch of m updates on a RAM of size N. Our results also benefit the recent arguments for sub-vector relation, by enabling them to be efficient in presence of updates to the table. We believe that this is a contribution of independent interest. We implement our solution to evaluate its concrete efficiency. Our experiments show that it offers significant improvement over existing works on batching-efficient accumulators/RAMs, with a substantially reduced resource barrier.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670356",
        "pub_year": "2024",
        "theme_label": "密码学及应用"
    },
    {
        "title": "Secret Sharing with Snitching",
        "authors": "Dziembowski, Stefan; Faust, Sebastian; Lizurej, Tomasz; Mielniczuk, Marcin",
        "keywords": "Secret Sharing with Snitching (带告密的秘密共享) - 防止股东合谋泄密\nIndividual Cryptography (个体密码学) - 单机易多机难的计算任务\nMulti-Party Computation Security (多方计算安全) - 抵御恶意协议攻击\n选定的主题标签名称",
        "abstract": "We address the problem of detecting and punishing shareholder collusion in secret-sharing schemes. We do it in the recently proposed cryptographic model called individual cryptography (Dziembowski, Faust, and Lizurej, Crypto 2023), which assumes that there exist tasks that can be efficiently computed by a single machine but distributing this computation across multiple (mutually distrustful devices) is infeasible.Within this model, we introduce a novel primitive called secret sharing with snitching (SSS), in which each attempt to illegally reconstruct the shared secret.. results in a proof that can be used to prove such misbehavior (and, e.g., financially penalize the cheater on a blockchain). This holds in a very strong sense, even if the shareholders attempt not to reconstruct the entire secret.. but only learn some partial information about it. Our notion also captures the attacks performed using multiparty computation protocols (MPCs), i.e., those where the malicious shareholders use MPCs to compute partial information on S. The main idea of SSS is that any illegal reconstruction can be proven and punished, which suffices to discourage illegal secret reconstruction. Hence, our SSS scheme effectively prevents shareholders' collusion. We provide a basic definition of threshold (l -out-of-n) SSS. We then show how to construct it for t = n, and later, we use this construction to build an SSS scheme for an arbitrary...In order to prove the security of our construction, we introduce a generalization of the random oracle model (Bellare, Rogaway, CCS 1993), which allows modelling hash evaluations made inside MPC.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690296",
        "pub_year": "2024",
        "theme_label": "2.2.2 密码原语和范式"
    },
    {
        "title": "Multi-Verifier Zero-Knowledge Proofs for Any Constant Fraction of Corrupted Verifiers",
        "authors": "Escudero, Daniel; Polychroniadou, Antigoni; Song, Yifan; Weng, Chenkai",
        "keywords": "Multi-Verifier Zero-Knowledge (多验证者零知识证明) - 多方验证下的隐私保护协议\nPreprocessing Model (预处理模型) - 提升效率的离线计算阶段\nCorruption Tolerance (腐败容忍) - 容纳恶意合谋的安全机制",
        "abstract": "In this work we study the efficiency of Zero-Knowledge (ZK) arguments of knowledge, particularly exploring Multi-Verifier ZK (MVZK) protocols as a midway point between Non-Interactive ZK and Designated-Verifier ZK, offering versatile applications across various domains. We introduce a new MVZK protocol designed for the preprocessing model, allowing any constant fraction of verifiers to be corrupted, potentially colluding with the prover. Our contributions include the first MVZK over rings. Unlike recent prior works on fields in the dishonest majority case, our protocol demonstrates communication complexity independent of the number of verifiers, contrasting the linear complexity of previous approaches. This key advancement ensures improved scalability and efficiency. We provide an end-to-end implementation of our protocol. The benchmark shows that it achieves a throughput of 1.47 million gates per second for 64 verifiers with 50% corruption, and 0.88 million gates per second with 75% corruption.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670357",
        "pub_year": "2024",
        "theme_label": "密码学及应用"
    },
    {
        "title": "Password-Protected Key Retrieval with(out) HSM Protection",
        "authors": "Faller, Sebastian; Handirk, Tobias; Hesse, Julia; Horvath, Mate; Lehmann, Anja",
        "keywords": "Password-Protected Key Retrieval (密码保护的密钥检索) - 基于密码的安全密钥获取\nHardware Security Module (硬件安全模块) - 提供密钥存储与计算保护\nProvable Security (可证安全) - 形式化验证协议安全性\n选定的主题标签名称",
        "abstract": "Password-protected key retrieval (PPKR) enables users to store and retrieve high-entropy keys from a server securely. The process is bootstrapped from a human-memorizable password only, addressing the challenge of how end-users can manage cryptographic key material. The core security requirement is protection against a corrupt server, which should not be able to learn the key or offline-attack it through the password protection. PPKR is deployed at a large scale with the WhatsApp Backup Protocol (WBP), allowing users to access their encrypted messaging history when switching to a new device. Davies et al. (Crypto'23) formally analyzed the WBP, proving that it satisfies most of the desired security. The WBP uses the OPAQUE protocol for password-based key exchange as a building block and relies on the server using a hardware security module (HSM) for most of its protection. In fact, the security analysis assumes that the HSM is incorruptible - rendering most of the heavy cryptography in the WBP obsolete.In this work, we explore how provably secure and efficient PPKR can be built that either relies strongly on an HSM - but then takes full advantage of that - or requires less trust assumption for the price of more advanced cryptography. To this end, we expand the definitional work by Davies et al. to allow the analysis of PPKR with fine-grained HSM corruption, such as leakage of user records or attestation keys. For each scenario, we aim to give minimal PPKR solutions. For the strongest corruption setting, namely a fully corrupted HSM, we propose a protocol with a simpler design and better efficiency than the WBP. We also fix an attack related to client authentication that was identified by Davies et al.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690358",
        "pub_year": "2024",
        "theme_label": "2.3.2 密码协议设计与分析"
    },
    {
        "title": "Byzantine-Robust Decentralized Federated Learning",
        "authors": "Fang, Minghong; Zhang, Zifan; Hairi; Khanduri, Prashant; Liu, Jia; Lu, Songtao; Liu, Yuchen; Gong, Neil",
        "keywords": "Decentralized Federated Learning (去中心化联邦学习) - 基于对等网络的协同模型训练\nByzantine-Robustness (拜占庭容错) - 防御恶意节点攻击的能力\nPoisoning Attacks (投毒攻击) - 恶意模型破坏训练过程",
        "abstract": "Federated learning (FL) enables multiple clients to collaboratively train machine learning models without revealing their private training data. In conventional FL, the system follows the server-assisted architecture (server-assisted FL), where the training process is coordinated by a central server. However, the server-assisted FL framework suffers from poor scalability due to a communication bottleneck at the server, and trust dependency issues. To address challenges, decentralized federated learning (DFL) architecture has been proposed to allow clients to train models collaboratively in a serverless and peer-to-peer manner. However, due to its fully decentralized nature, DFL is highly vulnerable to poisoning attacks, where malicious clients could manipulate the system by sending carefully-crafted local models to their neighboring clients. To date, only a limited number of Byzantine-robust DFL methods have been proposed, most of which are either communication-inefficient or remain vulnerable to advanced poisoning attacks. In this paper, we propose a new algorithm called BALANCE (Byzantine-robust averaging through local similarity in decentralization) to defend against poisoning attacks in DFL. In BALANCE, each client leverages its own local model as a similarity reference to determine if the received model is malicious or benign. We establish the theoretical convergence guarantee for BALANCE under poisoning attacks in both strongly convex and non-convex settings. Furthermore, the convergence rate of BALANCE under poisoning attacks matches those of the state-of-the-art counterparts in Byzantine-free settings. Extensive experiments also demonstrate that BALANCE outperforms existing DFL methods and effectively defends against poisoning attacks.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670307",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Zero-Query Adversarial Attack on Black-box Automatic Speech Recognition Systems",
        "authors": "Fang, Zheng; Wang, Tao; Zhao, Lingchen; Zhang, Shenyi; Li, Bowen; Ge, Yunjie; Li, Qi; Shen, Chao; Wang, Qian",
        "keywords": "Zero-Query Adversarial Attack (零查询对抗攻击) - 无需查询的对抗样本攻击方法\nBlack-box Automatic Speech Recognition (黑盒自动语音识别) - 目标系统不可见的语音识别攻击\nTransfer-based Attack (基于迁移的攻击) - 利用代理模型生成可迁移对抗样本",
        "abstract": "In recent years, extensive research has been conducted on the vulnerability of ASR systems, revealing that black-box adversarial example attacks pose significant threats to real-world ASR systems. However, most existing black-box attacks rely on queries to the target ASRs, which is impractical when queries are not permitted. In this paper, we propose ZQ-Attack, a transfer-based adversarial attack on ASR systems in the zero-query black-box setting. Through a comprehensive review and categorization of modern ASR technologies, we first meticulously select surrogate ASRs of diverse types to generate adversarial examples. Following this, ZQ-Attack initializes the adversarial perturbation with a scaled target command audio, rendering it relatively imperceptible while maintaining effectiveness. Subsequently, to achieve high transferability of adversarial perturbations, we propose a sequential ensemble optimization algorithm, which iteratively optimizes the adversarial perturbation on each surrogate model, leveraging collaborative information from other models. We conduct extensive experiments to evaluate ZQ-Attack. In the over-the-line setting, ZQ-Attack achieves a 100% success rate of attack (SRoA) with an average signal-to-noise ratio (SNR) of 21.91dB on 4 online speech recognition services, and attains an average SRoA of 100% and SNR of 19.67dB on 16 open-source ASRs. In the over-the-air setting, ZQ-Attack also achieves a 100% SRoA with an average SNR of 15.77dB on 2 commercial intelligent voice control devices.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670309",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Real-World Universal zkSNARKs are Non-Malleable",
        "authors": "Faonio, Antonio; Fiore, Dario; Russo, Luigi",
        "keywords": "zkSNARKs (零知识简洁非交互式知识证明) - 隐私保护密码协议\nSimulation Extractability (模拟可提取性) - 安全性保证核心属性\nUniversal zkSNARKs (通用零知识证明系统) - 支持多方高效验证\n选定的主题标签名称",
        "abstract": "Simulation extractability is a strong security notion of zkSNARKs that guarantees that an attacker who produces a valid proof must know the corresponding witness, even if the attacker had prior access to proofs generated by other users. Notably, simulation extractability implies that proofs are non-malleable and is of fundamental importance for applications of zkSNARKs in distributed systems. In this work, we study sufficient and necessary conditions for constructing simulation-extractable universal zkSNARKs via the popular design approach based on compiling polynomial interactive oracle proofs (PIOP). Our main result is the first security proof that popular universal zkSNARKs, such as PLONK and Marlin, as deployed in the real world, are simulation-extractable. Our result fills a gap left from previous work (Faonio et al. TCC'23, and Kohlweiss et al. TCC'23) which could only prove the simulation extractability of the textbook versions of these schemes and does not capture their optimized variants, with all the popular optimization tricks in place, that are eventually implemented and deployed in software libraries.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690351",
        "pub_year": "2024",
        "theme_label": "2.1.2 计算数论"
    },
    {
        "title": "Scalable and Adaptively Secure Any-Trust Distributed Key Generation and All-hands Checkpointing",
        "authors": "Feng, Hanwen; Mai, Tiancheng; Tang, Qiang",
        "keywords": "Distributed Key Generation (分布式密钥生成) - 用于多方协同生成加密密钥\nAdaptive Security (自适应安全) - 安全机制动态抵御节点攻击\nBlockchain Checkpointing (区块链检查点) - 提升链安全性与状态一致性",
        "abstract": "The classical distributed key generation protocols (DKG) are resurging due to their widespread applications in blockchain. While efforts have been made to improve DKG communication, practical largescale deployments are still yet to come due to various challenges, including the heavy overhead (particularly broadcast) in adversarial cases. In this paper, we propose a practical DKG for DLog-based cryptosystems, which achieves (quasi-)linear computation and communication per-node cost with the help of a common coin, even in the face of the maximal amount of Byzantine nodes. Moreover, our protocol is secure against adaptive adversaries, which can corrupt less than half of all nodes. The key to our improvements lies in delegating the most costly operations to an Any-Trust group together with a set of techniques for adaptive security. Moreover, we present a generic transformer that enables us to efficiently deploy a conventional distributed protocol like our DKG, even when the participants have different weights.Our DKG leads to a fully practical instantiation of Filecoin's checkpointing mechanism, in which all validators of a Proof-ofStake (PoS) blockchain periodically run DKG and threshold signing to create checkpoints on Bitcoin, to enhance the security of the PoS chain. In comparison with the recent checkpointing approach of Babylon (Oakland, 2023), ours enjoys a significantly smaller cost of Bitcoin transaction fees. For 212 validators, our cost is merely 0.4% of that incurred by Babylon's approach.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690253",
        "pub_year": "2024",
        "theme_label": "8.1 共识机制及安全"
    },
    {
        "title": "Uncovering Gradient Inversion Risks in Practical Language Model Training",
        "authors": "Feng, Xinguo; Ma, Zhongkui; Wang, Zihan; Chegne, Eu Joe; Ma, Mengyao; Abuadbba, Alsharif; Bai, Guangdong",
        "keywords": "Gradient Inversion Attack (梯度反转攻击) - 联邦学习隐私威胁\nFederated Learning (联邦学习) - 分布式模型训练方法\nLanguage Model Privacy (语言模型隐私) - 文本数据隐私保护\n选定的主题标签名称",
        "abstract": "The gradient inversion attack has been demonstrated as a significant privacy threat to federated learning (FL), particularly in continuous domains such as vision models. In contrast, it is often considered less effective or highly dependent on impractical training settings when applied to language models, due to the challenges posed by the discrete nature of tokens in text data. As a result, its potential privacy threats remain largely underestimated, despite FL being an emerging training method for language models. In this work, we propose a domain-specific gradient inversion attack named Grab (gradient inversion with hybrid optimization). Grab features two alternating optimization processes to address the challenges caused by practical training settings, including a simultaneous optimization on dropout masks between layers for improved token recovery and a discrete optimization for effective token sequencing. Grab can recover a significant portion (up to 92.9% recovery rate) of the private training data, outperforming the attack strategy of utilizing discrete optimization with an auxiliary model by notable improvements of up to 28.9% recovery rate in benchmark settings and 48.5% recovery rate in practical settings. Grab provides a valuable step forward in understanding this privacy threat in the emerging FL training mode of language models.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690292",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Bytes to Schlep? Use a FEP: Hiding Protocol Metadata with Fully Encrypted Protocols",
        "authors": "Fenske, Ellis; Johnson, Aaron",
        "keywords": "Fully Encrypted Protocols (完全加密协议) - 隐藏元数据的通信协议\nMetadata Protection (元数据保护) - 保障通信内容特征不泄露\nProtocol Indistinguishability (协议不可区分性) - 协议类型难以被识别\n选定的主题标签名称",
        "abstract": "Fully Encrypted Protocols (FEPs) have arisen in practice as a technique to avoid network censorship. Such protocols are designed to produce messages that appear completely random. This design hides communications metadata, such as version and length fields, and makes it difficult to even determine what protocol is being used. Moreover, these protocols frequently support padding to hide the length of protocol fields and the contained message. These techniques have relevance well beyond censorship circumvention, as protecting protocol metadata has security and privacy benefits for all Internet communications. The security of FEP designs depends on cryptographic assumptions, but neither security definitions nor proofs exist for them. We provide novel security definitions that capture the metadata-protection goals of FEPs. Our definitions are given in both the datastream and datagram settings, which model the ubiquitous TCP and UDP interfaces available to protocol designers. We prove relations among these new notions and existing security definitions. We further present new FEP constructions and prove their security. Finally, we survey existing FEP candidates and characterize the extent to which they satisfy FEP security. We identify novel ways in which these protocols are identifiable, including their responses to the introduction of data errors and the sizes of their smallest protocol messages.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690198",
        "pub_year": "2024",
        "theme_label": "2.5 网络系统安全应用"
    },
    {
        "title": "ThorPIR: Single Server PIR via Homomorphic Thorp Shuffles",
        "authors": "Fisch, Ben; Lazzaretti, Arthur; Liu, Zeyu; Papamanthou, Charalampos",
        "keywords": "Private Information Retrieval (私有信息检索) - 保护用户查询隐私\nHomomorphic Encryption (同态加密) - 支持密文计算的加密方法\nThorp Shuffle (托普洗牌算法) - 用于轻量级安全混洗操作\n选定的主题标签名称",
        "abstract": "Private Information Retrieval (PIR) is a two player protocol where the client, given some query x is an element of [N], interacts with the server, which holds a N-bit string DB, in order to privately retrieve DB[x]. In this work, we focus on the single-server client-preprocessing model, initially proposed by Corrigan-Gibbs and Kogan (EUROCRYPT 2020), where the client and server first run a joint preprocessing algorithm, after which the client can retrieve elements from DB privately in time sublinear in N. Most known constructions of single-server client-preprocessing PIR follow one of two paradigms: They feature either (1) a linear-bandwidth offline phase where the client downloads the whole database from the server, or (2) a sublinear-bandwidth offline phase where however the server has to compute a large-depth (Omega(lambda)(N)) circuit under fully-homomorphic encryption (FHE) in order to execute the preprocessing phase.In this paper, we propose ThorPIR, a single-server client preprocessing PIR scheme which achieves both sublinear offline bandwidth (asymptotically and concretely) and a low-depth, highly parallelizable preprocessing circuit. Our main insight is to use and significantly optimize the concrete circuit-depth of a much more efficient shuffling technique needed during preprocessing, called Thorp shuffle. A Thorp shuffle satisfies a weaker security property (e.g., compared to an AES permutation) which is just enough for our construction. We estimate that with a powerful server (e.g., hundreds of thousands of GPUs), ThorPIR's end-to-end preprocessing time is faster than any prior work. Additionally, compared to prior FHE-based works with sublinear bandwidth, our construction is at least around 10,000 times faster.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690326",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Fake It till You Make It: Enhancing Security of Bluetooth Secure Connections via Deferrable Authentication",
        "authors": "Fischlin, Marc; Sanina, Olga",
        "keywords": "Bluetooth Security (蓝牙安全) - 保障无线连接协议安全\nAuthentication Protocol (认证协议) - 验证身份确保通信可信\nKey Negotiation (密钥协商) - 安全交换加密通信密钥\n选定的主题标签名称",
        "abstract": "The Bluetooth protocol for wireless connection between devices comes with several security measures to protect confidentiality and integrity of data. At the heart of these security protocols lies the Secure Simple Pairing, wherewith the devices can negotiate a shared key before communicating sensitive data. Despite the good intentions, the Bluetooth security protocol has repeatedly been shown to be vulnerable, especially with regard to active attacks on the Secure Simple Pairing.We propose here a mechanism to limit active attacks on the Secure Connections protocol (the more secure version of the Secure Simple Pairing protocol), without infringing on the current Bluetooth protocol stack specification. The idea is to run an authentication protocol, like a classical challenge-response step for certified keys, within the existing infrastructure, even at a later, more convenient point in time. We prove that not only does this authentication step ensure freshness of future encryption keys, but an interesting feature is that it-a posteriori-also guarantees security of previously derived encryption keys. We next argue that this approach indeed prevents a large set of known attacks on the Bluetooth protocol.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670360",
        "pub_year": "2024",
        "theme_label": "网络与系统安全"
    },
    {
        "title": "Byzantine-Secure Relying Party for Resilient RPKI",
        "authors": "Friess, Jens; Mirdita, Donika; Schulmann, Haya; Waidner, Michael",
        "keywords": "Byzantine Fault Tolerance (拜占庭容错) - 分布式系统容错机制\nRPKI Validation (RPKI验证) - 互联网路由路径验证\nConsensus Protocol (共识协议) - 多节点协同决策机制",
        "abstract": "BGP is a gaping hole in Internet security, as evidenced by numerous hijacks and outages. The significance of BGP for stability and security of the Internet has made it a top priority on the cyber security agenda of the US government, with CISA, FCC, and other federal agencies leading the efforts [12].To protect against prefix hijacks, Resource Public Key Infrastructure (RPKI) has been standardized. Yet, RPKI validation is still not widely supported. To enjoy the security guarantees of RPKI, networks need to install a new component, the Relying Party validator, which fetches and validates RPKI objects and provides them to border routers. However, research showed that Relying Parties experience failures when retrieving RPKI objects and are vulnerable to a range of attacks, all of which can disable RPKI validation. Therefore, even the few adopters are not necessarily secure.We propose a Byzantine-secure Relying Party functionality, we call ByzRP, and show that it significantly improves the resilience and security of RPKI validation. With ByzRP, Relying Party nodes redundantly validate RPKI objects and reach a global consensus through a voting process. ByzRP removes the need for networks to install, operate, and upgrade their own Relying Party instances on the one hand, and does not require to trust the individual operators of ByzRP nodes on the other hand.We show through simulations and experimental evaluations that ByzRP, as an intermediate RPKI service, reduces the load on RPKI publication points and produces a robust output, despite RPKI repository failures, jitters, and attacks. We engineer ByzRP to be fully backward compatible and readily deployable - it does not require any changes to border routers and RPKI repositories. We demonstrate that ByzRP can protect networks transparently, either with a decentralized or a centralized deployment and it enables users to independently verify the correctness of its operation.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690368",
        "pub_year": "2024",
        "theme_label": "网络基础设施安全"
    },
    {
        "title": "Detecting Tunneled Flooding Traffic via Deep Semantic Analysis of Packet Length Patterns",
        "authors": "Fu, Chuanpu; Li, Qi; Shen, Meng; Xu, Ke",
        "keywords": "Tunneled Flooding Traffic (隐蔽隧道泛洪流量) - 指加密隧道中的攻击流量\nDeep Semantic Analysis (深度语义分析) - 利用语义特征识别攻击模式\nPacket Length Patterns (数据包长度模式) - 分析长度特征检测异常流量\n选定的主题标签名称",
        "abstract": "Distributed denial-of-service (DDoS) protection services capture various flooding attacks by analyzing traffic features. However, existing services are unable to accurately detect tunneled attack traffic because the tunneling protocols encrypt both packet headers and payloads, which hide the traffic features used for detection, and can thus evade these detection services. In this paper, we develop Exosphere, which detects tunneled attack traffic by analyzing packet length patterns, without investigating any information in packets. Specifically, it utilizes a deep learning based method to analyze the semantics of packet patterns, i.e., the features represent the strong correlations between flooding packets with similar length patterns, and classify attack traffic according to these semantic features. We prove that the strong correlations of packet length patterns ensure the theoretical guarantee of applying semantic analysis to recognize correlated attack packets. We prototype Exosphere with FPGAs and deploy it in a real-world institutional network. The experimental results demonstrate that Exosphere achieves 0.967 F1 accuracy, while detecting flooding traffic generated by unseen attacks and misconfigurations. Moreover, it achieves 0.996 AUC accuracy on existing datasets including various stealthy attacks, and thus significantly outperforms the existing deep learning models. It achieves accuracy comparable to the best performances achieved by 12 state-of-the-art methods that cannot detect tunneled flooding traffic, while improving their efficiency by 6.19 times.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670353",
        "pub_year": "2024",
        "theme_label": "3.9 攻击防御"
    },
    {
        "title": "Poster: Enhance Hardware Domain Specific Large Language Model with Reinforcement Learning for Resilience",
        "authors": "Fu, Weimin; Zhao, Yifang; Jin, Yier; Guo, Xiaolong",
        "keywords": "Reinforcement Learning (强化学习) - 通过反馈优化模型决策能力\nHardware Design (硬件设计) - 涉及芯片与系统结构设计\nSide-channel Attacks (侧信道攻击) - 利用物理信息进行安全攻击\n选定的主题标签名称",
        "abstract": "To enhance the performance of large language models (LLMs) on hardware design tasks, we focus on training with reinforcement learning(RL) to improve LLMs' syntax synthesis and functional verification performance. We observed significant gains in power, performance, and area (PPA) metrics by applying RL. Specifically, DeepSeek Code saw a 23.6% performance increase, while the RTL-Coder improved by 7.86%. Our findings demonstrate the effectiveness of RL in refining LLMs for more accurate hardware generation, considering power and area consumption. This approach offers a promising direction for generating hardware resilient to side-channel attacks in computer systems.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691384",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Benchmarking Secure Sampling Protocols for Differential Privacy",
        "authors": "Fu, Yucheng; Wang, Tianhao",
        "keywords": "Differential Privacy (差分隐私) - 隐私保护数据分析方法\nSecure Multi-party Computation (安全多方计算) - 多方协同隐私保护协议\nBenchmarking Protocols (基准测试协议) - 协议性能与安全性评估\n选定的主题标签名称",
        "abstract": "Differential privacy (DP) is widely employed to provide privacy protection for individuals by limiting information leakage from the aggregated data. Two well-known models of DP are the central model and the local model. The former requires a trustworthy server for data aggregation, while the latter requires individuals to add noise, significantly decreasing the utility of aggregated results. Recently, many studies have proposed to achieve DP with Secure Multi-party Computation (MPC) in distributed settings, namely, the distributed model, which has utility comparable to central model while, under specific security assumptions, preventing parties from obtaining others' information. One challenge of realizing DP in distributed model is efficiently sampling noise with MPC. Although many secure sampling methods have been proposed, they have different security assumptions and isolated theoretical analyses. There is a lack of experimental evaluations to measure and compare their performances. We fill this gap by benchmarking existing sampling protocols in MPC and performing comprehensive measurements of their efficiency. First, we present a taxonomy of the underlying techniques of these sampling protocols. Second, we extend widely used distributed noise generation protocols to be resilient against Byzantine attackers. Third, we implement discrete sampling protocols and align their security settings for a fair comparison. We then conduct an extensive evaluation to study their efficiency and utility. Our experiments show that (1) malicious protocols based on a technique called bitwise sampling are more efficient than other methods, and using an oblivious data structure can reduce the circuit size in high-security regimes, (2) the cost of realizing malicious security is high, under the assumption of semi-honest, using a method named distributed noise generation is much more efficient, and (3) the utility loss caused by sampling noise in MPC is small, which to a certain extent eliminates utility concerns when using the DDP protocol in practice. We open-source our code at https://github.com/yuchengxj/Secure-sampling-benchmark.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690257",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Secure Vickrey Auctions with Rational Parties",
        "authors": "Ganesh, Chaya; Gupta, Shreyas; Kanukurthi, Bhavana; Shankar, Girisha",
        "keywords": "Secure Auctions (安全拍卖) - 确保护理拍卖过程隐私\nRational Parties (理性参与方) - 基于效用最大化的自利行为\nPrivacy-Preserving Protocols (隐私保护协议) - 保障数据机密性的协议设计\n选定的主题标签名称",
        "abstract": "In this work, we construct a second price (Vickrey) auction protocol (SPA), which does not require any auctioneers and ensures total privacy in the presence of rational parties participating in the auction. In particular, the confidentiality of the highest bid and the identity of the second highest bidder are protected. We model the bidders participating in the second price auction as rational, computationally bounded and privacy-sensitive parties. These are self-interested agents who care about winning the auction more than learning about the private bids of other parties. A rational party does not deviate from the protocol arbitrarily but does so only for its own individual 'advantage' - without any consideration for others. Such an advantage is modelled using suitable utility functions.We show that for rational and computationally bounded parties participating in our second-price auctions protocol, there exists a privacy-preserving dominant strategy equilibrium in which every party prefers to follow the protocol rather than to deviate.Our protocol is implemented using open-source cryptographic constructs. Running our SPA protocol on commodity hardware with 15 bidders, with bids of length 10 bits, completes in 1.26sec and has total communication of 0.77MB whereas, under similar conditions, Atlas (semi-honest) protocol takes 40% more time (2.11 sec) and 87% more communication (6.09MB).",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670311",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Graphical vs. Deep Generative Models: Measuring the Impact of Differentially Private Mechanisms and Budgets on Utility",
        "authors": "Ganev, Georgi; Xu, Kai; De Cristofaro, Emiliano",
        "keywords": "Differential Privacy (差分隐私) - 隐私保护数据发布技术\nGenerative Models (生成模型) - 用于合成数据建模的方法\nPrivacy-Utility Tradeoff (隐私-效用权衡) - 平衡隐私保护与数据可用性\n选定的主题标签名称",
        "abstract": "Generative models trained with Differential Privacy (DP) can produce synthetic data while reducing privacy risks. However, navigating their privacy-utility tradeoffs makes finding the best models for specific settings/tasks challenging. This paper bridges this gap by profiling how DP generative models for tabular data distribute privacy budgets across rows and columns, which is one of the primary sources of utility degradation. We compare graphical and deep generative models, focusing on the key factors contributing to how privacy budgets are spent, i.e., underlying modeling techniques, DP mechanisms, and data dimensionality.Through our measurement study, we shed light on the characteristics that make different models suitable for various settings and tasks. For instance, we find that graphical models distribute privacy budgets horizontally and thus cannot handle relatively wide datasets for a fixed training time; also, the performance on the task they were optimized for monotonically increases with more data but could also overfit. Deep generative models spend their budgets per iteration, so their behavior is less predictable with varying dataset dimensions, but are more flexible as they could perform better if trained on more features. Moreover, low levels of privacy (epsilon >= 100) could help some models generalize, achieving better results than without applying DP. We believe our work will aid the deployment of DP synthetic data techniques by navigating through the best candidate models vis-a-vis the dataset features, desired privacy levels, and downstream tasks.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690215",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Efficient Scalable Multi-Party Private Set Intersection(-Variants) from Bicentric Zero-Sharing",
        "authors": "Gao, Ying; Luo, Yuanchao; Wang, Longxin; Liu, Xiang; Qi, Lin; Wang, Wei; Zhou, Mengmeng",
        "keywords": "Multi-Party Private Set Intersection (多方私有集合交集) - 隐私保护下的集合交集计算\nBicentric Zero-Sharing (双中心零共享) - 用于简化多方协议的密码学原语\nOblivious Key-Value Store ( oblivious键值存储) - 支持隐私数据检索的数据结构",
        "abstract": "Multi-party private set intersection (MPSI) allows n (n >= 3) participants, each holding a dataset of size.., to compute the intersection of their sets without revealing any additional information. We extract a primitive called bicentric zero-sharing, which can reduce MPSI to two-party PSI between two central participants named Pivot and Leader. We introduce an efficient instantiation of bicentric zero-sharing, which involves a round of sharing and reconstruction of an oblivious key-value store (OKVS) object. We then combine this construction with two-party PSI to propose a new efficient scalable MPSI protocol. We also propose protocols for computing MPSI variants based on bicentric zero-sharing, such as multi-party private set intersection cardinality (MPSI-CA) and multi-party threshold private set intersection (MTPSI).Our protocols are mainly based on symmetric-key operations, and the communication complexity of each participant is at most O(n + m). The security of our protocols relies on the assumption that Leader and Pivot do not collude, which can be applicable in many scenarios. In this case, our protocols are secure against arbitrary collusion (except Leader and Pivot) in the semi-honest model. Moreover, our protocols are secure against up to n - 2 malicious Clients (participants except Leader and Pivot) in the random oracle model. All these protocols realize the scalability with the number of participants.We demonstrate the scalability of our protocols with an implementation and a comparison with the state-of-the-art MPSI. Experiments show that when computing MPSI for 15 participants with datasets of 2(20) elements each, our protocol is 46.4x faster in the LAN setting, 18.3x faster in WAN setting, and requires 24.7x less communication cost compared to the state-of-the-art in CCS'21 ( by Nevo et al.), and the improvement becomes more significant as the number of participants and set size increases. To the best of our knowledge, ours are the first protocols that report on more than 100 participants. For 140 participants with datasets of 2(20) elements each, our MPSI and MPSI-CA protocol requires only 4.557s and 16.02s in the LAN setting, respectively.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690245",
        "pub_year": "2024",
        "theme_label": "安全多方计算"
    },
    {
        "title": "Computationally Secure Aggregation and Private Information Retrieval in the Shuffle Model",
        "authors": "Gascon, Adria; Ishai, Yuval; Kelkar, Mahimna; Li, Baiyu; Ma, Yiping; Raykova, Mariana",
        "keywords": "Secure Aggregation (安全聚合) - 多方计算中隐私保护求和技术\nPrivate Information Retrieval (私密信息检索) - 用户从数据库私密查询数据\nShuffle Model (洗牌模型) - 基于匿名通信的隐私计算框架\n选定的主题标签名称",
        "abstract": "The shuffle model has recently emerged as a popular setting for differential privacy, where clients can communicate with a central server using anonymous channels or an intermediate message shuffler. This model was also explored in the context of cryptographic tasks such as secure aggregation and private information retrieval (PIR). However, this study was almost entirely restricted to the stringent notion of information-theoretic security.In this work, we study computationally secure aggregation protocols and PIR in the shuffle model. Our starting point is the insight that the previous technique of shuffling additive shares can be improved in the computational setting. We show that this indeed holds under the standard learning parity with noise (LPN) assumption, but even better efficiency follows from plausible conjectures about the multi-disjoint syndrome decoding (MDSD) problem that we introduce and study in this work.We leverage the above towards improving the efficiency of secure aggregation and PIR in the shuffle model. For secure aggregation of long vectors, our protocols require 9x-25x less communication than the previous information-theoretic solutions. Our PIR protocols enjoy the simplicity and concrete efficiency benefits of multi-server PIR while only requiring a single server to store the database. Under the MDSD assumption, they improve over recent single-server PIR constructions by up to two orders of magnitude.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670391",
        "pub_year": "2024",
        "theme_label": "密码学及应用"
    },
    {
        "title": "SemPat: From Hyperproperties to Attack Patterns for Scalable Analysis of Microarchitectural Security",
        "authors": "Godbole, Adwait; Manerkar, Yatin A.; Seshia, Sanjit A.",
        "keywords": "Hyperproperty (超属性) - 形式化安全性质\nAttack Pattern (攻击模式) - 漏洞利用特征\nMicroarchitectural Security (微架构安全) - 硬件层级防护\n选定的主题标签名称",
        "abstract": "Microarchitectural security verification of software has seen the emergence of two broad classes of approaches. The first uses non-interference-based semantic security properties which are verified for a given program and a given model of the hardware microarchitecture. The second is based on attack patterns, which, if found in a program execution, indicates the presence of an exploit. We observe that while the former uses a formal specification that can capture several gadget variants targeting the same vulnerability, it is limited by the scalability of verification. While more scalable, patterns must be currently constructed manually, as they are narrower in scope and sensitive to gadget-specific structure.This work develops a technique that, given a non-interferencebased semantic security hyperproperty, automatically generates attack patterns up to a certain complexity parameter (called the skeleton size). Thus, we combine the advantages of both approaches: security can be specified by a hyperproperty that uniformly captures several gadget variants, while automatically generated patterns can be used for scalable verification. We implement our approach in a tool and demonstrate the ability to generate new patterns, (e.g., for SpectreV1, SpectreV4) and improved scalability using the generated patterns over hyperproperty-based verification.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690214",
        "pub_year": "2024",
        "theme_label": "3.2 硬件安全"
    },
    {
        "title": "Dora: A Simple Approach to Zero-Knowledge for RAM Programs",
        "authors": "Goel, Aarushi; Hall-Andersen, Mathias; Kaptchuk, Gabriel",
        "keywords": "Zero-Knowledge Proof (零知识证明) - 隐私保护的密码学协议\nRAM Program Verification (RAM程序验证) - 验证程序执行正确性\nHomomorphic Commitments (同态承诺) - 支持运算的数据加密技术\n选定的主题标签名称",
        "abstract": "Existing protocols for proving the correct execution of a RAM program in zero-knowledge are plagued by a processor expressiveness tradeoff : supporting fewer instructions results in smaller processor circuits (which improves performance), but may result in more program execution steps because non-supported instruction must be emulated over multiple processor steps (diminishing performance).We present Dora, a very simple and concretely efficient zeroknowledge protocol for RAM programs that sidesteps this tension by making it (nearly) free to add additional instructions to the processor. The computational and communication complexity of proving each step of a computation in Dora, is constant in the number of supported instructions. Dora's approach is united by intuitive abstraction we call a ZKBag, a cryptographic primitive constructed from linearly homomorphic commitments that captures the properties of a physical bag. We implement Dora and demonstrate that on commodity hardware it can prove the correct execution of a processor with thousands of instruction, each of which has thousands of gates, in just a few milliseconds per step.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690213",
        "pub_year": "2024",
        "theme_label": "2.2.2 密码原语和范式"
    },
    {
        "title": "Demo: FT-PrivacyScore: Personalized Privacy Scoring Service for Machine Learning Participation",
        "authors": "Gu, Yuechun; He, Jiajie; Chen, Keke",
        "keywords": "Privacy Scoring (隐私评分) - 量化参与机器学习的隐私风险\nMachine Learning Participation (机器学习参与) - 数据贡献者参与模型训练的过程\nControlled Data Access (受控数据访问) - 限制环境下的数据使用以保护隐私\n选定的主题标签名称",
        "abstract": "Training data privacy has been a top concern in AI modeling. While methods like differentiated private learning allow data contributors to quantify acceptable privacy loss, model utility is often significantly damaged. In practice, controlled data access remains a mainstream method for protecting data privacy in many industrial and research environments. In controlled data access, authorized model builders work in a restricted environment to access sensitive data, which can fully preserve data utility with reduced risk of data leak. However, unlike differential privacy, there is no quantitative measure for individual data contributors to tell their privacy risk before participating in a machine learning task. We developed the demo prototype FT-PrivacyScore to show that it's possible to efficiently and quantitatively estimate the privacy risk of participating in a model fine-tuning task. The demo source code will be available at https://github.com/RhincodonE/demo_privacy_scoring.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691366",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Characterizing Ethereum Address Poisoning Attack",
        "authors": "Guan, Shixuan; Li, Kai",
        "keywords": "Address Poisoning Attack (地址投毒攻击) - 针对区块链地址的钓鱼攻击\nEthereum Blockchain Security (以太坊区块链安全) - 保障以太坊链上资产与交易安全\nPhishing Detection System (钓鱼检测系统) - 用于识别恶意地址与交易行为\n选定的主题标签名称",
        "abstract": "This paper presents the first comprehensive analysis of the address poisoning attack surged on the Ethereum blockchain. This phishing attack typically exploits the address shortening feature of Ethereum explorers and digital wallets (e.g., Etherscan and MetaMask) by crafting token transfer events with a seemingly correct address to poison victims' transfer history, waiting for them to mistakenly transfer assets to the attacker's address.To systematically detect and characterize the address poisoning attack, we developed a detection system named Poison-Hunter, which can recognize the attacker's crafted transfers and detect the phishing addresses controlled by the attacker. By applying PoisonHunter to Ethereum blocks produced from Nov. 2022 to Feb. 2024, we have detected millions of phishing transfers and phishing addresses. Our analysis shows that the attacker has predominantly targeted USDC and USDT token holders and used a phishing address that looks highly similar to a benign one. We also find that the sender of legitimate transfers was the primary target of this attack. Furthermore, by tracing the transaction history of the detected phishing addresses, we reveal that over 1,800 victim addresses have lost crypto assets, with a potential financial loss of up to $144 million US dollars. Among them, about $90 million of loss are confirmed by this work. Finally, our analysis suggests that 98% of phishing addresses are controlled by four entities, which collected nearly 92% of the total profits.Overall, this paper sheds light on the tactics utilized in the address poisoning attack and its scale and impact on the Ethereum blockchain, emphasizing the urgent need for an effective detection and prevention mechanism against such a phishing activity.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690277",
        "pub_year": "2024",
        "theme_label": "8.2 智能合约及安全"
    },
    {
        "title": "Understanding Legal Professionals' Practices and Expectations in Data Breach Incident Reporting",
        "authors": "Gumusel, Ece; Xiao, Yue; Qin, Yue; Qin, Jiaxin; Liao, Xiaojing",
        "keywords": "Data Breach Incident Reporting (数据泄露事件报告) - 事件响应与合规分析\nLegal Compliance Analysis (法律合规分析) - 隐私法规遵循评估\nPrivacy-related Items Identification (隐私相关项识别) - 判定隐私保护内容",
        "abstract": "Legal professionals are essential in analyzing data breach incident reports and guiding the response to comply with data privacy laws and regulations. Their expertise helps mitigate privacy and security risks and prevents failures in privacy compliance. However, little research has been done to understand how legal professionals perceive, react to, and face challenges within the data breach incident reporting procedure. In this study, we conducted a simulated incident report assessment experiment and semi-structured interviews with 33 legal professionals who varied in age, gender, and legal background. We reported the criteria used by legal professionals to identify privacy-related items and also uncovered that the agreement among legal professionals on the concepts of privacy-related items is low. Furthermore, we presented findings regarding the perceptions and strategies of legal professionals concerning legal and regulatory compliance, as well as the key features of incident responses that facilitate efficient analysis of data privacy and security law compliance. After taking into account the challenges and suggestions provided by legal professionals, we concluded this study with recommendations for enhancing the effectiveness of legal compliance analysis for incident responses.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690357",
        "pub_year": "2024",
        "theme_label": "1.6 人的安全行为与管理"
    },
    {
        "title": "Obfuscated Key Exchange",
        "authors": "Gunther, Felix; Stebila, Douglas; Veitch, Shannon",
        "keywords": "Obfuscated Key Exchange (混淆密钥交换) - 用于抗审查的加密通信\nFully Encrypted Protocol (全加密协议) - 流量特征与随机无异\nQuantum-Safe Cryptography (量子安全密码学) - 抵抗量子计算攻击\n选定的主题标签名称",
        "abstract": "Censorship circumvention tools enable clients to access endpoints in a network despite the presence of a censor. Censors use a variety of techniques to identify content they wish to block, including filtering traffic patterns that are characteristic of proxy or circumvention protocols and actively probing potential proxy servers. Circumvention practitioners have developed fully encrypted protocols (FEPs), intended to have traffic that appears indistinguishable from random. A FEP is typically composed of a key exchange protocol to establish shared secret keys, and then a secure channel protocol to encrypt application data; both must avoid revealing to observers that an obfuscated protocol is in use.We formalize the notion of obfuscated key exchange, capturing the requirement that a key exchange protocol's traffic looks random and that it resists active probing attacks, in addition to ensuring secure session keys and authentication. We show that the Tor network's obfs4 protocol satisfies this definition. We then show how to extend the obfs4 design to defend against stronger censorship attacks and present a quantum-safe obfuscated key exchange protocol. To instantiate our quantum-safe protocol using the ML-KEM (Kyber) standard, we present Kemeleon, a new mapping between ML-KEM public keys/ciphertexts and uniform byte strings.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690220",
        "pub_year": "2024",
        "theme_label": "2.3.2 密码协议设计与分析"
    },
    {
        "title": "A Qualitative Analysis of Practical De-Identification Guides",
        "authors": "Guo, Wentao; Kishore, Aditya; Aviv, Adam J.; Mazurek, Michelle L.",
        "keywords": "De-identification (去标识化) - 数据匿名化处理方法\nPrivacy Protection (隐私保护) - 保障个人信息安全\nGuide Usability (指南可用性) - 提升实践指导效果",
        "abstract": "De-identifying microdata is necessary yet difficult. Myriad techniques exist, which reduce risk and preserve utility to varying, often unclear extents. We conducted a thematic analysis of 38 online de-identification guides for practitioners, to understand what content they contain and how they are designed to support decision-making and execution. We highlight trends and differences between guides, and we find some concerning patterns, including inconsistent definitions of key terms, gaps in coverage of threats to de-identification, and areas for improvement in usability. We identify directions for future research and suggest changes to de-identification guidance in order to better support practitioners in conducting effective de-identification.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690270",
        "pub_year": "2024",
        "theme_label": "数据隐私保护"
    },
    {
        "title": "REACTAPPSCAN: Mining React Application Vulnerabilities via Component Graph",
        "authors": "Guo, Zhiyong; Kang, Mingqing; Venkatakrishnan, V. N.; Gjomemo, Rigel; Cao, Yinzhi",
        "keywords": "Vulnerability Detection (漏洞检测) - 程序安全缺陷识别\nComponent Graph (组件图) - 组件间数据流动建模\nData Flow Tracking (数据流跟踪) - 数据传播路径分析\n选定的主题标签名称",
        "abstract": "React, a single-page application framework, has recently become popular among web developers due to its flexible and convenient management of web application states via a syntax extension to JavaScript, called JSX ( JavaScript and XML). Despite its abundant functionalities, the security of React, especially vulnerability detection, still lags: many existing vulnerability detection works do not support JSX let alone React Data Flow introduced by React components. The only exception is CodeQL, which supports JSX syntax. However, CodeQL cannot properly track React Data Flow across different components for detecting vulnerabilities.In this paper, we design a novel framework, called REACTAPPSCAN, which constructs a Component Graph (CoG) for tracking React Data Flowand detecting vulnerabilities following both JavaScript and React data flows. Specifically, REACTAPPSCAN relies on abstract interpretation to build such a component graph via tracking component lifecycles and then detects vulnerabilities via finding paths between sources and sinks. Our evaluation shows that REACTAPPSCAN detects 61 zero-day vulnerabilities in real-world React applications. We have responsibly reported all the vulnerabilities and so far six vulnerabilities have been fixed and two have been acknowledged.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670331",
        "pub_year": "2024",
        "theme_label": "3.8.1 漏洞挖掘与逆向分析"
    },
    {
        "title": "Organic or Diffused: Can We Distinguish Human Art from AI-generated Images?",
        "authors": "Ha, Anna Yoo Jeong; Passananti, Josephine; Bhaskar, Ronik; Shan, Shawn; Southen, Reid; Zheng, Haitao; Zhao, Ben Y.",
        "keywords": "AI-generated Image Detection (AI生成图像检测) - 识别图像是否由AI生成\nHuman Art Authentication (人类艺术认证) - 鉴别艺术作品的人工属性\nAdversarial Robustness (对抗鲁棒性) - 提升检测在对抗环境下的稳定性",
        "abstract": "The advent of generative AI images has completely disrupted the art world. Distinguishing AI generated images from human art is a challenging problem whose impact is growing over time. A failure to address this problem allows bad actors to defraud individuals paying a premium for human art and companies whose stated policies forbid AI imagery. It is also critical for content owners to establish copyright, and for model trainers interested in curating training data in order to avoid potential model collapse.There are several different approaches to distinguishing human art from AI images, including classifiers trained by supervised learning, research tools targeting diffusion models, and identification by professional artists using their knowledge of artistic techniques. In this paper, we seek to understand how well these approaches can perform against today's modern generative models in both benign and adversarial settings. We curate real human art across 7 styles, generate matching images from 5 generative models, and apply 8 detectors (5 automated detectors and 3 different human groups including 180 crowdworkers, 3800+ professional artists, and 13 expert artists experienced at detecting AI). Both Hive and expert artists do very well, but make mistakes in different ways (Hive is weaker against adversarial perturbations while Expert artists produce higher false positives). We believe these weaknesses will persist, and argue that a combination of human and automated detectors provides the best combination of accuracy and robustness.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670306",
        "pub_year": "2024",
        "theme_label": "信息内容安全"
    },
    {
        "title": "Rules Refine the Riddle: Global Explanation for Deep Learning-Based Anomaly Detection in Security Applications",
        "authors": "Han, Dongqi; Wang, Zhiliang; Feng, Ruitao; Jin, Minghui; Chen, Wenqi; Wang, Kai; Wang, Su; Yang, Jiahai; Shi, Xingang; Yin, Xia; Liu, Yang",
        "keywords": "Global Explanation (全局解释) - 提供模型整体决策逻辑\nAnomaly Detection (异常检测) - 识别安全领域的异常行为\nRule Extraction (规则提取) - 从模型中提炼可解释规则",
        "abstract": "Deep learning (DL) based anomaly detection has shown great promise in the field of security due to its remarkable performance in various tasks. However, the issue of poor interpretability in DL models has significantly impeded their deployment in practical security applications. Despite the progress made in existing studies on DL explanations, the majority of them focus on providing local explanations for individual samples, neglecting the global understanding of the model knowledge. Furthermore, most explanations for supervised models fail to apply to anomaly detection due to their different learning mechanisms.In this work, we address the gap in the existing research by proposing GEAD, a novel global explanation for DL-based anomaly detection, to extract high-fidelity rules from DL models. We apply GEAD to two security applications, network intrusion detection and system log anomaly detection, and demonstrate the efficacy with three usages: comparing model knowledge with expert knowledge, identifying knowledge discrepancies between models, and combining model and expert knowledge. We provide several case studies to showcase how GEAD can significantly enhance existing anomaly detection systems. Moreover, we provide a real-world deployment in a SCADA system to showcase the potential in practice. Some important insights are drawn to help the community understand and improve anomaly detection systems in security.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670375",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Not One Less: Exploring Interplay between User Profiles and Items in Untargeted Attacks against Federated Recommendation",
        "authors": "Hao, Yurong; Chen, Xihui; Lyu, Xiaoting; Liu, Jiqiang; Zhu, Yongsheng; Wan, Zhiguo; Mauw, Sjouke; Wang, Wei",
        "keywords": "Federated Recommendation (联邦推荐) - 个性化推荐隐私保护\nPoisoning Attacks (投毒攻击) - 恶意数据破坏模型训练\nAttack Defense (攻击防御) - 防御恶意攻击方法",
        "abstract": "Federated recommendation (FR) is a decentralised approach to training personalised recommender systems, protecting users' privacy by avoiding data collection. Despite its privacy advantages, FR remains vulnerable to poisoning attacks. We focus on untargeted poisoning attacks against FR which degrade the overall performance of recommender services, leading to a detrimental impact on user experience and service quality. In this paper, we propose a general framework to formalise untargeted attacks and identify the vital role played by the interplay between items and user profiles in determining FR's performance. We present an untargeted attack FRecAttack2 which exploits this interplay. Specifically, we develop various methods for sampling user profiles, which approximate user distributions with and without collusion among malicious users. Then we leverage a new measurement to identify items that can disrupt the original interplay with user profiles, based on the change velocity of items' recommendation scores during optimisation. Extensive experiments demonstrate the superiority of our attack, outperforming existing methods by up to 27.56%, and its stealthiness in evading mainstream defences. To counteract untargeted attacks, we present a defence GuardCQ to detect malicious users by quantifying their contribution to boost the right interplay between items and user profiles. Empirical results show that GuardCQ effectively mitigates the attack's impact on FR and enhances the robustness of FR against poisoning attacks.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670365",
        "pub_year": "2024",
        "theme_label": "攻击防御"
    },
    {
        "title": "Rhombus: Fast Homomorphic Matrix-Vector Multiplication for Secure Two-Party Inference",
        "authors": "He, Jiaxing; Yang, Kang; Tang, Guofeng; Huang, Zhangjie; Lin, Li; Wei, Changzheng; Yan, Ying; Wang, Wei",
        "keywords": "Homomorphic Encryption (同态加密) - 支持密文计算的加密技术\nSecure Two-Party Computation (安全两方计算) - 双方私密数据协同处理协议\nPrivacy-Preserving Machine Learning (隐私保护机器学习) - 保护数据隐私的ML方法",
        "abstract": "We present Rhombus, a new secure matrix-vector multiplication (MVM) protocol in the semi-honest two-party setting, which is able to be seamlessly integrated into existing privacy-preserving machine learning (PPML) frameworks and serve as the basis of secure computation in linear layers. Rhombus adopts RLWE-based homomorphic encryption (HE) with coefficient encoding, which allows messages to be chosen from not only a field F-p but also a ring Z(2)l, where the latter supports faster computation in non-linear layers. To achieve better efficiency, we develop an input-output packing technique that reduces the communication cost incurred by HE with coefficient encoding by about 21x, and propose a split-point picking technique that reduces the number of rotations to that sublinear in the matrix dimension. Compared to the recent protocol HELiKs by Balla and Koushanfar (CCS'23), our implementation demonstrates that Rhombus improves the whole performance of an MVM protocol by a factor of 7.4x similar to 8x, and improves the end-to-end performance of secure two-party inference of ResNet50 by a factor of 4.6x similar to 18x.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690281",
        "pub_year": "2024",
        "theme_label": "6.3 同态加密"
    },
    {
        "title": "MGTBench: Benchmarking Machine-Generated Text Detection",
        "authors": "He, Xinlei; Shen, Xinyue; Chen, Zeyuan; Backes, Michael; Zhang, Yang",
        "keywords": "Machine-Generated Text Detection (机器生成文本检测) - 识别文本是否由模型生成\nBenchmark Framework (基准框架) - 提供统一评估标准与方法\nText Attribution (文本溯源) - 判定文本来源模型或作者类型\n选定的主题标签名称",
        "abstract": "Nowadays, powerful large language models (LLMs) such as ChatGPT have demonstrated revolutionary power in a variety of natural language processing (NLP) tasks such as text classification, sentiment analysis, language translation, and question-answering. Consequently, the detection of machine-generated texts (MGTs) is becoming increasingly crucial as LLMs become more advanced and prevalent. These models have the ability to generate human-like language, making it challenging to discern whether a text is authored by a human or a machine. This raises concerns regarding authenticity, accountability, and potential bias. However, existing methods for detecting MGTs are evaluated using different model architectures, datasets, and experimental settings, resulting in a lack of a comprehensive evaluation framework that encompasses various methodologies. Furthermore, it remains unclear how existing detection methods would perform against powerful LLMs.In this paper, we fill this gap by proposing the first benchmark framework for MGT detection against powerful LLMs, named MGTBench. Extensive evaluations on public datasets with curated texts generated by various powerful LLMs such as ChatGPT-turbo and Claude demonstrate the effectiveness of different detection methods. Our ablation study shows that a larger number of words in general leads to better performance and most detection methods can achieve similar performance with much fewer training samples. Additionally, our findings reveal that metric-based/model-based detection methods exhibit better transferability across different LLMs/datasets. Furthermore, we delve into a more challenging task: text attribution, where the goal is to identify the originating model of a given text, i.e., whether it is a specific LLM or authored by a human. Our findings indicate that the model-based detection methods still perform well in the text attribution task. To investigate the robustness of different detection methods, we consider three adversarial attacks, namely paraphrasing, random spacing, and adversarial perturbations. We discover that these attacks can significantly diminish detection effectiveness, underscoring the critical need for the development of more robust detection methods. We envision that MGTBench will serve as a benchmark tool to accelerate future investigations involving the evaluation of powerful MGT detection methods on their respective datasets and the development of more advanced MGT detection methods.(1)",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670344",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Is Difficulty Calibration AllWe Need? Towards More Practical Membership Inference Attacks",
        "authors": "He, Yu; Li, Boheng; Wang, Yao; Yang, Mengda; Wang, Juan; Hu, Hongxin; Zhao, Xingyu",
        "keywords": "Membership Inference Attack (成员推理攻击) - 隐私泄露分析\nDifficulty Calibration (难度校准) - 提高攻击准确性\nRAPID Attack Method (RAPID攻击方法) - 高效攻击设计",
        "abstract": "The vulnerability of machine learning models to Membership Inference Attacks (MIAs) has garnered considerable attention in recent years. These attacks determine whether a data sample belongs to the model's training set or not. Recent research has focused on reference-based attacks, which leverage difficulty calibration with independently trained reference models. While empirical studies have demonstrated its effectiveness, there is a notable gap in our understanding of the circumstances under which it succeeds or fails. In this paper, we take a further step towards a deeper understanding of the role of difficulty calibration. Our observations reveal inherent limitations in calibration methods, leading to the misclassification of non-members and suboptimal performance, particularly on high-loss samples. We further identify that these errors stem from an imperfect sampling of the potential distribution and a strong dependence of membership scores on the model parameters. By shedding light on these issues, we propose RAPID: a queryefficient and computation-efficient MIA that directly Re-leverAges the original membershiP scores to mItigate the errors in Difficulty calibration. Our experimental results, spanning 9 datasets and 5 model architectures, demonstrate that RAPID outperforms previous state-of-the-art attacks (e.g., LiRA and Canary offline) across different metrics while remaining computationally efficient. Our observations and analysis challenge the current de facto paradigm of difficulty calibration in high-precision inference, encouraging greater attention to the persistent risks posed by MIAs in more practical scenarios.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690316",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "The Harder You Try, The Harder You Fail: The KeyTrap Denial-of-Service Algorithmic Complexity Attacks on DNSSEC",
        "authors": "Heftrig, Elias; Schulmann, Haya; Vogel, Niklas; Waidner, Michael",
        "keywords": "DNSSEC (域名系统安全扩展) - 确保域名解析安全的协议\nAlgorithmic Complexity Attack (算法复杂度攻击) - 利用计算资源耗尽实施攻击\nDenial of Service (拒绝服务) - 阻断正常服务请求的攻击方式",
        "abstract": "Availability is a major concern in the design of DNSSEC. To ensure availability, DNSSEC follows Postel's Law [RFC1123]: Be liberal in what you accept, and conservative in what you send. Hence, name-servers should send not just one matching key for a record set, but all the relevant cryptographic material, e.g., all the keys for all the ciphers that they support and all the corresponding signatures. This ensures that validation succeeds, and hence availability, even if some of the DNSSEC keys are misconfigured, incorrect or correspond to unsupported ciphers.We show that this design of DNSSEC is flawed. Exploiting vulnerable recommendations in the DNSSEC standards, we develop a new class of DNSSEC-based algorithmic complexity attacks on DNS, we dub KeyTrap attacks. All popular DNS implementations and services are vulnerable. With just a single DNS packet, the KeyTrap attacks lead to a 2.000.000x spike in CPU instruction count in vulnerable DNS resolvers, stalling some for as long as 16 hours. This devastating effect prompted major DNS vendors to refer to KeyTrap as the worst attack on DNS ever discovered. Exploiting KeyTrap, an attacker could effectively disable Internet access in any system utilizing a DNSSEC-validating resolver.We disclosed KeyTrap to vendors and operators on November 2, 2023, confidentially reporting the vulnerabilities to a closed group of DNS experts, operators and developers from the industry. Since then we have been working with all major vendors to mitigate KeyTrap, repeatedly discovering and assisting in closing weaknesses in proposed patches. Following our disclosure, the industry-wide umbrella CVE-2023-50387 has been assigned, covering the DNSSEC protocol vulnerabilities we present in this work.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670389",
        "pub_year": "2024",
        "theme_label": "网络与系统安全"
    },
    {
        "title": "The Insecurity of Masked Comparisons: SCAs on ML-KEM's FO-Transform",
        "authors": "Hermelink, Julius; Ning, Kai-Chun; Petri, Richard; Strieder, Emanuele",
        "keywords": "Side-channel Attacks (侧信道攻击) - 利用物理泄露信息破解系统\nMasked Comparison (掩码比较) - 防止信息泄露的计算方法\nML-KEM Security (ML-KEM安全) - 后量子密码嵌入式防护\n选定的主题标签名称",
        "abstract": "NIST released the draft standard for ML-KEM, and we can expect its widespread use in the embedded world in the near future. Several side-channel attacks have been proposed, and one line of research has focused on attacks against the comparison step of the FO-transform. A work published at TCHES 2022 stressed the need for secure higher-order masked comparisons beyond the C-probing model and proposed a higher-order masked comparison method. Subsequently, D'Anvers, Van Beirendonck, and Verbauwhede improved upon the performance of several previous proposals; their higher-order masked algorithm currently achieves the highest performance for masked comparisons.In this work, we show that while this proposal is secure in the C-probing model, its security in practice is questionable. We first propose an approximate template attack that requires only a small number of traces for profiling and has an exceptionally high noise tolerance. We demonstrate that, without knowledge of the targeted values, a vertical analysis of the distribution of certain points of interest can replace the profiling phase. Finally, we explain how a decryption failure oracle may be constructed from a single trace.We prove that these attacks are not affected by higher masking orders for noise levels that by far prevent previous profiled attacks on ML-KEM. Further, we provide simulations showing that even under extreme noise levels, the attacks are not prevented by realistic masking orders. Additionally, we carry out the attacks on multiple physical devices to stress the practicality of our attack. We discuss the underlying causes for our attack, demonstrate the difficulty of securing the FO-transform in ML-KEM, draw conclusions about the (in-)sufficiency of C-probing security in this context, and highlight an open gap in securing ML-KEM on embedded devices.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690339",
        "pub_year": "2024",
        "theme_label": "2.4 密码工程技术"
    },
    {
        "title": "Selling Satisfaction: A Qualitative Analysis of Cybersecurity Awareness Vendors' Promises",
        "authors": "Hielscher, Jonas; Schoeps, Markus; Opdenbusch, Jens; Reichmann, Felix; Gutfleisch, Marco; Marky, Karola; Parkin, Simon",
        "keywords": "Security Awareness Training (安全意识培训) - 提升员工网络安全认知\nVendor Promises (供应商承诺) - 分析营销宣传与实际差距\nHuman-Centered Security (以人为本的安全) - 关注用户角色与行为",
        "abstract": "Security awareness and training (SAT) vendors operate in a growing multi-billion dollar market. They publish various marketing promises on their websites to their customers - organizations of all sizes. This paper investigates how these promises align with customers' needs, how they relate to human-centered security challenges highlighted in prior research, and what narrative is presented regarding the role of employees (as SAT recipients). We also investigate the level of transparency in vendor promises, as to whether it constitutes an information asymmetry. We gathered search terms from n = 30 awareness professionals to perform an automated Google search and scraping of SAT vendors' websites. We then performed a thematic analysis of 2,476 statements on 156 websites from 59 vendors. We found that the messaging from SAT vendors precisely targets customers' need for easy-to-implement and compliance-fulfilling SAT products; how SAT products are offered also means that some of the impacts of SAT go unmentioned and are transferred to the customer, such as user support. In this vendor-customer relationship, employees are portrayed as a source of weaknesses, needing an indefinite amount of training to be incorporated into the organization's protection. We conclude with suggestions for SAT vendors and regulators, notably toward an SAT ecosystem that directly links SAT solutions to usable security technologies within the organization environment.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690196",
        "pub_year": "2024",
        "theme_label": "1.6 人的安全行为与管理"
    },
    {
        "title": "End-to-End Encrypted Cloud Storage in the Wild: A Broken Ecosystem",
        "authors": "Hofmann, Jonas; Truong, Kien Tuong",
        "keywords": "End-to-End Encryption (端到端加密) - 加密通信保障数据安全\nCloud Storage Security (云存储安全) - 保护云端数据完整性与机密性\nCryptographic Vulnerabilities (密码学漏洞) - 揭示加密设计中的安全隐患\n选定的主题标签名称",
        "abstract": "End-to-end encrypted cloud storage offers a way for individuals and organisations to delegate their storage needs to a third-party, while keeping control of their data using cryptographic techniques. We conduct a cryptographic analysis of various products in the ecosystem, showing that many providers fail to provide an adequate level of security. In particular, we provide an in-depth analysis of five end-to-end encrypted cloud storage systems, namely Sync, pCloud, Icedrive, Seafile, and Tresorit, in the setting of a malicious server. These companies cumulatively have over 22 million users and are major providers in the field. We unveil severe cryptographic vulnerabilities in four of them. Our attacks invalidate the marketing claims made by the providers of these systems, showing that a malicious server can, in some cases, inject files in the encrypted storage of users, tamper with file data, and even gain direct access to the content of the files. Many of our attacks affect multiple providers in the same way, revealing common failure patterns in independent cryptographic designs. We conclude by discussing the significance of these patterns beyond the security of the specific providers.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690309",
        "pub_year": "2024",
        "theme_label": "2.5 密码应用技术"
    },
    {
        "title": "Securing Floating-Point Arithmetic for Noise Addition",
        "authors": "Holohan, Naoise; Braghin, Stefano; Suliman, Mohamed",
        "keywords": "Floating-Point Arithmetic (浮点运算) - 数值计算基础方法\nNoise Addition (噪声添加) - 隐私保护常用技术\nInformation Leakage (信息泄露) - 安全风险来源\n选定的主题标签名称",
        "abstract": "Floating-point arithmetic is ubiquitous across computing, with its wide range of values, large and small, making it the preferred tool for storing, analysing, and manipulating numerical data. Its flexibility comes at the cost of additional risks in some security/privacy-aware settings. In this paper, we discuss the threat of information leakage caused by floating-point arithmetic when adding noise to sensitive values, which can allow the sensitive information to be recovered (e.g., in differential privacy). We present a solution, Mantissa Bit Manipulation (MBM), that is orders of magnitude faster than the current state-of-the-art, applicable to most continuous probability distributions and to all floating-point number formats.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690347",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Poster: Detecting Ransomware Attacks by Analyzing Replicated Block Snapshots Using Neural Networks",
        "authors": "Hong, Seok Min; Kim, Beom Heyn; Mannan, Mohammad",
        "keywords": "Ransomware Detection (勒索软件检测) - 恶意行为识别与防御\nNeural Networks (神经网络) - 人工智能模型分析\nCloud Antivirus (云杀毒) - 虚拟环境安全防护\n选定的主题标签名称",
        "abstract": "Cloud antivirus solutions address limitations of host-based malware detection such as extensive resource consumption. However, they remain vulnerable to sophisticated polymorphic and privileged malware. Also, existing solutions are not suitable to defend against destructive ransomware attacks. We propose an enhancement to existing cloud antivirus solutions that enables deep learning-based block snapshot analysis to detect evasive and privileged ransomware in virtualized environment without requiring any hardware support. Preliminary results validate the proposed approach.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691399",
        "pub_year": "2024",
        "theme_label": "3.7 恶意代码分析与防护"
    },
    {
        "title": "Spec-o-Scope: Cache Probing at Cache Speed",
        "authors": "Horowitz, Gal; Ronen, Eyal; Yarom, Yuval",
        "keywords": "Microarchitectural Side Channel (微架构侧信道) - 利用硬件特性泄露敏感信息\nTransient Execution (瞬态执行) - 指令乱序执行引发安全漏洞\nCache Timing Attack (缓存时序攻击) - 通过缓存访问时间推测数据",
        "abstract": "Over the last two decades, microarchitectural side channels have been the focus of a large body of research on the development of new attack techniques, exploiting them to attack various classes of targets and designing mitigations. One line of work focuses on increasing the speed of the attacks, achieving higher levels of temporal resolution that can allow attackers to learn finer-grained information. The most recent addition to this line of work is Prime+ Scope [CCS '21], which only requires a single access to the L1 cache to confirm the absence of victim activity in a cache set. While significantly faster than prior attacks, Prime+Scope is still an order of magnitude slower than cache access. In this work, we set out to close this gap.We draw on techniques from research into microarchitectural weird gates, software constructs that exploit transient execution to perform arbitrary computation on cache state. We design the Speco-Scope gate, a new weird gate that performs 10 cache probes in quick succession, and forms the basis for our eponymous attack. Our Spec-o-Scope attack achieves an order of magnitude improvement in temporal resolution compared to the previous state-of-the-art of Prime+Scope, reducing the measurement time from approximate to 70 cycles to only 5 - only one cycle more than an L1 cache access. We experimentally verify that our attack can detect timing differences in a 5 cycle resolution. Finally, using our Spec-o-Scope attack, we show the first microarchitectural side-channel attack on an unmodified AES S-box-based implementation, which uses generic CPU features and does not require manipulation of the operating system's scheduler.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690313",
        "pub_year": "2024",
        "theme_label": "3.2.1 芯片安全"
    },
    {
        "title": "ERASER: Machine Unlearning in MLaaS via an Inference Serving-Aware Approach",
        "authors": "Hu, Yuke; Lou, Jian; Liu, Jiaqi; Ni, Wangze; Lin, Feng; Qin, Zhan; Ren, Kui",
        "keywords": "Machine Unlearning (机器遗忘) - 模型数据删除技术\nInference Service Obsolescence (推理服务过时) - 影响模型更新问题\nPrivacy Vulnerability (隐私漏洞) - 数据保护风险隐患\n选定的主题标签名称",
        "abstract": "Over the past years, Machine Learning-as-a-Service (MLaaS) has received a surging demand for supporting Machine Learning-driven services to offer revolutionized user experience across diverse application areas. MLaaS provides inference service with low inference latency based on an ML model trained using a dataset collected from numerous individual data owners. Recently, for the sake of data owners' privacy and to comply with the right to be forgotten (RTBF) as enacted by data protection legislation, many machine unlearning methods have been proposed to remove data owners' data from trained models upon their unlearning requests. However, despite their promising efficiency, almost all existing machine unlearning methods handle unlearning requests independently from inference requests, which unfortunately introduces a new security issue of inference service obsolescence and a privacy vulnerability of undesirable exposure for machine unlearning in MLaaS.In this paper, we propose the ERASER framework for machinE unleaRning in MLaAS via an inferencE seRving-aware approach. ERASER strategically chooses appropriate unlearning execution timing to address the inference service obsolescence issue. A novel inference consistency certification mechanism is proposed to avoid the violation of RTBF principle caused by postponed unlearning executions, thereby mitigating the undesirable exposure vulnerability. ERASER offers three groups of design choices to allow for tailor-made variants that best suit the specific environments and preferences of various MLaaS systems. Extensive empirical evaluations across various settings confirm ERASER's effectiveness, e.g., it can effectively save up to 99% of inference latency and 31% of computation overhead over the inference-oblivion baseline.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670398",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Detecting Broken Object-Level Authorization Vulnerabilities in Database-Backed Applications",
        "authors": "Huang, Yongheng; Shi, Chenghang; Lu, Jie; Li, Haofeng; Meng, Haining; Li, Lian",
        "keywords": "BOLA Vulnerability (越权访问漏洞) - 数据库应用中的权限验证缺陷\nObject-Level Authorization (对象级授权) - 控制数据对象访问的机制\nStatic and SQL Analysis (静态与SQL分析) - 检测漏洞的混合分析方法\n选定的主题标签名称",
        "abstract": "Broken object-level authorization (BOLA) vulnerabilities are among the most critical security risks facing database-backed applications. However, there is still a significant gap in our systematic understanding of these vulnerabilities. To bridge this gap, we conducted an in-depth study of 101 real-world BOLA vulnerabilities from open-source applications. Our study revealed the four most common object-level authorization models in database-backed application.The insights gained from our study inspired the development of a new tool called BolaRay. This tool employs a combination of SQL and static analysis to automatically infer the distinct types of object-level authorization models, and subsequently verify whether existing implementations enforce appropriate checks for these models. We evaluated BolaRay using 25 popular database-backed applications, which led to the identification of 193 true vulnerabilities, including 178 vulnerabilities that have never been reported before, at a false positive rate of 21.86%. We reported all newly identified vulnerabilities to the corresponding maintainers. To date, 155 vulnerabilities have been confirmed, with 52 CVE IDs",
        "doi": "https://dl.acm.org/doi/nan",
        "pub_year": "2024",
        "theme_label": "数据库安全"
    },
    {
        "title": "A General Framework for Data-Use Auditing of ML Models",
        "authors": "Huang, Zonghao; Gong, Neil Zhenqiang; Reiter, Michael K.",
        "keywords": "Data-Use Auditing (数据使用审计) - 审计训练数据来源与使用情况\nMembership Inference (成员推断) - 推断数据是否参与模型训练\nSequential Hypothesis Testing (序贯假设检验) - 基于统计的逐步验证方法",
        "abstract": "Auditing the use of data in training machine-learning (ML) models is an increasingly pressing challenge, as myriad ML practitioners routinely leverage the effort of content creators to train models without their permission. In this paper, we propose a general method to audit an ML model for the use of a data-owner's data in training, without prior knowledge of the ML task for which the data might be used. Our method leverages any existing black-box membership inference method, together with a sequential hypothesis test of our own design, to detect data use with a quantifiable, tunable false-detection rate. We show the effectiveness of our proposed framework by applying it to audit data use in two types of ML models, namely image classifiers and foundation models.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690226",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "PLEAK: Prompt Leaking Attacks against Large Language Model Applications",
        "authors": "Hui, Bo; Yuan, Haolin; Gong, Neil; Burlina, Philippe; Cao, Yinzhi",
        "keywords": "Prompt Leaking (提示泄露) - 窃取系统提示信息的攻击方法\nLarge Language Models Security (大语言模型安全) - 保障LLM应用的安全机制\nAdversarial Query Optimization (对抗查询优化) - 生成用于攻击的优化查询",
        "abstract": "Large Language Models (LLMs) enable a new ecosystem with many downstream applications, called LLM applications, with different natural language processing tasks. The functionality and performance of an LLM application highly depend on its system prompt, which instructs the backend LLM on what task to perform. Therefore, an LLM application developer often keeps a system prompt confidential to protect its intellectual property. As a result, a natural attack, called prompt leaking, is to steal the system prompt from an LLM application, which compromises the developer's intellectual property. Existing prompt leaking attacks primarily rely on manually crafted queries, and thus achieve limited effectiveness.In this paper, we design a novel, closed-box prompt leaking attack framework, called PLEAK, to optimize an adversarial query such that when the attacker sends it to a target LLM application, its response reveals its own system prompt. We formulate finding such an adversarial query as an optimization problem and solve it with a gradient-based method approximately. Our key idea is to break down the optimization goal by optimizing adversary queries for system prompts incrementally, i.e., starting from the first few tokens of each system prompt step by step until the entire length of the system prompt.We evaluate PLEAK in both offline settings and for real-world LLM applications, e.g., those on Poe, a popular platform hosting such applications. Our results show that PLEAK can effectively leak system prompts and significantly outperforms not only baselines that manually curate queries but also baselines with optimized queries that are modified and adapted from existing jailbreaking attacks. We responsibly reported the issues to Poe and are still waiting for their response. Our implementation is available at this repository: https://github.com/BHui97/PLeak.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670370",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Poster: The Concept of a System for Automatic Detection and Correction of Vulnerabilities in the Source Code",
        "authors": "Hyla, Tomasz; Wawrzyniak, Natalia",
        "keywords": "Vulnerability Detection (漏洞检测) - 源代码安全缺陷识别\nArtificial Intelligence (人工智能) - 提升检测精度与能力\nSource Code Analysis (源代码分析) - 自动化安全审查关键\n选定的主题标签名称",
        "abstract": "Defects in the source code that affect security are one of the main elements used to carry out cyber attacks. Examining source code for vulnerabilities is a difficult and expensive process. As a result, specialized software is needed for this. Due to the development of various artificial intelligence methods, improving existing vulnerability detection methods is possible. In particular, it is possible to reduce the number of false positives and enable the detection of complex vulnerabilities that require understanding the broader context of the code. The article presents the concept of a system for automatic analysis of vulnerabilities in source code, along with the challenges and problems related to its design and use.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691417",
        "pub_year": "2024",
        "theme_label": "3.8.1 漏洞挖掘与逆向分析"
    },
    {
        "title": "Metric Differential Privacy at the User-Level via the Earth Mover's Distance",
        "authors": "Imola, Jacob; Chowdhury, Amrita Roy; Chaudhuri, Kamalika",
        "keywords": "Metric Differential Privacy (度量差分隐私) - 隐私保护的度量方法\nEarth Mover's Distance (地球移动距离) - 数据分布差异度量\nUser-Level Privacy (用户级隐私) - 以用户为粒度的隐私保护",
        "abstract": "Metric differential privacy (DP) provides heterogeneous privacy guarantees based on a distance between the pair of inputs. It is a widely popular notion of privacy since it captures the natural privacy semantics for many applications (such as, for location data) and results in better utility than standard DP. However, prior work in metric DP has primarily focused on the item-level setting where every user only reports a single data item. A more realistic setting is that of user-level DP where each user contributes multiple items and privacy is then desired at the granularity of the user's entire contribution. In this paper, we initiate the study of one natural definition of metric DP at the user-level. Specifically, we use the earth-mover's distance (d(EM)) as our metric to obtain a notion of privacy as it captures both the magnitude and spatial aspects of changes in a user's data.We make three main technical contributions. First, we design two novel mechanisms under d(EM)-DP to answer linear queries and item-wise queries. Specifically, our analysis for the latter involves a generalization of the privacy amplification by shuffling result which may be of independent interest. Second, we provide a black-box reduction from the general unbounded to bounded d(EM)-DP (size of the dataset is fixed and public) with a novel sampling based mechanism. Third, we show that our proposed mechanisms can provably provide improved utility over user-level DP, for certain types of linear queries and frequency estimation.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690363",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Poster: Patching NSEC3-Encloser: The Good, the Bad, and the Ugly",
        "authors": "Jacobsen, Oliver; Schulmann, Haya",
        "keywords": "NSEC3 (哈希算法) - DNSSEC安全机制\nDNS resolver (域名解析器) - 处理DNS查询服务\nExhaustion attack (资源耗尽攻击) - 消耗系统计算资源",
        "abstract": "This paper evaluates the effectiveness of patches designed to mitigate the NSEC3-encloser attack in DNS resolvers. NSEC3, used in DNSSEC to authenticate non-existence of records, can be exploited to exhaust resolver resources through excessive SHA-1 hashing. Despite recent patches, our study reveals that major DNS resolvers remain vulnerable. We test the NSEC3 exhaustion attacks against pre- and post-patch versions of popular DNS resolvers (Unbound, BIND9, PowerDNS, and Knot Resolver), and observe a 72-fold increase in CPU instructions during attacks. PowerDNS 5.0.5 and Knot Resolver 5.7.3 showed improvements, limiting CPU load with strict hash limits. Conversely, BIND9 exhibited marginal improvement, and Unbound 1.20.0 experienced increased CPU load. At an attack rate of 150 malicious NSEC3 records per second, benign DNS request loss rates ranged from 2.7% to 30%. Our study indicates the need for robust countermeasures to address NSEC3 vulnerabilities.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691395",
        "pub_year": "2024",
        "theme_label": "网络与系统安全"
    },
    {
        "title": "Poster: Whether We Are Good Enough to Detect Server-Side Request Forgeries in PHP-native Applications?",
        "authors": "Ji, Yuchen; Dai, Ting; Tang, Yutian; He, Jingzhu",
        "keywords": "Static Taint Analysis (静态污点分析) - 程序分析检测漏洞\nServer-Side Request Forgery (服务器端请求伪造) - Web应用安全威胁\nPHP Application Security (PHP应用安全) - 保障脚本语言安全",
        "abstract": "Server-side request forgeries (SSRFs) are inevitable in PHP web applications. Existing static taint analysis tools for PHP suffer from both high rates of false positives and false negatives in detecting SSRF because they do not incorporate application-specific sources and sinks, account for PHP's dynamic type characteristics, and include SSRF-specific taint analysis rules, leading to over-tainting and under-tainting. In this work, we propose a technique to accurately detect SSRF vulnerabilities in PHP web applications. First, we extract both PHP built-in and application-specific functions as candidate source and sink functions. Second, we extract explicit and implicit function calls to construct applications' call graphs. Third, we perform a taint analysis based on a set of rules that prevent over-tainting and under-tainting. We have implemented a prototype and evaluated it with different types of PHP web applications. Our preliminary experiment shows that we detect 24 SSRF vulnerabilities in 13 different types of applications. 20 of the vulnerabilities are known and 4 of the vulnerabilities are new.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691419",
        "pub_year": "2024",
        "theme_label": "系统安全测评"
    },
    {
        "title": "HomeRun: High-efficiency Oblivious Message Retrieval, Unrestricted",
        "authors": "Jia, Yanxue; Madathil, Varun; Kate, Aniket",
        "keywords": "Oblivious Message Retrieval (不经意消息检索) - 隐私保护通信协议\nBlockchain Privacy (区块链隐私) - 提升链上数据匿名性\nSecure Multi-Server Protocols (安全多服务器协议) - 依赖非共谋服务器实现安全\n选定的主题标签名称",
        "abstract": "In the realm of privacy-preserving blockchain applications such as Zcash, oblivious message retrieval (OMR) enables recipients to privately access messages directed to them on blockchain nodes (or bulletin board servers). OMR prevents servers from linking a message and its corresponding recipient's address, thereby safeguarding recipient privacy. Several OMR schemes have emerged recently to meet the demands of these privacy-centric blockchains; however, we observe that existing solutions exhibit shortcomings in various critical aspects and may only achieve certain objectives inefficiently, sometimes relying on trusted hardware, thereby impacting their practical utility. This work introduces a novel OMR protocol, HomeRun, that leverages two semi-honest, non-colluding servers to excel in both performance and security attributes as compared to the current state-of-the-art.HomeRun stands out by providing unlinkability across multiple requests for the same recipient's address. Moreover, it does not impose a limit on the number of pertinent messages that can be received by a recipient, which thwarts message balance exhaustion attacks and enhances system usability. HomeRun also empowers servers to regularly delete the retrieved messages and the associated auxiliary data, which mitigates the constantly increasing computation costs and storage costs incurred by servers. Remarkably, none of the existing solutions offer all of these features collectively. Finally, thanks to our judicious use of highly efficient cryptographic building blocks, HomeRun is highly performant: Specifically, the total runtime of servers in HomeRun is 3830x less than that in the work by Liu et al. (CRYPTO '22) based on fully-homomorphic encryption, and at least 1459x less than that in the design by Madathil et al. (USENIX Security '22) based on two semi-honest and non-colluding servers, using a single thread in a WAN setting.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670381",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "RISiren: Wireless Sensing System Attacks via Metasurface",
        "authors": "Jiang, Chenghan; Yang, Jinjiang; Li, Xinyi; Li, Qi; Zhang, Xinyu; Ren, Ju",
        "keywords": "Wireless Sensing (无线感知) - 利用无线信号感知环境变化\nMetasurface (超构表面) - 可编程材料调控电磁波特性\nBlack-box Attack (黑盒攻击) - 无需内部信息的隐蔽攻击",
        "abstract": "After over a decade of intensive research, wireless sensing technology is nearing commercialization. However, the inherent openness of the wireless medium exposes this technology to security flaws and vulnerabilities. In this paper, we introduce RISiren to reveal the risk. RISiren is a pioneering end-to-end black-box attack system leveraging programmable metasurface with a high level of stealthiness. The key insight of RISiren lies in its ability to generate malicious multipath using metasurface, thereby disrupting wireless channel metrics influenced by genuine human activities and facilitating malicious attacks. To ensure the effectiveness of RISiren, we propose a novel metasurface configuration strategy aiming at creating human-like activities that stem from a comprehensive analysis of how human activities impact wireless signal propagation. We have implemented and validated RISiren using commercial Wi-Fi devices. Our evaluation involved testing our attack strategies against five state-of-the-art systems (including five different types of recognition frameworks) representative of the current landscape. The experimental results show that the adversarial wireless signals generated by RISiren achieve over 90% attack success rate on average, and remain robust and effective across different environments and deployment setups, including through wall attack scenarios.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690186",
        "pub_year": "2024",
        "theme_label": "网络与系统安全"
    },
    {
        "title": "BinPRE: Enhancing Field Inference in Binary Analysis Based Protocol Reverse Engineering",
        "authors": "Jiang, Jiayi; Zhang, Xiyuan; Wan, Chengcheng; Chen, Haoyi; Sun, Haiying; Su, Ting",
        "keywords": "Binary Analysis (二进制分析) - 程序逆向与安全研究\nProtocol Reverse Engineering (协议逆向工程) - 协议结构与语义推断\nField Inference (字段推断) - 数据格式与语义识别\n选定的主题标签名称",
        "abstract": "Protocol reverse engineering (PRE) aims to infer the specification of network protocols when the source code is not available. Specifically, field inference is one crucial step in PRE to infer the field formats and semantics. To perform field inference, binary analysis based PRE techniques are one major approach category. However, such techniques face two key challenges - (1) the format inference is fragile when the logics of processing input messages may vary among different protocol implementations, and (2) the semantic inference is limited by inadequate and inaccurate inference rules.To tackle these challenges, we present BinPRE, a binary analysis based PRE tool. BINPRE incorporates (1) an instruction-based semantic similarity analysis strategy for format extraction; (2) a novel library composed of atomic semantic detectors for improving semantic inference adequacy; and (3) a cluster-and-refine paradigm to further improve semantic inference accuracy. We have evaluated BinPRE against five existing PRE tools, including Polyglot, AUTOFORMAT, TUPNI, BINARYINFERNO and DYNPRE. The evaluation results on eight widely-used protocols show that BinPRE outperforms the prior PRE tools in both format and semantic inference. BinPRE achieves the perfection of 0.73 on format extraction and the F1-score of 0.74 (0.81) on semantic inference of types (functions), respectively. The field inference results of BINPRE have helped improve the effectiveness of protocol fuzzing by achieving 5 similar to 29% higher branch coverage, compared to those of the best prior PRE tool. BINPRE has also helped discover one new zero-day vulnerability, which otherwise cannot be found.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690299",
        "pub_year": "2024",
        "theme_label": "3.8.1 漏洞挖掘与逆向分析"
    },
    {
        "title": "PG: Byzantine Fault-Tolerant and Privacy-Preserving Sensor Fusion With Guaranteed Output Delivery",
        "authors": "Jin, Chenglu; Yin, Chao; van Dijk, Marten; Duan, Sisi; Massacci, Fabio; Reiter, Michael K.; Zhang, Haibin",
        "keywords": "Byzantine Fault Tolerance (拜占庭容错) - 容错机制保障系统可靠性\nPrivacy-Preserving (隐私保护) - 保护数据隐私不被泄露\nSensor Fusion (传感器融合) - 多源传感数据整合分析",
        "abstract": "We design and implement PG, a Byzantine fault-tolerant and privacy-preserving multi-sensor fusion system. PG is flexible and extensible, supporting a variety of fusion algorithms and application scenarios.On the theoretical side, PG develops and unifies techniques from dependable distributed systems and modern cryptography. PG can provably protect the privacy of individual sensor inputs and fusion results. In contrast to prior works, PG can provably defend against pollution attacks and guarantee output delivery, even in the presence of malicious sensors that may lie about their inputs, contribute ill-formed inputs, and provide no inputs at all to sway the final result, and in the presence of malicious servers serving as aggregators.On the practical side, we implement PG in the client-server-sensor setting. Moreover, we deploy PG in a cloud-based system with 261 sensors and a cyber-physical system with 19 resource-constrained sensors. In both settings, we show that PG is efficient and scalable in both failure-free and failure scenarios.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670343",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Elephants Do Not Forget: Differential Privacy with State Continuity for Privacy Budget",
        "authors": "Jin, Jiankai; Chuengsatiansup, Chitchanok; Murray, Toby; Rubinstein, Benjamin I. P.; Yarom, Yuval; Ohrimenko, Olga",
        "keywords": "Differential Privacy (差分隐私) - 隐私保护数据分析方法\nPrivacy Budget (隐私预算) - 控制隐私泄露总量机制\nTrusted Execution Environment (可信执行环境) - 硬件级安全隔离运行环境",
        "abstract": "Current implementations of differentially-private (DP) systems either lack support to track the global privacy budget consumed on a dataset, or fail to faithfully maintain the state continuity of this budget. We show that failure to maintain a privacy budget enables an adversary to mount replay, rollback and fork attacks - obtaining answers to many more queries than what a secure system would allow. As a result the attacker can reconstruct secret data that DP aims to protect - even if DP code runs in a Trusted Execution Environment (TEE). We propose ELEPHANTDP, a system that aims to provide the same guarantees as a trusted curator in the global DP model would, albeit set in an untrusted environment. Our system relies on a state continuity module to provide protection for the privacy budget and a TEE to faithfully execute DP code and update the budget. To provide security, our protocol makes several design choices including the content of the persistent state and the order between budget updates and query answers. We prove that ELEPHANTDP provides liveness (i.e., the protocol can restart from a correct state and respond to queries as long as the budget is not exceeded) and DP confidentiality (i.e., an attacker learns about a dataset as much as it would from interacting with a trusted curator). Our implementation and evaluation of the protocol use Intel SGX as a TEE to run the DP code and a network of TEEs to maintain state continuity. Compared to an insecure baseline, we observe 1.1-3.2x overheads and lower relative overheads for complex DP queries.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670281",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Pulsar: Secure Steganography for Diffusion Models",
        "authors": "Jois, Tushar M.; Beck, Gabrielle; Kaptchuk, Gabriel",
        "keywords": "Steganography (隐写术) - 信息隐藏技术\nDiffusion Models (扩散模型) - 图像生成方法\nSecure Communication (安全通信) - 加密传输保障",
        "abstract": "Widespread efforts to subvert access to strong cryptography has renewed interest in steganography, the practice of embedding sensitive messages in mundane cover messages. Recent efforts at provably secure steganography have focused on text-based generative models and cannot support other types of models, such as diffusion models, which are used for high-quality image synthesis. In this work, we study securely embedding steganographic messages into the output of image diffusion models. We identify that the use of variance noise during image generation provides a suitable steganographic channel. We develop our construction, Pulsar, by building optimizations to make this channel practical for communication. Our implementation of Pulsar is capable of embedding approximate to 320-613 bytes (on average) into a single image without altering the distribution of the generated image, all in < 3 seconds of online time on a laptop. In addition, we discuss how the results of Pulsar can inform future research into diffusion models. Pulsar shows that diffusion models are a promising medium for steganography and censorship resistance.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690218",
        "pub_year": "2024",
        "theme_label": "信息隐藏"
    },
    {
        "title": "Poster: Synchronization Concerns of DNS Integrations",
        "authors": "Kaizer, Andrew; Naciri, Will; Sheth, Swapneel",
        "keywords": "DNS Integration (DNS集成) - 域名系统与其他应用的结合\nSynchronization Risks (同步风险) - 注册状态不一致带来的隐患\nIETF Draft Feedback (IETF草案反馈) - 对标准草案提出改进建议",
        "abstract": "The widespread use of the Domain Name System (DNS) as a namespace for websites, email addresses, and other applications has led to proposals for integrating domain names into additional applications. An important quality for DNS integrations is synchronization, i.e., there is evidence that a current registrant of a domain name associated with the integration has chosen to participate in the integration. Failure to maintain synchronization may result in avoidable risks to users, however no study has detailed the scope of synchronization concerns across DNS integrations. To that end, this paper presents preliminary results from three novel DNS integrations that show between 1% and 40% of integrated domain name are not clearly synchronized and as such further study is merited to understand the risks and solutions that may be available. Furthermore, feedback on an IETF draft is proposed as one avenue through which researchers could provide input to address this problem space.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691415",
        "pub_year": "2024",
        "theme_label": "网络基础设施安全"
    },
    {
        "title": "Blockchain Bribing Attacks and the Efficacy of Counterincentives",
        "authors": "Karakostas, Dimitris; Kiayias, Aggelos; Zacharias, Thomas",
        "keywords": "Bribing Attacks (贿赂攻击) - 恶意激励影响行为\nGame Theory (博弈论) - 策略互动决策分析\nProof-of-Stake Blockchain (权益证明区块链) - 基于持币量的共识机制",
        "abstract": "We analyze bribing attacks in Proof-of-Stake distributed ledgers from a game theoretic perspective. In bribing attacks, an adversary offers participants a reward in exchange for instructing them howto behave, with the goal of attacking the protocol's properties. Specifically, our work focuses on adversaries that target blockchain safety. We consider two types of bribing, depending on how the bribes are awarded: i) guided bribing, where the bribe is given as long as the bribed party behaves as instructed; ii) effective bribing, where bribes are conditional on the attack's success, w.r.t. well-defined metrics. We analyze each type of attack in a game theoretic setting and identify relevant equilibria. In guided bribing, we show that the protocol is not an equilibrium and then describe good equilibria, where the attack is unsuccessful, and a negative one, where all parties are bribed such that the attack succeeds. In effective bribing, we show that both the protocol and the all bribed setting are equilibria. Using the identified equilibria, we then compute bounds on the Prices of Stability and Anarchy. Our results indicate that additional mitigations are needed for guided bribing, so our analysis concludes with incentive-based mitigation techniques, namely slashing and dilution. Here, we present two positive results, that both render the protocol an equilibrium and achieve maximal welfare for all parties, and a negative result, wherein an attack becomes more plausible if it severely affects the ledger's token's market price.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670330",
        "pub_year": "2024",
        "theme_label": "8.1 共识机制及安全"
    },
    {
        "title": "Complete Knowledge: Preventing Encumbrance of Cryptographic Secrets",
        "authors": "Kelkar, Mahimna; Babel, Kushal; Daian, Philip",
        "keywords": "Complete Knowledge (完全知识) - 证明秘密未被限制使用\nEncumbrance of Secrets (秘密受限使用) - 秘密访问受条件限制\nTrusted Execution Environments (可信执行环境) - 硬件级安全隔离执行环境",
        "abstract": "Most cryptographic protocols model a player's knowledge of secrets in a simple way. Informally, the player knows a secret in the sense that she can directly furnish it as a (private) input to a protocol, e.g., to digitally sign a message.The growing availability of Trusted Execution Environments (TEEs) and multiparty computation (MPC), however, undermines this model of knowledge. Such tools can encumber a secret sk and permit a chosen player to access sk conditionally, without actually knowing sk. By permitting selective access to sk by an adversary, encumbrance of secrets can enable vote-selling in cryptographic voting schemes, illegal sale of credentials for online services, and erosion of deniability in anonymous messaging systems.Unfortunately, existing proof-of-knowledge protocols fail to demonstrate that a secret is unencumbered. We therefore introduce and formalize a new notion called complete knowledge (CK). A proof (or argument) of CK shows that a prover does not just know a secret, but also has fully unencumbered knowledge, i.e., unrestricted ability to use the secret.We introduce two practical CK schemes that use special-purpose hardware, specifically TEEs and off-the-shelf mining ASICs. We prove the security of these schemes and explore their practical deployment with a complete, open-source, end-to-end prototype with smart-contract verification that supports both. We show how CK can address encumbrance attacks identified in previous work. Finally, we introduce two new applications enabled by CK that involve proving ownership of blockchain assets.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690273",
        "pub_year": "2024",
        "theme_label": "密码学及应用"
    },
    {
        "title": "RSA-Based Dynamic Accumulator without Hashing into Primes",
        "authors": "Kemmoe, Victor Youdom; Lysyanskaya, Anna",
        "keywords": "Cryptographic Accumulator (密码累积器) - 动态集合成员证明机制\nRSA Cryptosystem (RSA密码系统) - 非对称加密与数字签名基础\nProof of Exponentiation (指数证明) - 提升验证效率的关键技术\n选定的主题标签名称",
        "abstract": "A cryptographic accumulator is a compact data structure for representing a set of elements coming from some domain. It allows for a compact proof of membership and, in the case of a universal accumulator, non-membership of an element.. in the data structure. A dynamic accumulator, furthermore, allows elements to be added to and deleted from the accumulator.Previously known RSA-based dynamic accumulators were too slow in practice because they required that an element in the domain be represented as a prime number. Accumulators based on settings other than RSA had other drawbacks such as requiring a prohibitively large common reference string or a trapdoor, or not permitting deletions.In this paper, we construct an RSA-based dynamic accumulator that does not require that the accumulated elements be represented as primes and show how it can be extended into a universal accumulator. We also show how to aggregate membership and non-membership witnesses and batch additions and deletions. We demonstrate that, for 112-bit, 128-bit, and 192-bit security, the efficiency gains compared to previously known RSA-based accumulators are substantial, and, for the first time, make cryptographic accumulators a viable candidate for a certificate revocation mechanism as part of a WebPKI-type system. To achieve an efficient verification time for aggregated witnesses, we introduce a variant of Wesolowski's proof of exponentiation ( Journal of Cryptology 2020) that does not require hashing into primes.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690199",
        "pub_year": "2024",
        "theme_label": "2.1.2 计算数论"
    },
    {
        "title": "Demo: SGCode: A Flexible Prompt-Optimizing System for Secure Generation of Code",
        "authors": "Khiem Ton; Nhi Nguyen; Nazzal, Mahmoud; Khreishah, Abdallah; Borcea, Cristian; NhatHai Phan; Jin, Ruoming; Khalil, Issa; Shen, Yelong",
        "keywords": "Prompt Optimization (提示优化) - 优化模型输入以提升效果\nSecure Code Generation (安全代码生成) - 生成无漏洞的程序代码\nLarge Language Models (大语言模型) - 基于海量数据训练的语言模型",
        "abstract": "This paper introduces SGCode, a flexible prompt-optimizing system to generate secure code with large language models (LLMs). SGCode integrates recent prompt-optimization approaches with LLMs in a unified system accessible through front-end and back-end APIs, enabling users to 1) generate secure code, which is free of vulnerabilities, 2) review and share security analysis, and 3) easily switch from one prompt optimization approach to another, while providing insights on model and system performance. We populated SGCode on an AWS server with PromSec, an approach that optimizes prompts by combining an LLM and security tools with a lightweight generative adversarial graph neural network to detect and fix security vulnerabilities in the generated code. Extensive experiments show that SGCode is practical as a public tool to gain insights into the trade-offs between model utility, secure code generation, and system cost. SGCode has only a marginal cost compared with prompting LLMs. SGCode is available at: SGCode.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691367",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Nakamoto Consensus under Bounded Processing Capacity",
        "authors": "Kiffer, Lucianna; Neu, Joachim; Sridhar, Srivatsan; Zohar, Aviv; Tse, David",
        "keywords": "Nakamoto Consensus (中本聪共识) - 区块链核心共识机制\nBounded Processing Capacity (有界处理能力) - 节点资源限制模型\nTeasing Attack (诱导攻击) - 利用拥堵的新攻击策略",
        "abstract": "For Nakamoto's longest-chain consensus protocol, whose proof-of-work (PoW) and proof-of-stake (PoS) variants power major blockchains such as Bitcoin and Cardano, we revisit the classic problem of the security-performance tradeoff: Given a network of nodes with finite communication- and computation-resources, against what fraction of adversary power is Nakamoto consensus (NC) secure for a given block production rate? State-of-the-art analyses of NC fail to answer this question, because their bounded-delay model does not capture the rate limits to nodes' processing of blocks, which cause congestion when blocks are released in quick succession. We develop a new analysis technique to prove a refined security-performance tradeoff for PoW NC in a bounded-capacity model. In this model, we showthat, in contrast to the classic bounded-delay model, Nakamoto's private attack is no longer the worst attack, and a new attack we call the teasing strategy, that exploits congestion, is strictly worse. In PoS, equivocating blocks can exacerbate congestion, making traditional PoS NC insecure except at very low block production rates. To counter such equivocation spamming, we present a variant of PoS NC we call Blanking NC (BlaNC), which achieves the same resilience as PoW NC.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670347",
        "pub_year": "2024",
        "theme_label": "区块链及安全"
    },
    {
        "title": "Poster: Advanced Features for Real-Time Website Fingerprinting Attacks on Tor",
        "authors": "Kim, Donghoon; Booth, Andrew; Choo, Euijin; Hwang, Doosung",
        "keywords": "Website Fingerprinting (网站指纹攻击) - 网络流量识别技术\nReal-Time Attack (实时攻击) - 实战环境下的攻击方法\nFeature Engineering (特征工程) - 提升攻击效率的关键\n选定的主题标签名称",
        "abstract": "The Tor network has been identified as vulnerable to website fingerprinting (WF) attacks. Existing WF attacks have proven effective against the Tor network. However, prior research has mostly been limited to controlled experimental settings, leading to questions about the practicality of WF attacks in real-time environments. Recent advancements in feature engineering and machine learning aim to address this by exploring real-world scenarios, though they often overlook the preprocessing time required to design features from raw network traffic data. To tackle these issues, this research focuses on developing more efficient and high-performing feature vectors for WF attacks in real-time by analyzing previously successful feature vectors. The results indicate that advanced features, particularly those in a compact feature set, deliver competitive performance with reduced training times for real-time WF attacks. This study enhances our understanding of the feasibility of real-time WF attacks on Tor networks in practical settings and may inform future security improvements.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691373",
        "pub_year": "2024",
        "theme_label": "3.9.1 攻击行为监测发现"
    },
    {
        "title": "Simpler and Faster BFV Bootstrapping for Arbitrary Plaintext Modulus from CKKS",
        "authors": "Kim, Jaehyung; Seo, Jinyeong; Song, Yongsoo",
        "keywords": "Fully Homomorphic Encryption (全同态加密) - 支持密文直接计算\nBootstrapping (自举技术) - 同态加密中的噪声消除\nCKKS Scheme (CKKS方案) - 近似同态加密方法\n选定的主题标签名称",
        "abstract": "Bootstrapping is currently the only known method for constructing fully homomorphic encryptions. In the BFV scheme specifically, bootstrapping aims to reduce the error of a ciphertext while preserving the encrypted plaintext. The existing BFV bootstrapping methods follow the same pipeline, relying on the evaluation of a digit extraction polynomial to annihilate the error located in the least significant digits. However, due to its strong dependence on performance, bootstrapping could only utilize a limited form of plaintext modulus, such as a power of a small prime number.In this paper, we present a novel approach to instantiate BFV bootstrapping, distinct from the previous digit extraction-based method. The core idea of our bootstrapping is to utilize CKKS bootstrapping as a subroutine, so the performance of our method mainly depends on the underlying CKKS bootstrapping rather than the plaintext modulus.We implement our method at a proof-of-concept level to provide concrete benchmark results. When performing the bootstrapping operation for a 51-bits plaintext modulus, our method improves the previous digit extraction-based method by a factor of 37.9 in latency and 29.4 in throughput. Additionally, we achieve viable bootstrapping performance for large plaintext moduli, such as 144-bits and 234-bits, which has never been measured before.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670302",
        "pub_year": "2024",
        "theme_label": "6.3 同态加密"
    },
    {
        "title": "Using AI Assistants in Software Development: A Qualitative Study on Security Practices and Concerns",
        "authors": "Klemmer, Jan H.; Horstmann, Stefan Albert; Patnaik, Nikhil; Ludden, Cordelia; Burton, Cordell, Jr.; Powers, Carson; Massacci, Fabio; Rahman, Akond; Votipka, Daniel; Lipford, Heather Richter; Rashid, Awais; Naiakshina, Alena; Fahl, Sascha",
        "keywords": "AI辅助开发 (AI-assisted Development) - 利用人工智能工具辅助软件开发\n安全实践 (Security Practices) - 软件开发中的安全保障措施\n代码安全 (Code Security) - 确保代码无安全漏洞的过程\n选定的主题标签名称",
        "abstract": "Following the recent release of AI assistants, such as OpenAI's ChatGPT and GitHub Copilot, the software industry quickly utilized these tools for software development tasks, e.g., generating code or consulting AI for advice. While recent research has demonstrated that AI-generated code can contain security issues, how software professionals balance AI assistant usage and security remains unclear. This paper investigates how software professionals use AI assistants in secure software development, what security implications and considerations arise, and what impact they foresee on security in software development. We conducted 27 semi-structured interviews with software professionals, including software engineers, team leads, and security testers. We also reviewed 190 relevant Reddit posts and comments to gain insights into the current discourse surrounding AI assistants for software development. Our analysis of the interviews and Reddit posts finds that, despite many security and quality concerns, participants widely use AI assistants for security-critical tasks, e.g., code generation, threat modeling, and vulnerability detection. Participants' overall mistrust leads to checking AI suggestions in similar ways to human code. However, they expect improvements and, therefore, a heavier use of AI for security tasks in the future. We conclude with recommendations for software professionals to critically check AI suggestions, for AI creators to improve suggestion security and capabilities for ethical security tasks, and for academic researchers to consider generalpurpose AI in software development.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690283",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Stealing Maggie's Secrets-On the Challenges of IP Theft Through FPGA Reverse Engineering",
        "authors": "Klix, Simon; Albartus, Nils; Speith, Julian; Staat, Paul; Verstege, Alice; Wilde, Annika; Lammers, Daniel; Langheinrich, Joern; Kison, Christian; Sester-Wehle, Sebastian; Holcomb, Daniel; Paar, Christof",
        "keywords": "FPGA Reverse Engineering (现场可编程门阵列逆向工程) - 硬件安全分析技术\nIP Theft (知识产权窃取) - FPGA设计安全威胁\nNetlist Analysis (网表分析) - 逆向还原电路逻辑方法",
        "abstract": "Intellectual Property (IP) theft is a cause of major financial and reputational damage, reportedly in the range of hundreds of billions of dollars annually in the U.S. alone. Field Programmable Gate Arrays (FPGAs) are particularly exposed to IP theft, because their configuration file contains the IP in a proprietary format that can be mapped to a gate-level netlist with moderate effort. Despite this threat, the scientific understanding of this issue lacks behind reality, thereby preventing an in-depth assessment of IP theft from FPGAs in academia. We address this discrepancy through a real-world case study on a Lattice iCE40 FPGA found inside iPhone 7. Apple refers to this FPGA as Maggie. By reverse engineering the proprietary signal-processing algorithm implemented on Maggie, we generate novel insights into the actual efforts required to commit FPGA IP theft and the challenges an attacker faces on the way. Informed by our case study, we then introduce generalized netlist reverse engineering techniques that drastically reduce the required manual effort and are applicable across a diverse spectrum of FPGA implementations and architectures. We evaluate these techniques on six benchmarks that are representative of different FPGA applications and have been synthesized for Xilinx and Lattice FPGAs, as well as in an end-to-end white-box case study. Finally, we provide a comprehensive open-source tool suite of netlist reverse engineering techniques to foster future research, enable the community to perform realistic threat assessments, and facilitate the evaluation of novel countermeasures.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690235",
        "pub_year": "2024",
        "theme_label": "硬件安全"
    },
    {
        "title": "Skipping the Security Side Quests: A Qualitative Study on Security Practices and Challenges in Game Development",
        "authors": "Klostermeyer, Philip; Amft, Sabrina; Hoeltervennhoff, Sandra; Krause, Alexander; Busch, Niklas; Fahl, Sascha",
        "keywords": "Game Development Security (游戏开发安全) - 游戏开发中的安全实践研究\nSecurity Practices (安全实践) - 安全措施在游戏行业的应用\nChallenges and Priorities (挑战与优先级) - 资源限制下的安全决策",
        "abstract": "The video game market is one of the biggest for software products. Video game development has progressed in the last decades to complex and multifaceted endeavors. Games-as-a-Service significantly impacted distribution and gameplay, requiring providers and developers to consider factors beyond game functionality, including security and privacy. New security challenges emerged, including authentication, payment security, and user data or asset protection. However, the security community lacks in-depth insights into the security experiences, challenges, and practices of modern video game development. This paper aims to address this gap in research and highlights the criticality of considering security in the process. Therefore, we conducted 20 qualitative, semi-structured interviews with various roles of professional and skilled video game development experts, investigating awareness, priorities, knowledge, and practices regarding security in the industry through their first-hand experiences. We find that stakeholders are aware of the urgency of security and related issues. However, they often face obstacles, including a lack of money, time, and knowledge, which force them to put security issues lower in priority. We conclude our work by recommending how the game industry can incorporate security into its development processes while balancing other resources and priorities and illustrating ideas for future research.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690190",
        "pub_year": "2024",
        "theme_label": "人的安全行为与管理"
    },
    {
        "title": "Phantom: Untargeted Poisoning Attacks on Semi-Supervised Learning",
        "authors": "Knauer, Jonathan; Rieger, Phillip; Fereidooni, Hossein; Sadeghi, Ahmad-Reza",
        "keywords": "Poisoning Attacks (投毒攻击) - 数据污染影响模型训练\nSemi-Supervised Learning (半监督学习) - 利用少量标签提升模型性能\nAdversarial Machine Learning (对抗机器学习) - 研究模型安全与攻击防御",
        "abstract": "Deep Neural Networks (DNNs) can handle increasingly complex tasks, albeit they require rapidly expanding training datasets. Collecting data from platforms with user-generated content, such as social networks, has significantly eased the acquisition of large datasets for training DNNs. Despite these advancements, the manual labeling process remains a substantial challenge in terms of both time and cost. In response, Semi-Supervised Learning (SSL) approaches have emerged, where only a small fraction of the dataset needs to be labeled, leaving the majority unlabeled. However, leveraging data from untrusted sources like social networks also creates new security risks, as potential attackers can easily inject manipulated samples. Previous research on the security of SSL primarily focused on injecting backdoors into trained models, while less attention was given to the more challenging untargeted poisoning attacks. In this paper, we introduce Phantom, the first untargeted poisoning attack in SSL that disrupts the training process by injecting a small number of manipulated images into the unlabeled dataset. Unlike existing attacks, our approach only requires adding few manipulated samples, such as posting images on social networks, without the need to control the victim. Phantom causes SSL algorithms to overlook the actual images' pixels and to rely only on maliciously crafted patterns that Phantom superimposed on the real images. We show Phantom's effectiveness for six different datasets and 3 real-world social-media platforms (Facebook, Instagram, Pinterest). Already small fractions of manipulated samples (e.g., 5%) reduce the accuracy of the resulting model by 10%, with higher percentages leading to a performance comparable to a naive classifier. Our findings demonstrate the threat of poisoning user-generated content platforms, rendering them unsuitable for SSL in specific tasks.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690369",
        "pub_year": "2024",
        "theme_label": "人工智能安全"
    },
    {
        "title": "The Not-So-Silent Type: Vulnerabilities in Chinese IME Keyboards' Network Security Protocols",
        "authors": "Knockel, Jeffrey; Wang, Mona; Reichert, Zoe",
        "keywords": "Chinese IME Keyboards (中文输入法编辑器键盘) - 云输入法安全研究\nNetwork Security Protocols (网络安全协议) - 协议安全性分析\nKeystroke Privacy (击键隐私) - 敏感数据传输保护",
        "abstract": "Popular Chinese Input Method Editor (IME) keyboards almost universally feature cloud-based features that improve character prediction when typing. Handling such sensitive data (i.e., keystrokes) in transit demands security in transit. In this work, we perform a comprehensive security measurement of the Chinese IME keyboard ecosystem, investigating the network security of keystrokes sent in transit by popular Chinese IME keyboards from nine vendors. We studied the three most popular third-party keyboards, comprising 95.9% of the third-party keyboard market share in China, as well as the default Chinese IME keyboards pre-installed on six popular Android mobile device manufacturers in China. We found that the vast majority of IME keyboards utilize proprietary, non-TLS network encryption protocols. Our measurement revealed critical vulnerabilities in these encryption protocols from eight out of the nine vendors in which network attackers could completely reveal the contents of users' keystrokes in transit. We estimate that up to one billion users were affected by these vulnerabilities. Finally, we provide recommendations to various stakeholders to limit the harm from this existing set of vulnerabilities, as well as to prevent future vulnerabilities of this kind.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690302",
        "pub_year": "2024",
        "theme_label": "网络安全应急响应"
    },
    {
        "title": "Graphiti: Secure Graph Computation Made More Scalable",
        "authors": "Koti, Nishat; Kukkala, Varsha Bhat; Patra, Arpita; Gopal, Bhavish Raj",
        "keywords": "Secure Graph Computation (安全图计算) - 图结构上隐私保护分析\nSecure Multiparty Computation (安全多方计算) - 多方协同计算不泄露输入\nScalable Privacy-Preserving Computation (可扩展隐私保护计算) - 提升隐私计算性能与规模\n选定的主题标签名称",
        "abstract": "Privacy-preserving graph analysis allows performing computations on graphs that store sensitive information while ensuring all the information about the topology of the graph, as well as data associated with the nodes and edges, remains hidden. The current work addresses this problem by designing a highly scalable framework, Graphiti, that allows securely realising any graph algorithm. Graphiti relies on the technique of secure multiparty computation (MPC) to design a generic framework that improves over the state-of-the-art framework of GraphSC by Araki et al. (CCS'21). The key technical contribution is that Graphiti has round complexity independent of the graph size, which in turn allows attaining the desired scalability. Specifically, this is achieved by (i) decoupling the Scatter primitive of GraphSC into separate operations of Propagate and ApplyE, (ii) designing a novel constant-round approach to realise Propagate, as well as (iii) designing a novel constant-round approach to realise the Gather primitive of GraphSC by leveraging the linearity of the aggregation operation. We benchmark the performance of Graphiti for the application of contact tracing via BFS for 10 hops and observe that it takes less than 2 minutes when computing over a graph of size 10(7). Concretely it improves over the state-of-the-art up to a factor of 1034x in online run time. Similar to GraphSC by Araki et al., since Graphiti relies on a secure protocol for shuffle, we additionally design a shuffle protocol secure against a semi-honest adversary in the 2-party with a helper setting. Given the versatility of shuffle protocol, the designed solution is of independent interest. Hence, we also benchmark the performance of the designed shuffle where we observe improvements of up to 1.83x in online run time when considering an input vector of size 107, in comparison to the state-of-the-art in the considered setting.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670393",
        "pub_year": "2024",
        "theme_label": "6.2 安全多方计算"
    },
    {
        "title": "Fast Two-party Threshold ECDSA with Proactive Security",
        "authors": "Koziel, Brian; Gordon, S. Dov; Gentry, Craig",
        "keywords": "Threshold ECDSA (门限椭圆曲线数字签名算法) - 分布式签名机制\nProactive Security (主动安全性) - 安全状态周期更新\nPaillier Encryption (帕利尔加密算法) - 同态加密技术应用",
        "abstract": "We present a new construction of two-party, threshold ECDSA, building on a 2017 scheme of Lindell and improving his scheme in several ways.ECDSA signing is notoriously hard to distribute securely, due to non-linearities in the signing function. Lindell's scheme uses Paillier encryption to encrypt one party's key share and handle these non-linearities homomorphically, while elegantly avoiding any expensive zero knowledge proofs over the Paillier group during the signing process. However, the scheme pushes that complexity into key generation. Moreover, avoiding ZK proofs about Paillier ciphertexts during signing comes with a steep price - namely, the scheme requires a global abort when a malformed ciphertext is detected, after which an entirely new key must be generated.We overcome all of these issues with a proactive Refresh procedure. Since the Paillier decryption key is part of the secret that must be proactively refreshed, our first improvement is to radically accelerate key generation by replacing one of Lindell's ZK proofs which requires 80 Paillier ciphertexts for statistical security 2(-40) - with a much faster weak proof that requires only 2 Paillier ciphertexts, and which proves a weaker statement about a Paillier ciphertext that we show is sufficient in the context of our scheme. Secondly, our more efficient key generation procedure also makes frequent proactive Refreshes practical. Finally, we show that adding noise to one party's key share suffices to avoid the need to reset the public verification key when certain bad behavior is detected. Instead, we prove that our Refresh procedure, performed after each detection, suffices for addressing the attack, allowing the system to continue functioning without disruption to applications that rely on the verification key.Our scheme is also very efficient, competitive with the best constructions that do not provide proactive security, and state-of-the-art among the few results that do. Our optimizations to ECDSA key generation speed up runtime and improve bandwidth over Lindell's key generation by factors of 7 and 13, respectively. Our Key Generation protocol requires 20% less bandwidth than existing constructions, completes in only 3 protocol messages, and executes much faster than all but OT-based key generation. For ECDSA signing, our extra Refresh protocol does add a 10X latency and 5X bandwidth overhead compared to Lindell. However, this still fits in 150 ms runtime and about 5.4 KB of messages when run in our AWS cluster benchmark.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670387",
        "pub_year": "2024",
        "theme_label": "2.3.2 密码协议设计与分析"
    },
    {
        "title": "Content, Nudges and Incentives: A Study on the Effectiveness and Perception of Embedded Phishing Training",
        "authors": "Lain, Daniele; Jost, Tarek; Matetic, Sinisa; Kostiainen, Kari; Capkun, Srdjan",
        "keywords": "Embedded Phishing Training (嵌入式钓鱼训练) - 通过模拟攻击提升安全意识\nNudges and Incentives (提示与激励) - 影响行为的外部干预方式\nHuman Security Behavior (人的安全行为) - 用户在安全决策中的表现",
        "abstract": "A common form of phishing training in organizations is the use of simulated phishing emails to test employees' susceptibility to phishing attacks, and the immediate delivery of training material to those who fail the test. This widespread practice is dubbed embedded training; however, its effectiveness in decreasing the likelihood of employees falling for phishing again in the future is questioned by the contradictory findings of several recent field studies.We investigate embedded phishing training in three aspects. First, we observe that the practice incorporates different components-knowledge gains from its content, nudges and reminders from the test itself, and the deterrent effect of potential consequences-our goal is to study which ones are more effective, if any. Second, we explore two potential improvements to training, namely its timing and the use of incentives. Third, we analyze employees' reception and perception of the practice. For this, we conducted a large-scale mixed-methods (quantitative and qualitative) study on the employees of a partner company.Our study contributes several novel findings on the training practice: in particular, its effectiveness comes from its nudging effect, i.e., the periodic reminder of the threat rather than from its content, which is rarely consumed by employees due to lack of time and perceived usefulness. Further, delaying training to ease time pressure is as effective as currently established practices, while rewards do not improve secure behavior. Finally, some of our results support previous findings with increased ecological validity, e.g., that phishing is an attention problem, rather than a knowledge one, even for the most susceptible employees, and thus enforcing training does not help.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690348",
        "pub_year": "2024",
        "theme_label": "1.6 人的安全行为与管理"
    },
    {
        "title": "Poster: E-Graphs and Equality Saturation for Term-Rewriting in MBA Deobfuscation: An Empirical Study",
        "authors": "Lee, Seoksu; Jeon, Hyeongchang; Cho, Eun-Sun",
        "keywords": "E-Graphs (等价图) - 用于表达式等价关系的紧凑数据结构\nEquality Saturation (等价饱和) - 基于等价关系的优化与重写方法\nMBA Deobfuscation (混合布尔算术去混淆) - 拆解复杂算术混淆以恢复原始逻辑\n选定的主题标签名称",
        "abstract": "Obfuscation is a powerful software protection technique. It changes a program into a more complicated one while preserving its semantics. Malware distributors also employ this method, to protect their malware from being understood by malware analysts. Thus, it is crucial to deobfuscate malware in a timely manner, to enable a prompt action to malware.This poster presents an efficient deobfuscation method using e-graph and equality saturation, a recent attention-gathering optimization technique, known for inherent theoretical efficiency in term-rewriting. Among the various deobfuscation techniques, we focus on Mixed Boolean Arithmetic (MBA) obfuscation, which is one of the most popular obfuscation methods due to its unparalleled strength and efficiency. We implement an e-graph and equality-saturation-based term-rewrite MBA deobfuscator, called EMBA, to simplify various sets of MBA-obfuscated expressions. By comparing its performance with state-of-the-art deobfuscators, we have shown that the equality saturation-based method has promising properties in MBA deobfuscation.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691382",
        "pub_year": "2024",
        "theme_label": "3.8.1 漏洞挖掘与逆向分析"
    },
    {
        "title": "SeqMIA: Sequential-Metric Based Membership Inference Attack",
        "authors": "Li, Hao; Li, Zheng; Wu, Siyuan; Hu, Chengrui; Ye, Yutong; Zhang, Min; Feng, Dengguo; Zhang, Yang",
        "keywords": "Membership Inference Attack (成员推断攻击) - 隐私风险分析\nMetric Sequence Pattern (度量序列模式) - 训练过程特征分析\nAttention-based RNN (基于注意力机制的RNN) - 序列建模与攻击推理\n选定的主题标签名称",
        "abstract": "Most existing membership inference attacks (MIAs) utilize metrics (e.g., loss) calculated on the model's final state, while recent advanced attacks leverage metrics computed at various stages, including both intermediate and final stages, throughout the model training. Nevertheless, these attacks often process multiple intermediate states of the metric independently, ignoring their time-dependent patterns. Consequently, they struggle to effectively distinguish between members and non-members who exhibit similar metric values, particularly resulting in a high false-positive rate.In this study, we delve deeper into the new membership signals in the black-box scenario. We identify a new, more integrated membership signal: the Pattern of Metric Sequence, derived from the various stages of model training. We contend that current signals provide only partial perspectives of this new signal: the new one encompasses both the model's multiple intermediate and final states, with a greater emphasis on temporal patterns among them. Building upon this signal, we introduce a novel attack method called Sequential-metric based Membership Inference Attack (SeqMIA). Specifically, we utilize knowledge distillation to obtain a set of distilled models representing various stages of the target model's training. We then assess multiple metrics on these distilled models in chronological order, creating distilled metric sequence. We finally integrate distilled multi-metric sequences as a sequential multiformat and employ an attention-based RNN attack model for inference. Empirical results show SeqMIA outperforms all baselines, especially can achieve an order of magnitude improvement in terms of TPR @ 0.1% FPR. Furthermore, we delve into the reasons why this signal contributes to SeqMIA's high attack performance, and assess various defense mechanisms against SeqMIA. (1)",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690335",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "FUZZCACHE: Optimizing Web Application Fuzzing Through Software-Based Data Cache",
        "authors": "Li, Penghui; Zhang, Mingxue",
        "keywords": "Fuzzing (模糊测试) - 通过输入变异检测漏洞\nSoftware Cache (软件缓存) - 提升重复数据访问效率\nCode Coverage (代码覆盖) - 衡量程序执行路径广度",
        "abstract": "Fuzzing has shown great promise in detecting vulnerabilities in server-side web applications. In this work, we introduce an innovative software-based data cache mechanism that complements and improves all existing web application fuzzing tools. Our key observation is that a great proportion of execution time (e.g., 50%) of web applications is spent on fetching data from two major sources: database and network; our in-depth investigation reveals that the same data is often repeatedly fetched across fuzzing trials. We thus design a new solution, FUZZCACHE, that stores the data into software-based caches, mitigating the need for repeated and expensive data fetches. FUZZCACHE exposes the cached data across fuzzing trials through inter-process shared memory segments. It also, as the first work, incorporates just-in-time compilation to avoid the performance overhead associated with interpreting PHP code in real time, thereby enhancing execution efficiency.We demonstrate that FUZZCACHE significantly enhances web application fuzzing performance. In our experiments, we integrated FUZZCACHE with both a black-box fuzzer (Black-Widow) and a grey-box fuzzer (WebFuzz). The results illustrate that FUZZCACHE accelerates both black-box and grey-box fuzzing, achieving a throughput increase of 3x to 4x. FUZZCACHE substantially improves code coverage by an average of 25%. Consequently, FUZZCACHE enables faster vulnerability detection, leading to the discovery of a greater number of vulnerabilities.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670278",
        "pub_year": "2024",
        "theme_label": "系统安全测评"
    },
    {
        "title": "PowerPeeler: A Precise and General Dynamic Deobfuscation Method for PowerShell Scripts",
        "authors": "Li, Ruijie; Zhang, Chenyang; Chai, Huajun; Ying, Lingyun; Duan, Haixin; Tao, Jun",
        "keywords": "Dynamic Deobfuscation (动态去混淆) - 动态分析实现代码还原\nAbstract Syntax Tree (抽象语法树) - 程序结构分析基础\nMalicious PowerShell Scripts (恶意PowerShell脚本) - 攻击常用自动化工具\n选定的主题标签名称",
        "abstract": "PowerShell is a powerful and versatile task automation tool. Unfortunately, it is also widely abused by cyber attackers. To bypass malware detection and hinder threat analysis, attackers often employ diverse techniques to obfuscate malicious PowerShell scripts. Existing deobfuscation tools suffer from the limitation of static analysis, which fails to simulate the real deobfuscation process accurately. Accurate, complete, and robust PowerShell script deobfuscation is still a challenging problem.In this paper, we propose PowerPeeler. To the best of our knowledge, it is the first dynamic PowerShell script deobfuscation approach at the instruction level. It utilizes expression-related Abstract Syntax Tree (AST) nodes to identify potential obfuscated script pieces. Then, PowerPeeler correlates the AST nodes with their corresponding instructions and monitors the script's entire execution process. Subsequently, PowerPeeler dynamically tracks the execution of these instructions and records their execution results. Finally, PowerPeeler stringifies these results to replace the corresponding obfuscated script pieces and reconstruct the deobfuscated script.To evaluate the effectiveness of PowerPeeler, we collect 1,736,669 real-world malicious PowerShell samples and distill two high-quality datasets with diversity obfuscation methods: D-Script with 4,264 obfuscated script files and D-Cmdline with 381 obfuscated samples using PowerShell command-line interface. We compare PowerPeeler with five state-of-the-art deobfuscation tools and GPT-4. The evaluation results demonstrate that PowerPeeler can effectively handle all well-known obfuscation methods. Additionally, the deobfuscation correctness rate of PowerPeeler reaches 95%, significantly surpassing that of other tools. PowerPeeler not only recovers the highest amount of sensitive data (e.g., IPs and URLs) but also maintains a semantic consistency over 97%, which is also the best. Moreover, PowerPeeler effectively obtains the largest quantity of valid deobfuscated results within a limited time frame (i.e., two minutes). Furthermore, PowerPeeler is extendable and can be used as a helpful tool for other cyber security solutions, such as malware analysis and threat intelligence generation.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670310",
        "pub_year": "2024",
        "theme_label": "3.7 恶意代码分析与防护"
    },
    {
        "title": "Are We Getting Well-informed? An In-depth Study of Runtime Privacy Notice Practice in Mobile Apps",
        "authors": "Li, Shuai; Yang, Zhemin; Nan, Yuhong; Yu, Shutian; Zhu, Qirui; Yang, Min",
        "keywords": "Runtime Privacy Notice (运行时隐私通知) - 用户数据收集告知实践\nGDPR Compliance (GDPR合规性) - 法规要求与实施差距分析\nMobile App Ecosystem (移动应用生态) - 应用隐私透明度研究\n选定的主题标签名称",
        "abstract": "Under the General Data Protection Regulation (GDPR), mobile app developers are required to inform users of necessary information at the time when user data is collected (called users' Right-to-be-Informed). This is typically done by app developers via providing runtime privacy notices (RPNs for short). However, given the heterogeneous privacy data types and data access patterns in modern apps, it is not clear to what extent apps (app developers) effectively fulfill this compliance requirement in practice.In this paper, we perform the first systematic study of current RPN practices in mobile apps. Our research endeavors to comprehend (1) the ecosystem of RPN, (2) potential gaps between legal requirements and RPN practices, and (3) the underlying reasons for such gaps. To achieve this, we design an automated pipeline - RENO that can effectively identify, extract, and analyze RPN at a large scale. With the help of RENO, we investigated 4,656 mobile apps selected from 19 European Union countries. Our analysis reveals a number of interesting findings. For example, 77.10% of user data collection behaviors lack RPNs. Among those provided RPNs, 86.35% of them have no more than three required notice elements when GDPR requires seven. In addition, to further understand the reasons behind such gaps, we perform a notification campaign and ask for feedback from the app developers. Indeed, the collected responses highlighted several critical reasons. For instance, a substantial proportion of app developers regard RPN as an optional complement to their privacy policies as RPNs are not strictly enforced by app stores. Our study shows the pressing need for better transparency in user data collection delivered by RPN.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670377",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Secure Multiparty Computation with Lazy Sharing",
        "authors": "Li, Shuaishuai; Zhang, Cong; Lin, Dongdai",
        "keywords": "Secure Multiparty Computation (安全多方计算) - 多方协同计算保护隐私\nLazy Sharing (懒惰共享) - 降低门限分享开销\nSecret Sharing (秘密共享) - 数据分割保障安全性\n选定的主题标签名称",
        "abstract": "Secure multiparty computation (MPC) protocols enable.. parties, each with private inputs, to compute a given function without leaking information beyond the outputs. One of the main approaches to designing efficient MPC protocols is to use secret sharing. In general, secret sharing based MPC contains three phases: input sharing, circuit evaluation, and output recovery. If the adversary corrupts at most.. parties, the protocol typically uses (t,n) threshold secret sharing to share the inputs. In this work, we consider a weaker variant of threshold secret sharing called lazy threshold secret sharing (or simply lazy sharing) and show thatcenter dot Lazy sharing can serve as a viable alternative to threshold secret sharing in MPC without compromising security.center dot Lazy sharing could be generated more efficiently than threshold secret sharing.As a result, replacing threshold secret sharing with lazy sharing can lead to a more efficient input sharing phase. Moreover, we propose that the efficiency of the circuit evaluation phase can also be further improved. To support this claim, we apply lazy sharing to several state-of-the-art MPC protocols and analyze the efficiency gain in various settings. These protocols include the GMW protocol (Goldreich et al., STOC 1987), the AFLNO protocol (Araki et al., CCS 2016), and the SPDZ protocol (Damgard et al., CRYPTO 2012). By doing so, we analyze the efficiency gains in various settings and highlight the advantages of incorporating lazy sharing into MPC protocols.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690207",
        "pub_year": "2024",
        "theme_label": "6.2 安全多方计算"
    },
    {
        "title": "Poster: Towards Real-Time Intrusion Detection with Explainable AI-Based Detector",
        "authors": "Li, Wenhao; Ma, Duohe; Li, Zhaoxuan; Bao, Huaifeng; Wang, Shuai; Jin, Huamin; Zhang, Xiao-Yu",
        "keywords": "Intrusion Detection (入侵检测) - 网络攻击实时识别\nExplainable AI (可解释人工智能) - 提升模型决策透明性\nTree Regularization (树正则化) - 优化模型结构简化",
        "abstract": "Identifying malicious traffic is crucial for safeguarding internal networks from privacy breaches. Intrusion Detection Systems (IDS) traditionally rely on inefficient and outdated rule-sets, necessitating a shift towards AI-driven, learning-based algorithms for enhanced detection capabilities. Despite their promise, AI-integrated IDS face deployment challenges due to complex, opaque decision-making processes that can lead to latency and an increased risk of false positives. This paper presents the Explainable AI-based Intrusion Detection System (XAI-IDS), addressing the limitations of both rule-based and AI-driven IDS by integrating interpretable deep learning models. XAI-IDS employs tree regularization to transform complex models into efficient, transparent decision trees, facilitating real-time detection with improved accuracy and explainability. Experiments on two benchmark datasets demonstrate XAI-IDS's superior performance, offering a scalable solution to the challenge of identifying malicious traffic with reduced risk of false positives.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691410",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "BASEMIRROR: Automatic Reverse Engineering of Baseband Commands from Android's Radio Interface Layer",
        "authors": "Li, Wenqiang; Wen, Haohuang; Lin, Zhiqiang",
        "keywords": "Baseband Security (基带安全) - 保障移动设备通信核心的安全\nReverse Engineering (逆向工程) - 分析软件以揭示其功能与结构\nVulnerability Discovery (漏洞挖掘) - 发现系统潜在安全缺陷",
        "abstract": "In modern mobile devices, baseband is an integral component running on top of cellular processors to handle crucial radio communications. However, recent research reveals significant vulnerabilities in these basebands, posing serious security risks like remote code execution. Yet, effectively scrutinizing basebands remains a daunting task, as they run closed-source and proprietary software on vendor-specific chipsets. Existing analysis methods are limited by their dependence on manual processes and heuristic approaches, reducing their scalability. This paper introduces a novel approach to unveil security issues in basebands from a unique perspective: to uncover vendor-specific baseband commands from the Radio Interface Layer (RIL), a hardware abstraction layer interfacing with basebands. To demonstrate this concept, we have designed and developed BASEMIRROR, a static binary analysis tool to automatically reverse engineer baseband commands from vendor-specific RIL binaries. It utilizes a bidirectional taint analysis algorithm to adeptly identify baseband commands from an enhanced control flow graph enriched with reconstructed virtual function calls. Our methodology has been applied to 28 vendor RIL libraries, encompassing a wide range of Samsung Exynos smartphone models on the market. Remarkably, BASEMIRROR has uncovered 873 unique baseband commands undisclosed to the public. Based on these results, we develop an automated attack discovery framework to successfully derive and validate 8 zero-day vulnerabilities that trigger denial of cellular service and arbitrary file access on a Samsung Galaxy A53 device. These findings have been reported and confirmed by Samsung and a bug bounty was awarded to us.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690254",
        "pub_year": "2024",
        "theme_label": "3.8.1 漏洞挖掘与逆向分析"
    },
    {
        "title": "Toward Understanding the Security of Plugins in Continuous Integration Services",
        "authors": "Li, Xiaofan; Gu, Yacong; Qiao, Chu; Zhang, Zhenkai; Liu, Daiping; Ying, Lingyun; Duan, Haixin; Gao, Xing",
        "keywords": "Continuous Integration Security (持续集成安全) - 研究CI系统中的安全隐患\nPlugin Vulnerabilities (插件漏洞) - 分析插件机制中的安全弱点\nAttack Surface Analysis (攻击面分析) - 评估插件带来的潜在威胁",
        "abstract": "Mainstream Continuous Integration (CI) platforms have provided the plugin functionality to accelerate the development of CI pipelines. Unfortunately, CI plugins, which are essentially reusable code snippets, also expose new attack surfaces as plugins might be developed by less trusted users. In this paper, we present an in-depth study to understand potential security risks in existing CI plugins. We conduct a comprehensive analysis of plugin implementations on four mainstream CI platforms (GitHub Actions, GitLab CI, CircleCI, and Azure Pipelines), and investigate several weak links in existing plugin distributions and isolation mechanisms. We investigate seven attack vectors that can enable attackers to hijack plugins and distribute malicious code without plugins users being aware, and further exploit hijacked plugins to manipulate the workflow execution. Additionally, we find that plugin dependency (a plugin references other plugins) might further amplify the attack impact of our disclosed attacks. To evaluate the potential impact, we conduct a large-scale measurement on GitHub and GitLab, covering a total of 1,328,912 repositories using the aforementioned CI platforms. Our measurement results show that a large number of repositories and existing plugins, including many widely used ones, are potentially vulnerable to the proposed attacks. We have duly reported the identified vulnerabilities and received positive responses.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670366",
        "pub_year": "2024",
        "theme_label": "系统软件安全"
    },
    {
        "title": "SafeGen: Mitigating Sexually Explicit Content Generation in Text-to-Image Models",
        "authors": "Li, Xinfeng; Yang, Yuchen; Deng, Jiangyi; Yan, Chen; Chen, Yanjiao; Ji, Xiaoyu; Xu, Wenyuan",
        "keywords": "Text-to-Image Models (文本到图像生成模型) - 通过文本生成高质量图像\nSexual Content Mitigation (色情内容缓解) - 阻止生成不当视觉内容\nAdversarial Prompt Resistance (对抗性提示抵抗) - 抵御伪装文本输入攻击",
        "abstract": "Text-to-image (T2I) models, such as Stable Diffusion, have exhibited remarkable performance in generating high-quality images from text descriptions in recent years. However, text-to-image models may be tricked into generating not-safe-for-work (NSFW) content, particularly in sexually explicit scenarios. Existing countermeasures mostly focus on filtering inappropriate inputs and outputs, or suppressing improper text embeddings, which can block sexually explicit content (e.g., naked) but may still be vulnerable to adversarial prompts-inputs that appear innocent but are ill-intended. In this paper, we present SafeGen, a framework to mitigate sexual content generation by text-to-image models in a text-agnostic manner. The key idea is to eliminate explicit visual representations from the model regardless of the text input. In this way, the text-to-image model is resistant to adversarial prompts since such unsafe visual representations are obstructed from within. Extensive experiments conducted on four datasets and large-scale user studies demonstrate SafeGen's effectiveness in mitigating sexually explicit content generation while preserving the high-fidelity of benign images. SafeGen outperforms eight state-of-the-art baseline methods and achieves 99.4% sexual content removal performance.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670295",
        "pub_year": "2024",
        "theme_label": "信息内容安全"
    },
    {
        "title": "Poster: Few-Shot Inter-Domain Routing Threat Detection with Large-Scale Multi-Modal Pre-Training",
        "authors": "Li, Yizhi; Li, Jiang; Cao, Jiahao; Xie, Renjie; Wang, Yangyang; Xu, Mingwei",
        "keywords": "Few-shot Learning (小样本学习) - 用少量数据实现高效模型训练\nBGP Threat Detection (BGP威胁检测) - 识别互联网路由协议安全隐患\nMulti-modal Pre-training (多模态预训练) - 融合多种数据提升模型泛化能力\n选定的主题标签名称",
        "abstract": "Border Gateway Protocol (BGP) plays a pivotal role as the de facto inter-domain routing protocol on the Internet. However, BGP threats continually emerge and undermine the Internet reliability. Existing BGP threat detection methods based on machine learning require substantial labeled data and expert involvement, making them costly and labor-intensive. Moreover, they fail to learn rich information from massive unlabeled BGP data consistently generated on the Internet. In this paper, we propose FIRE that enables few-shot inter-domain routing threat detection with large-scale multi-modal pre-training. FIRE conducts domain-specific pre-training tasks to acquire rich BGP implicit knowledge from massive unlabeled BGP data for few-shot learning. Our experiments show that FIRE can be fine-tuned to precisely identify BGP threats with only a few labeled samples, e.g., a 93.2% precision in route leak detection with merely 8 events for fine-tuning.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691402",
        "pub_year": "2024",
        "theme_label": "3.9.1 攻击行为监测发现"
    },
    {
        "title": "GPSBuster: Busting out Hidden GPS Trackers via MSoC Electromagnetic Radiations",
        "authors": "Li, Yue; Yan, Zhenxiong; Jin, Wenqiang; Ning, Zhenyu; Liu, Daibo; Qin, Zheng; Liu, Yu; Zhu, Huadi; Li, Ming",
        "keywords": "GPS tracking detection (GPS追踪检测) - 利用侧信道分析识别隐藏设备\nElectromagnetic radiation analysis (电磁辐射分析) - 提取芯片辐射特征信号\nSignal processing techniques (信号处理技术) - 去噪与能量累积提升信噪比\n选定的主题标签名称",
        "abstract": "The escalating threat of hidden GPS tracking devices poses significant risks to personal privacy and security. Featured by their miniaturization and misleading appearances, GPS devices can be easily disguised in their surroundings making their detection extremely challenging. In this paper, we propose a novel side-channel-driven detection system, GPSBuster, leveraging electromagnetic radiation (EMR) emitted by GPS trackers. Our feasibility studies and hardware analysis reveal that unique EMR patterns associated with the tracker's operation, stemming from the quartz oscillator, local oscillator, and mixer in the Mixed-Signal on Chip (MSoC) system. Nevertheless, as a side-channel leakage, EMRs can be extremely weak and suffer from the ambient noise interference, rendering the detection impractical. To address these challenges, we develop the signal processing techniques with noise removals and a dual-dimensional folding mechanism to accumulate the spectrum energy and protrude the EMR patterns with high Signal-to-Noise Ratios (SNR). Our detection prototype, built with a portable HackRF One device, allows users to perform a scan-to-detect manner and achieves an overall success rate of 98.4% on top-10 selling GPS trackers under various testing cases. The maximum detection range is 0.61m.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690362",
        "pub_year": "2024",
        "theme_label": "3.2.1 芯片安全"
    },
    {
        "title": "Demo: Enhancing Smart Contract Security Comprehensively through Dynamic Symbolic Execution",
        "authors": "Li, Zhaoxuan; Zhao, Ziming; Li, Wenhao; Zhang, Rui; Xue, Rui; Lu, Siqi; Zhang, Fan",
        "keywords": "Dynamic Symbolic Execution (动态符号执行) - 程序分析与漏洞挖掘技术\nSmart Contract Security (智能合约安全) - 区块链应用安全性保障\nSecurity Monitoring (安全监控) - 实时检测异常行为与交易",
        "abstract": "The frequent security incidents of contracts indicate a pressing need to ensure contract security from deployment to running stages, but the state-of-the-art (SOTA) analysis methods cannot work well for three requirements. (i) Identify contract defective code snippets, while generating exploit call sequences to help developers fix them. (ii) Monitor abnormal call behaviors, especially for multiple continuous transactions. (iii) Validate numerous unexploitable detection results automatically because manual verification is labor-intensive. To tackle these problems, we propose SymX, a symbolic execution-based security analysis art accounting for contract development and running stages. The experiment results demonstrate that it can accurately identify 90.22% of contracts and 98.04% of call transactions, as well as validate misreports as intended, which is superior to SOTAs, thereby protecting contracts better during the contract lifecycle. Currently, SymX is available at https://github.com/Secbrain/SymX.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691365",
        "pub_year": "2024",
        "theme_label": "8.2 智能合约及安全"
    },
    {
        "title": "Analyzing Inference Privacy Risks Through Gradients In Machine Learning",
        "authors": "Li, Zhuohang; Lowy, Andrew; Liu, Jing; Koike-Akino, Toshiaki; Parsons, Kieran; Malin, Bradley; Wang, Ye",
        "keywords": "Gradient Inference (梯度推断) - 通过模型梯度推测敏感信息\nPrivacy Risks (隐私风险) - 分析分布式学习中的隐私泄露问题\nDefensive Mechanisms (防御机制) - 研究缓解梯度泄露的防护手段",
        "abstract": "In distributed learning settings, models are iteratively updated with shared gradients computed from potentially sensitive user data. While previous work has studied various privacy risks of sharing gradients, our paper aims to provide a systematic approach to analyze private information leakage from gradients. We present a unified game-based framework that encompasses a broad range of attacks including attribute, property, distributional, and user disclosures. We investigate how different uncertainties of the adversary affect their inferential power via extensive experiments on five datasets across various data modalities. Our results demonstrate the inefficacy of solely relying on data aggregation to achieve privacy against inference attacks in distributed learning. We further evaluate five types of defenses, namely, gradient pruning, signed gradient descent, adversarial perturbations, variational information bottleneck, and differential privacy, under both static and adaptive adversary settings. We provide an information-theoretic view for analyzing the effectiveness of these defenses against inference from gradients. Finally, we introduce a method for auditing attribute inference privacy, improving the empirical estimation of worst-case privacy through crafting adversarial canary records.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690304",
        "pub_year": "2024",
        "theme_label": "数据安全与隐私保护"
    },
    {
        "title": "fAmulet: Finding Finalization Failure Bugs in Polygon zkRollup",
        "authors": "Li, Zihao; Peng, Xinghao; He, Zheyuan; Luo, Xiapu; Chen, Ting",
        "keywords": "Zero-knowledge Layer 2 Protocols (零知识二层协议) - 提升区块链扩展性\nFinalization Failure Bugs (最终化失败漏洞) - 导致交易无法完成\nFuzzing Testing (模糊测试技术) - 自动检测系统缺陷",
        "abstract": "Zero-knowledge layer 2 protocols emerge as a compelling approach to overcoming blockchain scalability issues by processing transactions through the transaction finalization process. During this process, transactions are efficiently processed off the main chain. Besides, both the transaction data and the zero-knowledge proofs of transaction executions are reserved on the main chain, ensuring the availability of transaction data as well as the correctness and verifiability of transaction executions. Hence, any bugs that cause the transaction finalization failure are crucial, as they impair the usability of these protocols and the scalability of blockchains.In this work, we conduct the first systematic study on finalization failure bugs in zero-knowledge layer 2 protocols, and define two kinds of such bugs. Besides, we design fAmulet, the first tool to detect finalization failure bugs in Polygon zkRollup, a prominent zero-knowledge layer 2 protocol, by leveraging fuzzing testing. To trigger finalization failure bugs effectively, we introduce a finalization behavior model to guide our transaction fuzzer to generate and mutate transactions for inducing diverse behaviors across each component (e.g., Sequencer) in the finalization process. Moreover, we define bug oracles according to the distinct bug definitions to accurately detect bugs. Through our evaluation, fAmulet can uncover twelve zero-day finalization failure bugs in Polygon zkRollup, and cover at least 20.8% more branches than baselines. Furthermore, we employ fAmulet to uncover zero-day bugs and reconfirm known bugs in Scroll zkRollup and Optimism Rollup, highlighting the generality of fAmulet to be extended to other layer 2 protocols. At the time of writing, all our uncovered zero-day bugs have been confirmed and fixed by the corresponding official teams.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690243",
        "pub_year": "2024",
        "theme_label": "8.2 智能合约及安全"
    },
    {
        "title": "Internet's Invisible Enemy: Detecting and Measuring Web Cache Poisoning in the Wild",
        "authors": "Liang, Yuejia; Chen, Jianjun; Guo, Run; Shen, Kaiwen; Jiang, Hui; Hou, Man; Yu, Yue; Duan, Haixin",
        "keywords": "Web Cache Poisoning (网页缓存投毒) - 缓存污染攻击检测与分析\nHCache (高效缓存检测方法) - 大规模漏洞识别技术\nVulnerability Disclosure (漏洞披露机制) - 安全研究与责任披露实践\n选定的主题标签名称",
        "abstract": "Web cache poisoning (WCP) has posed significant threats to Internet security by causing the cache server to deliver malicious responses to innocent users. This results in widespread denial of access to website resources and potential injection of harmful payloads. However, prior works on WCP vulnerability have been fragmented and conducted in a case-by-case form, lacking a systematic analysis of the threat landscape. In this paper, we fill this research gap by conducting a systematic evaluation of WCP vulnerabilities at scale. We propose HCache, a novel testing methodology to facilitates the widespread identification of WCP vulnerabilities. We evaluated our methodology against Tranco Top 1000 domains and their sub-domains, and found that over 1,000 websites across 172 domains, representing 17% of the evaluated domains, are vulnerable to WCP. In particular, we have identified 7 new attack vectors stemming from previously unexplored caching headers. We have responsibly disclosed the vulnerabilities to the affected websites and received acknowledgements and bug bounties from world-famous companies, such as Alibaba, Adobe, Huawei, and Microsoft.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690361",
        "pub_year": "2024",
        "theme_label": "3.8.1 漏洞挖掘与逆向分析"
    },
    {
        "title": "Smooth Sensitivity for Geo-Privacy",
        "authors": "Liang, Yuting; Yi, Ke",
        "keywords": "Geo-Privacy (地理隐私) - 基于位置距离的隐私保护\nSmooth Sensitivity (平滑敏感度) - 自适应噪声机制提升效用\nLocal Differential Privacy (本地差分隐私) - 用户端数据扰动保障隐私",
        "abstract": "Suppose each user x(i) holds a private value x(i) in some metric space (U, dist), and an untrusted data analyst wishes to compute Sigma(i)f(x(i)) for some function f : U -> R by asking each user to send in a privatized f(x(i)). This is a fundamental problem in privacy-preserving population analytics, and the local model of differential privacy (LDP) is the predominant model under which the problem has been studied. However, LDP requires any two different x(i), x(i)' to be epsilon-distinguishable, which can be overly strong for geometric/numerical data. On the other hand, Geo-Privacy (GP) stipulates that the level of distinguishability be proportional to dist(x(i), x(i)'), providing an attractive alternative notion of personal data privacy in a metric space. However, existing GP mechanisms for this problem, which add a uniform noise to either x(i) or f(x(i)), are not satisfactory. In this paper, we generalize the smooth sensitivity framework from Differential Privacy to Geo-Privacy, which allows us to add noise tailored to the hardness of the given instance. We provide definitions, mechanisms, and a generic procedure for computing the smooth sensitivity under GP equipped with a general metric. Then we present three applications: one-way and two-way threshold functions, and Gaussian kernel density estimation, to demonstrate the applicability and utility of our smooth sensitivity framework.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690365",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Leveraging Binary Coverage for Effective Generation Guidance in Kernel Fuzzing",
        "authors": "Liu, Jianzhong; Shen, Yuheng; Xu, Yiru; Jiang, Yu",
        "keywords": "Kernel Fuzzing (内核模糊测试) - 通过输入变异检测内核漏洞\nBinary Coverage Feedback (二进制覆盖率反馈) - 提升 fuzzing 的行为覆盖分析\nExecution Guidance (执行引导) - 指导生成更有效的测试输入",
        "abstract": "State-of-the-art kernel fuzzers use edge-based code coverage metrics for novel behavior detection. However, code coverage is not sufficient for operating system kernels, for they contain many untracked but interesting features, such as comparison operands, kernel state identifiers, flags, and executable code, within its data segments, that reflects different execution patterns, and can profoundly increase the granularity and scope of the coverage metrics.This paper proposes the use of Kernel Binary Coverage Feedback, a comprehensive and effective execution feedback method that provides metrics reflecting the execution coverage status of the entire binary coverage to kernel fuzzers. Our approach abstracts program behavior as its memory access pattern during execution, and considers all such relevant behavior, including standard memory reads and writes, predicate comparisons, etc., to obtain a coverage metric on the whole kernel binary for input generation guidance.We implemented a prototype tool KBinCov and integrated it into a popular kernel fuzzer Syzkaller. We evaluated its effectiveness against vanilla Syzkaller, aswell as certain other approaches, including StateFuzz and IJON. Our results show that KBinCov achieves code and binary coverage increases of 7%, 7%, 9%, and 87%, 34%, 61%, compared to Syzkaller (using kcov), StateFuzz, and IJON, on recent versions of the Linux kernels, respectively, while only incurring a 1.74x overhead increase, less than StateFuzz and IJON's 2.5x and 2.2x figures. In addition, we found 21 previously unknown bugs using KBinCov with Syzkaller, more than Syzkaller (with kcov), StateFuzz, and IJON, which found 4, 4, and 2 bugs, respectively.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690232",
        "pub_year": "2024",
        "theme_label": "系统安全测评"
    },
    {
        "title": "Cross-silo Federated Learning with Record-level Personalized Differential Privacy",
        "authors": "Liu, Junxu; Lou, Jian; Xiong, Li; Liu, Jinfei; Meng, Xiaofeng",
        "keywords": "Federated Learning (联邦学习) - 分布式机器学习框架\nDifferential Privacy (差分隐私) - 隐私数据保护技术\nPersonalized Privacy (个性化隐私) - 个性化隐私保护需求\n选定的主题标签名称",
        "abstract": "Federated learning (FL) enhanced by differential privacy has emerged as a popular approach to better safeguard the privacy of client-side data by protecting clients' contributions during the training process. Existing solutions typically assume a uniform privacy budget for all records and provide one-size-fits-all solutions that may not be adequate to meet each record's privacy requirement. In this paper, we explore the uncharted territory of cross-silo FL with record-level personalized differential privacy. We devise a novel framework named rPDP-FL, employing a two-stage hybrid sampling scheme with both uniform client-level sampling and non-uniform record-level sampling to accommodate varying privacy requirements.A critical and non-trivial problem is how to determine the ideal per-record sampling probability.. given the personalized privacy budget epsilon. We introduce a versatile solution named Simulation-CurveFitting, allowing us to uncover a significant insight into the nonlinear correlation between q and epsilon and derive an elegant mathematical model to tackle the problem. Our evaluation demonstrates that our solution can provide significant performance gains over the baselines that do not consider personalized privacy preservation.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670351",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "RIOTFUZZER: Companion App Assisted Remote Fuzzing for Detecting Vulnerabilities in IoT Devices",
        "authors": "Liu, Kaizheng; Yang, Ming; Ling, Zhen; Zhang, Yue; Lei, Chongqing; Luo, Junzhou; Fu, Xinwen",
        "keywords": "Blackbox Fuzzing (黑盒模糊测试) - 无需内部信息的漏洞探测方法\nCompanion App (配套应用程序) - 辅助物联网设备操作的应用程序\nSide-channel-guided Fuzzing (侧信道引导模糊测试) - 利用侧信道信息提升测试效率",
        "abstract": "Due to the diversity of architectures and peripherals of Internet of Things (IoT) systems, blackbox fuzzing stands out as a prime option for discovering vulnerabilities of IoT devices. Existing blackbox fuzzing tools often rely on companion apps to generate valid fuzzing packets. However, existing methods encounter the challenges of bypassing the cloud server side validation when it comes to fuzz devices that rely on cloud-based communication. Moreover, they tend to concentrate their efforts on Java components within Android companion apps, limiting their effectiveness in assessing non-Java components such as JavaScript-based mini-apps. In this paper, we introduce a novel blackbox fuzzing method, named RIOTFUZZER, designed to remotely uncover vulnerabilities of IoT devices with the assistance of companion apps, particularly those powered by All-in-one Apps with the JavaScript-based mini-apps feature enabled. Our approach utilizes document-based control command extraction, hybrid analysis for mutation point identification and side-channel-guided fuzzing to effectively address the challenges of fuzzing IoT devices remotely. We apply RIOTFUZZER to 27 IoT devices on prominent platforms and discovered 11 vulnerabilities. All of them have been acknowledged by the corresponding vendors. 8 have been confirmed by the vendors and have been assigned 4 CVE IDs. Our experiment results also demonstrate that side-channel-guided fuzzing can significantly enhance the efficiency of fuzzing packets sent to IoT devices, with an average increase of 76.62% and a maximum increase of 362.62%.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670342",
        "pub_year": "2024",
        "theme_label": "3.8.1 漏洞挖掘与逆向分析"
    },
    {
        "title": "PreCurious: How Innocent Pre-Trained Language Models Turn into Privacy Traps",
        "authors": "Liu, Ruixuan; Wang, Tianhao; Cao, Yang; Xiong, Li",
        "keywords": "Pre-trained Language Models (预训练语言模型) - 模型预训练与知识迁移\nMembership Inference Attacks (成员推理攻击) - 推理数据集成员身份\nDifferential Privacy (差分隐私) - 隐私保护与数据统计\n选定的主题标签名称",
        "abstract": "The pre-training and fine-tuning paradigm has demonstrated its effectiveness and has become the standard approach for tailoring language models to various tasks. Currently, community-based platforms offer easy access to various pre-trained models, as anyone can publish without strict validation processes. However, a released pre-trained model can be a privacy trap for fine-tuning datasets if it is carefully designed. In this work, we propose PreCurious framework to reveal the new attack surface where the attacker releases the pre-trained model and gets a black-box access to the final fine-tuned model. PreCurious aims to escalate the general privacy risk of both membership inference and data extraction on the fine-tuning dataset. The key intuition behind PreCurious is to manipulate the memorization stage of the pre-trained model and guide fine-tuning with a seemingly legitimate configuration. While empirical and theoretical evidence suggests that parameter-efficient and differentially private fine-tuning techniques can defend against privacy attacks on a fine-tuned model, PreCurious demonstrates the possibility of breaking up this invulnerability in a stealthy manner compared to fine-tuning on a benign pre-trained model. While DP provides some mitigation for membership inference attack, by further leveraging a sanitized dataset, PreCurious demonstrates potential vulnerabilities for targeted data extraction even under differentially private tuning with a strict privacy budget e.g. epsilon = 0.05. Thus, PreCurious raises warnings for users on the potential risks of downloading pre-trained models from unknown sources, relying solely on tutorials or common-sense defenses, and releasing sanitized datasets even after perfect scrubbing.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690279",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Poster: Solving the Free-rider Problem in Bittensor",
        "authors": "Liu, Sin Tai; Yu, Jiayuan; Steeves, Jacob",
        "keywords": "Commitment Scheme (承诺方案) - 用于防止信息复制攻击\nFree-rider Problem (搭便车问题) - 激励机制中的公平性保障\nDecentralized Incentive Mechanism (去中心化激励机制) - 匿名系统中行为激励设计\n选定的主题标签名称",
        "abstract": "The design and operation of Bittensor is a decentralized and anonymous system where actors are incentivized by rewards to provide utilities. To ensure that it is a fair game, utilities obtained by copying other participants should be identified and punished. Our first contribution is to apply a commitment scheme to address this free-rider problem. Under appropriate conditions, we show theoretically and empirically that a commitment scheme dissuades copying by reducing the rewards to the copier. In particular, this dissuasive power is a function of the duration between the commit- and reveal-steps. Our second contribution is to propose the liquid alpha solution to amplify the effect of the commitment scheme.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691414",
        "pub_year": "2024",
        "theme_label": "8.1 共识机制及安全"
    },
    {
        "title": "DeepCache: Revisiting Cache Side-Channel Attacks in Deep Neural Networks Executables",
        "authors": "Liu, Zhibo; Yuan, Yuanyuan; Chen, Yanzuo; Hu, Sihang; Li, Tianxiang; Wang, Shuai",
        "keywords": "Cache Side-Channel Attacks (缓存侧信道攻击) - 利用缓存行为泄露信息进行攻击\nDeep Neural Network Security (深度神经网络安全) - 保护DNN模型架构不被窃取\nCompiler Optimization Analysis (编译器优化分析) - 分析DL编译器优化对安全的影响\n选定的主题标签名称",
        "abstract": "Deep neural networks (DNN) are increasingly deployed in heterogeneous hardware, including high-performance devices like GPUs and low-power devices like mobile/IoT CPUs, FPGAs, and accelerators. In order to unlock the full performance potential of various hardware, deep learning (DL) compilers automatically optimize DNN inference computations and compile DNN models into DNN executables for efficient computations across hardware backends.As valuable intellectual properties, DNN architectures are one primary attack target. Since previous works already demonstrate the abuse of cache side channels to steal DNN architectures from DL frameworks (e.g., PyTorch and TensorFlow), we first study using those known side-channel attacks against DNN executables. We find that attacking DNN executables presents unique challenges, and existing works can hardly apply. Particularly, DNN executables exhibit a standalone paradigm that largely reduces cache side channel attack surfaces. Meanwhile, cache side channels capture only limited behaviors of the whole DNN execution while facing daunting technical challenges (e.g., noise and low time resolution).However, we unveil a unique attack vector in DNN executables, such that the cache-aware optimizations, which are extensively employed by contemporary DL compilers to harvest the full potentials of hardware, would result in distinguishable DNN operator cache access patterns, making model architecture recovery possible. We propose DeepCache, an end-to-end side channel attack framework, to infer DNN model architectures from DNN executables. DeepCache leverages cache side channels as the attacking primitives and combines contrastive learning and anomaly detection to enable precise inference. Our evaluation using the standard Prime+Probe shows that DeepCache yields a high accuracy in exploiting complex DNN executables under both the basic L1 cache attack and the more practical but challenging last level cache (LLC) attack settings.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690241",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Securing Cyber-Physical Systems via Advanced Cyber Threat Intelligence Methods",
        "authors": "Lopez-Morales, Efren",
        "keywords": "Cyber Threat Intelligence (网络威胁情报) - 威胁信息收集与分析\nCyber-Physical Systems (信息物理系统) - 物理与数字系统融合\nHoneypot Technology (蜜罐技术) - 诱捕攻击行为的技术",
        "abstract": "Many services that make our modern society work, such as communications and transportation, are only possible thanks to CyberPhysical Systems (CPS). This makes CPS the target of cyberattacks that aim to disrupt our society. One tool that we can leverage to protect CPS is Cyber Threat Intelligence (CTI). CTI is threat information that helps us understand a threat actor's techniques. However, current CTI on CPS is limited as current methods cannot collect and analyze data on the latest cyberattacks against CPS. In this dissertation research description, we address this problem by developing three new methods that advance the state-of-the-art CTI of three different CPS: Industrial Control Systems (ICS), Satellites, and Connected Autonomous Vehicles (CAV). The first research project involves the development of a novel threat taxonomy for programmable logic controllers (PLCs), which are a key part of ICS. The second project is the development of a satellite honeypot to collect data on adversaries' techniques. The third and final project involves the development of a CAV sandbox that allows us to test cyberattacks on CAVs to collect raw threat intelligence.Our preliminary results include a novel ICS threat matrix and a high-interaction satellite honeypot in the literature, which pushes the state of the art of CTI for CPS forward.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690865",
        "pub_year": "2024",
        "theme_label": "3.9.1 攻击行为监测发现"
    },
    {
        "title": "NEURAL DEHYDRATION: Effective Erasure of Black-box Watermarks from DNNs with Limited Data",
        "authors": "Lu, Yifan; Li, Wenxuan; Zhang, Mi; Pan, Xudong; Yang, Min",
        "keywords": "Black-box Watermarks (黑盒水印) - 通过API访问检测模型版权\nNeural Network Robustness (神经网络鲁棒性) - 模型对攻击的抵抗能力\nWatermark Removal Attack (水印移除攻击) - 在有限数据下擦除水印\n选定的主题标签名称",
        "abstract": "To protect the intellectual property of well-trained deep neural networks (DNNs), black-box watermarks, which are embedded into the prediction behavior of DNN models on a set of specially-crafted samples and extracted from suspect models using only API access, have gained increasing popularity in both academy and industry. Watermark robustness is usually implemented against attackers who steal the protected model and obfuscate its parameters for watermark removal. However, current robustness evaluations are primarily performed under moderate attacks or unrealistic settings. Existing removal attacks could only crack a small subset of the mainstream black-box watermarks, and fall short in four key aspects: incomplete removal, reliance on prior knowledge of the watermark, performance degradation, and high dependency on data.In this paper, we propose a watermark-agnostic removal attack called NEURAL DEHYDRATION (abbrev. DEHYDRA), which effectively erases all ten mainstream black-box watermarks from DNNs, with only limited or even no data dependence. In general, our attack pipeline exploits the internals of the protected model to recover and unlearn the watermark message. We further design target class detection and recovered sample splitting algorithms to reduce the utility loss and achieve data-free watermark removal on five of the watermarking schemes. We conduct comprehensive evaluation of DEHYDRA against ten mainstream black-box watermarks on three benchmark datasets and DNN architectures. Compared with existing removal attacks, Dehydra achieves strong removal effectiveness across all the covered watermarks, preserving at least 90% of the stolen model utility, under the data-limited settings, i.e., less than 2% of the training data or even data-free. Our work reveals the vulnerabilities of existing black-box DNN watermarks in realistic settings, highlighting the urgent need for more robust watermarking techniques. To facilitate future studies, we open-source our code in the following repository: https://github.com/LouisVann/Dehydra.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690334",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Training Robust ML-based Raw-Binary Malware Detectors in Hours, not Months",
        "authors": "Lucas, Keane; Lin, Weiran; Bauer, Lujo; Reiter, Michael K.; Sharif, Mahmood",
        "keywords": "Adversarial Training (对抗训练) - 提升模型抗攻击能力\nGreedyBlock-training (贪心块训练) - 快速训练鲁棒检测模型\nRobustness Evaluation (鲁棒性评估) - 高效衡量模型防御性能\n选定的主题标签名称",
        "abstract": "Machine-learning (ML) classifiers are increasingly used to distinguish malware from benign binaries. Recent work has shown that ML-based detectors can be evaded by adversarial examples, but also that one may defend against such attacks via adversarial training. However, adversarial training, and subsequent robustness evaluation, is computationally expensive in the raw-binary malware-detection domain because it requires producing many adversarial examples for both training and evaluation. Prior work found that Greedy-training, a faster robust training technique that forgoes using adversarial examples, showed some promise in producing robust malware detectors. However, Greedy-training was far less effective in inducing robustness than the more expensive adversarial training, and it also severely hurt natural accuracy (i.e., accuracy on the original data). To faster train models, this work presents GreedyBlock-training, an enhanced version of Greedy-training that we empirically show achieves not only state-of-the-art robustness in malware detectors, exceeding even adversarial training, but also retains natural accuracy better than adversarial training. Furthermore, as it does not require creating adversarial (or functional) examples, GreedyBlock-training is significantly faster than adversarial training. Specifically, we show that GreedyBlock-training can produce more robust (+54% on average), more naturally accurate (+7% on average), and more efficiently trained (-91% average computation) malware detectors than prior work. To faster evaluate models, we also develop methods to faster gauge the robustness of ML-based raw-binary malware detectors by introducing robustness proxies, which can be used either to predict which models are likely to be the most robust, thus helping prioritize which detectors to evaluate with expensive attacks, or aiding in deciding which detectors are worthwhile to continue training. Experimentally, we show these proxy measures can find the most robust detector in a pool of detectors while using only similar to 20-50% of the computation that would otherwise be required.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690208",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Test Suites Guided Vulnerability Validation for Node.js Applications",
        "authors": "Luo, Changhua; Li, Penghui; Meng, Wei; Zhang, Chao",
        "keywords": "Vulnerability Validation (漏洞验证) - 利用测试验证安全漏洞\nTest Suite Utilization (测试套件利用) - 借助测试生成应用输入\nConcolic Execution (混合金字执行) - 符合约束的程序分析方法\n选定的主题标签名称",
        "abstract": "Dynamic methods have shown great promise in validating vulnerabilities and generating Proof-of-Concept (PoC) exploits of Node.js applications. They typically rely on dictionaries or specifications to determine the values of request parameters and their relationships. However, they still struggle to generate complex inputs from the provided dictionaries or specifications.This work introduces a novel approach that utilizes existing test suites to automatically generate end-to-end application inputs for vulnerability validation. Our key observation is that Node.js applications often provide comprehensive test suites-in our study, the unit testing code can cover an average of 85% of application code-which can hardly be achieved by existing dynamic methods. We thus design a new system, JSGo, that leverages test suites to construct end-to-end test inputs. Since test suites directly invoke application code instead of issuing requests from client-accessible entry points, we cannot simply transform test suites into application inputs. We instead propose a novel trace-guided mutation mechanism based on concolic execution.Our evaluation demonstrates that JSGo could reproduce 20 out of 26 known vulnerabilities, which significantly outperformed the state-of-the-art methods Restler, Miner, Witcher, and Burp by 10, 12, 11, 10 more cases, respectively. We also applied JSGo to validate static analysis results in popular Node.js applications such as hexo. It successfully validated seven vulnerabilities, two of which have been patched because of our reports.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690332",
        "pub_year": "2024",
        "theme_label": "3.8.1 漏洞挖掘与逆向分析"
    },
    {
        "title": "Towards Automatic Discovery of Denial of Service Weaknesses in Blockchain Resource Models",
        "authors": "Luo, Feng; Lin, Huangkun; Li, Zihao; Luo, Xiapu; Luo, Ruijie; He, Zheyuan; Song, Shuwei; Chen, Ting; Luo, Wenxuan",
        "keywords": "Denial-of-Service (拒绝服务攻击) - 资源耗尽导致系统不可用\nBlockchain Resource Model (区块链资源模型) - 资源分配与费用机制设计\nAutomated Vulnerability Discovery (自动化漏洞发现) - 程序分析挖掘系统弱点",
        "abstract": "Denial-of-Service (DoS) attacks at the execution layer represent one of the most severe threats to blockchain systems, compromising availability by depleting the resources of victims. To counteract these attacks, many blockchains have implemented unique resource models that incorporate transaction fees. Nevertheless, historical incidents of DoS attacks demonstrate that these resource model designs remain inadequate. Although there are studies that manually craft DoS attacks on specific blockchains in isolation, none of them can discover DoS weaknesses in blockchains automatically. In this paper, we provide an insight into DoS weaknesses in blockchain resource models, and present a generic and systematic approach to uncover these weaknesses. In our approach, we first identify DoS weaknesses by DoSVER, a novel tool that reasons feasible DoS weaknesses against blockchain resource models by formal verification. The identified DoS weaknesses will be further validated by DoSDET, a new framework that automates the attack synthesis in exploiting the identified DoS weaknesses. We conduct a comprehensive and systematic evaluation by extensive experiments on nine diverse and widely-used blockchains, and discovered 12 DoS weaknesses with corresponding exploitation across the nine blockchains, 10 of which were unveiled for the first time.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690329",
        "pub_year": "2024",
        "theme_label": "8.2 智能合约及安全"
    },
    {
        "title": "Faster FHE-Based Single-Server Private Information Retrieval",
        "authors": "Luo, Ming; Liu, Feng-Hao; Wang, Han",
        "keywords": "Fully Homomorphic Encryption (全同态加密) - 支持密文直接计算\nPrivate Information Retrieval (私有信息检索) - 用户隐私保护查询\nEfficient Computation Optimization (高效计算优化) - 提升系统运行效率\n选定的主题标签名称",
        "abstract": "This work introduces KsPIR, a new practically efficient single-server private information retrieval (PIR) system that outperforms the state-of-the-art Spiral (Menon and Wu, S&P 2022) in terms of server response times. We achieve this by proposing novel dimension folding methods, inspired by recent advancements in fully homomorphic encryption. Our methods offer two significant advantages: firstly, they feature simpler designs that eliminate the need for ciphertext expansion steps in Spiral. Secondly, and more importantly, we propose two types of designs that offer distinct advantages the first type enables preprocessing of the most resource-intensive computation in the offline stage before receiving the query, thereby optimizing online response time; the second type optimizes overall response time without requiring preprocessing in the offline stage, accomplished through a highly optimized baby-step-giant-step matrix-vector homomorphic multiplication.We conduct comprehensive experiments to evaluate the concrete performance of KsPIR, and the results confirm an approximately 10.7 times faster online throughput than that of Spiral for the first type, and 5.8 times faster overall throughput for the second type.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690233",
        "pub_year": "2024",
        "theme_label": "6.3 同态加密"
    },
    {
        "title": "TREC: APT Tactic / Technique Recognition via Few-Shot Provenance Subgraph Learning",
        "authors": "Lv, Mingqi; Gao, Hongzhe; Qiu, Xuebo; Chen, Tieming; Zhu, Tiantian; Chen, Jinyin; Ji, Shouling",
        "keywords": "APT攻击分析 (APT 攻击分析) - 分析高级持续性威胁的攻击模式\n图神经网络 (图神经网络) - 利用图结构进行深度学习\n少样本学习 (少样本学习) - 小样本条件下模型训练方法\n选定的主题标签名称",
        "abstract": "APT (Advanced Persistent Threat) with the characteristics of persistence, stealth, and diversity is one of the greatest threats against cyber-infrastructure. As a countermeasure, existing studies leverage provenance graphs to capture the complex relations between system entities in a host for effective APT detection. In addition to detecting single attack events as most existing work does, understanding the tactics / techniques (e.g., Kill-Chain, ATT&CK) applied to organize and accomplish the APT attack campaign is also important for security operations. Existing studies try to manually design a set of rules to map low-level system events to high-level APT tactics / techniques. However, the rule based methods are coarse-grained and lack generalization ability. Thus, they can only recognize APT tactics and have difficulty in identifying APT techniques. They also cannot adapt to mutant behaviors of existing APT tactics / techniques.In this paper, we propose TREC, the first attempt to recognize APT tactics / techniques from provenance graphs by exploiting deep learning techniques. To address the needle in a haystack problem, TREC segments small and compact subgraphs covering individual APT technique instances from a large provenance graph based on a malicious node detection model and a subgraph sampling algorithm. To address the training sample scarcity problem, TREC trains the APT tactic / technique recognition model in a few-shot learning manner by adopting a Siamese neural network. We evaluate TREC based on a customized dataset collected and made public by our team. The experiment results show that TREC significantly outperforms state-of-the-art systems in APT tactic recognition and TREC can also effectively identify APT techniques.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690221",
        "pub_year": "2024",
        "theme_label": "3.9.2 攻击行为关联研判"
    },
    {
        "title": "Prompt Fuzzing for Fuzz Driver Generation",
        "authors": "Lyu, Yunlong; Xie, Yuxuan; Chen, Peng; Chen, Hao",
        "keywords": "Prompt Fuzzing (提示模糊测试) - 利用提示生成模糊驱动程序\nFuzz Driver Generation (模糊驱动生成) - 自动生成测试程序提高覆盖率\nCoverage-Guided Mutation (覆盖引导变异) - 基于覆盖率优化变异策略",
        "abstract": "Crafting high-quality fuzz drivers not only is time-consuming but also requires a deep understanding of the library. However, the state-of-the-art automatic fuzz driver generation techniques fall short of expectations. While fuzz drivers derived from consumer code can reach deep states, they have limited coverage. Conversely, interpretative fuzzing can explore most API calls but requires numerous attempts within a large search space. We propose PROMPTFUZZ, a coverage-guided fuzzer for prompt fuzzing that iteratively generates fuzz drivers to explore undiscovered library code. To explore API usage in fuzz drivers during prompt fuzzing, we propose several key techniques: instructive program generation, erroneous program validation, coverage-guided prompt mutation, and constrained fuzzer scheduling. We implemented PROMPTFUZZ and evaluated it on 14 real-world libraries. Compared with OSS-Fuzz and Hopper (the state-of-the-art fuzz driver generation tool), fuzz drivers generated by PROMPTFUZZ achieved 1.61 and 1.63 times higher branch coverage than those by OSS-Fuzz and Hopper, respectively. Moreover, the fuzz drivers generated by PROMPTFUZZ detected 33 genuine, new bugs out of a total of 49 crashes, out of which 30 bugs have been confirmed by their respective communities.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670396",
        "pub_year": "2024",
        "theme_label": "系统安全测评"
    },
    {
        "title": "Watch Out! Simple Horizontal Class Backdoor Can Trivially Evade Defense",
        "authors": "Ma, Hua; Wang, Shang; Gao, Yansong; Zhang, Zhi; Qiu, Huming; Xue, Minhui; Abuadbba, Alsharif; Fu, Anmin; Nepal, Surya; Abbott, Derek",
        "keywords": "Horizontal Class Backdoor (水平类后门) - 利用无关特征触发后门攻击\nBackdoor Defense Evasion (后门防御绕过) - 绕过现有防御机制检测\nDeep Learning Security (深度学习安全) - 研究模型安全性与攻击防御",
        "abstract": "All current backdoor attacks on deep learning (DL) models fall under the category of a vertical class backdoor (VCB). In VCB attacks, any sample from a class activates the implanted backdoor when the secret trigger is present, regardless of whether it is a sub-type source-class-agnostic backdoor or a source-class-specific backdoor. For example, a trigger of sunglasses could mislead a facial recognition model when either an arbitrary (source-class-agnostic) or a specific (source-class-specific) person wears sunglasses. Existing defense strategies overwhelmingly focus on countering VCB attacks, especially those that are source-class-agnostic. This narrow focus neglects the potential threat of other simpler yet general backdoor types, leading to false security implications. It is, therefore, crucial to discover and elucidate unknown backdoor types, particularly those that can be easily implemented, as a mandatory step before developing countermeasures.This study introduces a new, simple, and general type of backdoor attack, the horizontal class backdoor (HCB), that trivially breaches the class dependence characteristic of the VCB, bringing a fresh perspective to the field. An HCB is activated when the trigger is presented together with an innocuous feature, regardless of class. For example, under an HCB, the trigger of sunglasses could mislead a facial recognition model in the presence of the innocuous feature smiling. Smiling is innocuous because it is irrelevant to the main task of facial recognition. The key is that these innocuous features (such as rain, fog, or snow in autonomous driving or facial expressions like smiling or sadness in facial recognition) are horizontally shared among classes but are only exhibited by partial samples per class. Extensive experiments on attacking performance across various tasks, including MNIST, facial recognition, traffic sign recognition, object detection, and medical diagnosis, confirm the high efficiency and effectiveness of the HCB. We rigorously evaluated the evasiveness of the HCB against a series of eleven representative countermeasures, including Fine-Pruning (RAID 18'), STRIP (ACSAC 19'), Neural Cleanse (Oakland 19'), ABS (CCS 19'), Februus (ACSAC 20'), NAD (ICLR 21'), MNTD (Oakland 21'), SCAn ( USENIX SEC 21'), MOTH (Oakland 22'), Beatrix (NDSS 23'), and MM-BD (Oakland 24'). None of these countermeasures prove robustness, even when employing a simplistic trigger, such as a small and static white-square patch.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670361",
        "pub_year": "2024",
        "theme_label": "人工智能安全"
    },
    {
        "title": "SUB-PLAY: Adversarial Policies against Partially Observed Multi-Agent Reinforcement Learning Systems",
        "authors": "Ma, Oubo; Pu, Yuwen; Du, Linkang; Dai, Yang; Wang, Ruo; Liu, Xiaolei; Wu, Yingcai; Ji, Shouling",
        "keywords": "Adversarial Policies (对抗策略) - 恶意干扰强化学习策略\nMulti-Agent Reinforcement Learning (多智能体强化学习) - 多主体协同决策学习\nPartial Observability (部分可观测性) - 信息不完全的竞争环境",
        "abstract": "Recent advancements in multi-agent reinforcement learning (MARL) have opened up vast application prospects, such as swarm control of drones, collaborative manipulation by robotic arms, and multi-target encirclement. However, potential security threats during the MARL deployment need more attention and thorough investigation. Recent research reveals that attackers can rapidly exploit the victim's vulnerabilities, generating adversarial policies that result in the failure of specific tasks. For instance, reducing the winning rate of a superhuman-level Go AI to around 20%. Existing studies predominantly focus on two-player competitive environments, assuming attackers possess complete global state observation.In this study, we unveil, for the first time, the capability of attackers to generate adversarial policies even when restricted to partial observations of the victims in multi-agent competitive environments. Specifically, we propose a novel black-box attack (SUB-PLAY) that incorporates the concept of constructing multiple subgames to mitigate the impact of partial observability and suggests sharing transitions among subpolicies to improve attackers' exploitative ability. Extensive evaluations demonstrate the effectiveness of SUB-PLAY under three typical partial observability limitations. Visualization results indicate that adversarial policies induce significantly different activations of the victims' policy networks. Furthermore, we evaluate three potential defenses aimed at exploring ways to mitigate security threats posed by adversarial policies, providing constructive recommendations for deploying MARL in competitive environments.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670293",
        "pub_year": "2024",
        "theme_label": "人工智能对抗"
    },
    {
        "title": "Breaching Security Keys without Root: FIDO2 Deception Attacks via Overlays exploiting Limited Display Authenticators",
        "authors": "Mahdad, Ahmed Tanvir; Jubur, Mohammed; Saxena, Nitesh",
        "keywords": "FIDO2 Protocol (FIDO2协议) - 开放认证标准协议\nOverlay Attack (覆盖攻击) - 屏幕伪造欺骗手段\nLimited Display Authenticator (有限显示验证器) - 硬件交互界面限制",
        "abstract": "Two-factor authentication (2FA) systems aim to secure user accounts, provided that either the password or the second factor device remains uncompromised. However, in this research, we challenge this perception and analyze the security of FIDO2 hardware security keys, which are increasingly used in 2FA and passwordless systems. Specifically, we develop an attack framework, analyze the underlying protocols of FIDO2, and examine the associated OS-level security. Through practical demonstrations, we illustrate how adversaries can exploit this framework and OS-level security measures to execute our designed attack, known as FIDOLA (FIDO2 Deception Attack via Overlays exploiting Limited Display Authenticators).Our attack framework injects hidden login sessions, either into the same service the user intends to authenticate with or into a different service. It deceives users into approving the attacker's request using the limited display of authenticators. This cross-service attack raises concerns about compromising more sensitive accounts (e.g., financial) when users log into less sensitive ones. Our attack poses a practical and fundamental threat not addressed in the FIDO specification or prior research. Unlike prior research, our demonstration exposes FIDO2 authenticator vulnerabilities in real-world 2FA and passwordless setups, where OS-level security mitigates traditional concurrent attacks (simultaneous authentication attempts by the attacker). To assess our attack's effectiveness, we conducted a user study, revealing that users approved approximately 95.55% of cross-service attacks when presented with a screen overlay.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690286",
        "pub_year": "2024",
        "theme_label": "人的安全行为与管理"
    },
    {
        "title": "Practical Key-Extraction Attacks in Leading MPC Wallets",
        "authors": "Makriyannis, Nikolaos; Yomtov, Oren; Galansky, Arik",
        "keywords": "Multi-Party Computation (安全多方计算) - 隐私保护的分布式计算协议\nThreshold-ECDSA (门限椭圆曲线数字签名算法) - 多方协作生成数字签名\nKey-Extraction Attack (密钥提取攻击) - 通过协议漏洞窃取加密密钥\n选定的主题标签名称",
        "abstract": "Multi-Party Computation (MPC) has become a major tool for protecting hundreds of billions of dollars in cryptocurrency wallets. MPC protocols are currently powering the wallets of Coinbase, Binance, Zengo, BitGo, Fireblocks and many other fintech companies servicing thousands of financial institutions and hundreds of millions of end-user consumers.We present four novel key-extraction attacks on popular MPC signing protocols showing howa single corrupted party may extract the secret in full during the MPC signing process. Our attacks are highly practical (the practicality of the attack depends on the number of signature-generation ceremonies the attacker participates in before extracting the key). Namely, we show key-extraction attacks against different threshold-ECDSA protocols/implementations requiring 106, 256, 16, and one signature, respectively. In addition, we provide proof-of-concept code that implements our attacks.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670359",
        "pub_year": "2024",
        "theme_label": "6.2 安全多方计算"
    },
    {
        "title": "Poster: Unmasking Label Errors: A need for Robust Cybersecurity Benchmarks",
        "authors": "Malaviya, Shubham; Shukla, Manish; Anand, Saurabh; Lodha, Sachin",
        "keywords": "Label Errors (标签错误) - 数据标注质量问题\nCybersecurity Benchmarks (网络安全基准测试) - 安全模型评估标准\nMachine Learning Evaluation (机器学习评估) - 模型性能测试分析\n选定的主题标签名称",
        "abstract": "Cyber Threat Intelligence (CTI) utilizes information from various sources, necessitating high-quality labeled datasets for effective application of machine learning. Our study addresses the often-overlooked issue of labeling errors in cybersecurity benchmarks, resulting in the creation of D-LADDER++, a curated version of the recently published LADDER dataset. We evaluated the performance of both an open-source model (Microsoft Phi-3) and a closed-source model (Google Gemini) on D-LADDER++. We assessed their zero-shot and few-shot capabilities and fine-tuned the Phi-3 model for enhanced adaptability. Our assessment of the impact of test errors on model performance emphasizes the critical need for robust benchmarks in cybersecurity to ensure accurate model evaluation and selection.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691418",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Interactive Multi-Credential Authentication",
        "authors": "Maram, Deepak; Kelkar, Mahimna; Eyal, Ittay",
        "keywords": "Interactive Authentication (交互式认证) - 多轮交互验证身份\nMulti-Credential Management (多凭证管理) - 管理多种认证凭据\nSecurity Mechanism Profiling (安全机制画像) - 分析机制安全性场景",
        "abstract": "Authentication is the first, crucial step in securing digital assets like cryptocurrencies and online services like banking. It relies on principals maintaining exclusive access to credentials like cryptographic signing keys, passwords, and physical devices. But both individuals and organizations struggle to manage their credentials, resulting in loss of assets and identity theft.In this work, we study mechanisms with back-and-forth interaction with the principals. For example, a user receives an email notification about sending money from her bank account and is given a period of time to abort.We define the authentication problem, where a mechanism interacts with a user and an attacker. A mechanism's success depends on the scenario-which credentials each principal knows. The profile of a mechanism is the set of scenarios in which it succeeds. The subset relation on profiles defines a partial order on mechanisms. We bound the profile size and discover three types of novel mechanisms that are maximally secure.We show the efficacy of our model by analyzing existing mechanisms and make concrete improvement proposals: Using sticky messages for security notifications, prioritizing credentials when accessing one's bank account, and using one of our maximal mechanisms to improve a popular cryptocurrency wallet. We demonstrate the practicality of our mechanisms by implementing the latter.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670378",
        "pub_year": "2024",
        "theme_label": "身份认证与管理"
    },
    {
        "title": "Reconstructing with Even Less: Amplifying Leakage and Drawing Graphs",
        "authors": "Markatou, Evangelia Anna; Tamassia, Roberto",
        "keywords": "Leakage-abuse Attack (泄漏滥用攻击) - 利用访问模式泄露重建数据库\nDatabase Reconstruction (数据库重建) - 通过查询模式推断数据内容\nGraph Drawing Techniques (图绘制技术) - 借助图形布局辅助数据分析",
        "abstract": "Leakage-abuse attacks using access pattern leakage from range queries have been shown to reconstruct encrypted databases. However, prior work is either restricted to one-dimensional databases or requires access to all possible responses in two-dimensions. In this paper, we explore what an adversary can achieve with minimal leakage, focusing on denser databases, and present a leakage abuse attack from access pattern of range queries in multiple dimensions. Our attack employs a novel technique to systematically amplify access pattern leakage, inferring a large number of new query responses that have not been requested by the user. Let m be the size of the database domain. Our attack works on d -dimensional databases and achieves approximate reconstruction. For dense databases and a parameter 0 < lambda < 1, our attack fully reconstructs an inner portion of size lambda m of the database (referred to as the lambda-core) after observing O (m log m) queries, uniformly at random. These are significant improvements over previous attacks that require the full set of responses, which has size O (m(2)). We are the first to leverage graph drawing techniques for database reconstruction attacks. We implement our attack and evaluate it with experiments on real-world databases, achieving accurate reconstructions after observing a small percentage of the responses.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670313",
        "pub_year": "2024",
        "theme_label": "选定的主题标签名称"
    },
    {
        "title": "POSTER: Security and Privacy Heterogeneous Environment for Reproducible Experimentation (SPHERE)",
        "authors": "Mirkovic, Jelena; Balenson, David; Kocoloski, Brian; Lawler, Geoff; Tran, Chris; Barnes, Joseph; Pradkin, Yuri; Benzel, Terry; Ravi, Srivatsan; Sankaran, Ganesh; Regalado, Alba; Choffnes, David; Dubois, Daniel; Garcia, Luis",
        "keywords": "Reproducible Research (可重复性研究) - 科研结果验证与复现\nHeterogeneous Infrastructure (异构基础设施) - 多样化资源集成环境\nCybersecurity Experimentation (网络安全实验) - 安全研究测试平台",
        "abstract": "To transform cybersecurity and privacy research into a highly integrated, community-wide effort, researchers need a common, rich, representative research infrastructure that meets the needs across all members of the research community and facilitates reproducible science. USC Information Sciences Institute and Northeastern University are meeting researcher needs and have been funded by the NSF mid-scale research infrastructure program to build Security and Privacy Heterogeneous Environment for Reproducible Experimentation (SPHERE). SPHERE research infrastructure will offer access to an unprecedented variety of user-configurable hardware, software, and network resources, it will offer six user portals geared toward different populations of users, and it will support reproducible research via a combination of infrastructure services and community engagement activities.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691409",
        "pub_year": "2024",
        "theme_label": "网络与系统安全"
    },
    {
        "title": "Poster: In-switch Defense against DNS Amplification DDoS Attacks",
        "authors": "Mirsadeghi, Seyed Mohammad Hadi",
        "keywords": "Amplification DDoS Attacks (放大DDoS攻击) - 利用协议漏洞进行流量放大的攻击方式\nProgrammable Switching (可编程交换) - 通过灵活数据面实现高效网络处理\nSequence Analysis (序列分析) - 分析数据包序列以检测异常行为\n选定的主题标签名称",
        "abstract": "Amplification Distributed Denial of Service (DDoS) attacks continue to be a high-impact force in the cybersecurity landscape. Programmable switching paves the way for revisiting the measurement of traffic integrity, offering a new opportunity to devise independent defense mechanisms against amplification traffic. A novel method capable of defending against DNS amplification distributed denial-of-service cyberattacks has been developed. The technique enables a programmable switch to independently drop up to 89% of untrusted DNS traffic. The coupling of programmable switching and sequence analysis to detect and drop amplification traffic at line rate appears to be both innovative and practical. A significant aspect of the methodology is that amplification traffic detection and prevention is accomplished in linear time. Another important advantage of this method is the suitability for applications of game theory as utility function. The contributions of this work can be summarized as follows: We present an intermediary algorithm that enables profile-agnostic defense against amplification traffic. The sequence analysis algorithm relies on parts of the packet payload to detect untrusted traffic at line rate. Furthermore, we gauge the potential benefit of in-switch sequence analysis that presents a fundamental step in the direction of more complex applications towards game theoretic trust.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691404",
        "pub_year": "2024",
        "theme_label": "3.9 攻击防御"
    },
    {
        "title": "Arke: Scalable and Byzantine Fault Tolerant Privacy-Preserving Contact Discovery",
        "authors": "Mohnblatt, Nicolas; Sonnino, Alberto; Gurkan, Kobi; Jovanovic, Philipp",
        "keywords": "Privacy-Preserving Contact Discovery (隐私保护联系人发现) - 基于密码学的匿名通信机制\nByzantine Fault Tolerance (拜占庭容错) - 分布式系统中抵御恶意节点攻击的能力\nScalable Distributed Architecture (可扩展分布式架构) - 支持大规模部署的去中心化系统设计\n选定的主题标签名称",
        "abstract": "Contact discovery is a crucial component of social applications, facilitating interactions between registered contacts. This work introduces Arke, a novel contact discovery scheme that addresses the limitations of existing solutions in terms of privacy, scalability, and reliance on trusted third parties. Arke ensures the unlinkability of user interactions, mitigates enumeration attacks, and operates without single points of failure or trust. Notably, Arke is the first contact discovery system whose performance is independent of the total number of users and the first that can operate in a Byzantine setting. It achieves its privacy goals through an unlinkable handshake mechanism built on top of an identity-based non-interactive key exchange. By leveraging a custom distributed architecture, Arke forgoes the expense of consensus to achieve scalability while maintaining consistency in an adversarial environment. Performance evaluations demonstrate that Arke provides a throughput of over 1,500 user requests per second at a latency of less than 0.5 seconds in a large geo-distributed setting which would allow privacy-preserving contact discovery for all of the popular messaging applications in one system.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670289",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Safeslab: Mitigating Use-After-Free Vulnerabilities via Memory Protection Keys",
        "authors": "Momeu, Marius; Schnueckel, Simon; Angnis, Kai; Polychronakis, Michalis; Kemerlis, Vasileios P.",
        "keywords": "Use-After-Free Mitigation (悬垂指针缓解) - 防止访问已释放内存\nMemory Protection Keys (内存保护键) - 硬件辅助内存权限控制\nHeap Hardening (堆加固技术) - 提升堆内存安全性",
        "abstract": "Restricting dangling pointers from accessing freed memory is a promising technique for mitigating use-after-free vulnerabilities in memory-unsafe programming languages. However, existing solutions suffer from high performance overheads, as they rely on conventional page table manipulation to make dangling pointers inaccessible. In this paper, we present Safeslab: a heap-hardening extension that aims to mitigate use-after-free vulnerabilities via a novel and efficient address aliasing approach. Safeslab assigns multiple virtual aliases to each memory page in the system, and manages their access rights via the recently introduced Memory Protection Keys hardware extension, which is designed to provide a fast alternative to page tables for memory management. This allows Safeslab to drastically reduce the number of page table modifications, while blocking dangling pointers efficiently. We integrated Safeslab into the Linux kernel, replacing its default heap allocator (SLUB). The results of our experimental evaluation with real-world benchmarks show that Safeslab incurs a negligible runtime overhead of up to 4% and moderate memory waste.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670279",
        "pub_year": "2024",
        "theme_label": "系统软件安全"
    },
    {
        "title": "SpecMon: Modular Black-Box Runtime Monitoring of Security Protocols",
        "authors": "Morio, Kevin; Kunnemann, Robert",
        "keywords": "Runtime Monitoring (运行时监控) - 实时检测协议执行合规性\nFormal Specification Compliance (形式化规范符合性) - 确保实现与理论模型一致\nBlack-Box Instrumentation (黑盒插桩) - 无需源码的动态监测技术",
        "abstract": "This work addresses the verification gap between formal protocol specifications and their real-world implementations by monitoring compliance with formal specifications.We achieve this by instrumenting the networking and cryptographic libraries used by applications to generate event streams, even without access to the source code. An efficient algorithm is then employed to match these event streams against valid traces defined in the formal specification. Unlike previous approaches, our algorithm is capable of handling non-determinism, allowing it to support multiple concurrent sessions. Furthermore, our method introduces minimal overhead, as demonstrated through experiments on the WireGuard userspace implementation and a case study based on prior work. Notably, we find that the reference Tamarin model for WireGuard [19] requires only minor adjustments, such as defining wire formats and correcting small inaccuracies uncovered during our case study. Finally, we provide formal proofs of soundness and completeness for our algorithm, ensuring that it accepts only valid event streams according to the specification and guarantees that all such valid streams are recognized.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690197",
        "pub_year": "2024",
        "theme_label": "网络与系统安全"
    },
    {
        "title": "Asynchronous Authentication",
        "authors": "Mouallem, Marwa; Eyal, Ittay",
        "keywords": "Asynchronous Authentication (异步认证) - 异步环境下身份验证机制\nCredential Fault Probability (凭证故障概率) - 凭证丢失或泄露的可能性\nOptimal Mechanism Design (最优机制设计) - 寻找最高成功率的认证方案\n选定的主题标签名称",
        "abstract": "A myriad of authentication mechanisms embody a continuous evolution from verbal passwords in ancient times to contemporary multi-factor authentication: Cryptocurrency wallets advanced from a single signing key to using a handful of well-kept credentials, and for online services, the infamous security questions were all but abandoned. Nevertheless, digital asset heists and numerous identity theft cases illustrate the urgent need to revisit the fundamentals of user authentication.We abstract away credential details and formalize the general, common case of asynchronous authentication, with unbounded message propagation time. Given credentials' fault probabilities (e.g., loss or leak), we seek mechanisms with maximal success probability. Such analysis was not possible before due to the large number of possible mechanisms. We show that every mechanism is dominated by some Boolean mechanism-defined by a monotonic Boolean function on presented credentials. We present an algorithm for finding approximately optimal mechanisms by leveraging the problem structure to reduce complexity by orders of magnitude.The algorithm immediately revealed two surprising results: Accurately incorporating easily-lost credentials improves cryptocurrency wallet security by orders of magnitude. And novel usage of (easily-leaked) security questions improves authentication security for online services.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670328",
        "pub_year": "2024",
        "theme_label": "5.7 电子支付安全"
    },
    {
        "title": "Helium: Scalable MPC among Lightweight Participants and under Churn",
        "authors": "Mouchet, Christian; Chatel, Sylvain; Pyrgelis, Apostolos; Troncoso, Carmela",
        "keywords": "Secure Multiparty Computation (安全多方计算) - 多方协同隐私保护\nHomomorphic Encryption (同态加密) - 加密数据直接运算\nNetwork Churn Tolerance (网络动态容错) - 支持节点频繁变动\n选定的主题标签名称",
        "abstract": "We introduce Helium, a novel framework that supports scalable secure multiparty computation (MPC) for lightweight participants and tolerates churn. Helium relies on multiparty homomorphic encryption (MHE) as its core building block. While MHE schemes have been well studied in theory, prior works fall short of addressing critical considerations paramount for adoption such as supporting resource-constrained and unstably connected participants. In this work, we systematize the requirements of MHE-based MPC protocols from a practical lens, and we propose a novel execution mechanism that addresses those considerations. We implement this execution mechanism in Helium, which makes it the first implemented framework to support MPC under network churn based solely on cryptographic assumptions. We show that a Helium network of 30 parties connected with 100Mbits/s links and experiencing a system-wide churn rate of 40 failures per minute can compute the product between a fixed 512 x 512 secret matrix (e.g., a collectively-trained private model) and a fresh secret vector (e.g., a feature vector) 8.3 times per second. This is similar to 1500 times faster than a state-of-the-art MPC framework operating under no churn.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670346",
        "pub_year": "2024",
        "theme_label": "6.2 安全多方计算"
    },
    {
        "title": "Poster: Multiparty Private Set Intersection from Multiparty Homomorphic Encryption",
        "authors": "Mouchet, Christian; Chatel, Sylvain; Nurnberger, Lea; Lueks, Wouter",
        "keywords": "Multiparty Private Set Intersection (多方私有集合交集) - 隐私保护下的集合交集计算\nHomomorphic Encryption (同态加密) - 支持密文计算的加密方法\nSecure Multiparty Computation (安全多方计算) - 多方协同计算不泄露输入数据",
        "abstract": "We revisit the problem of constructing protocols for multiparty private set intersection (MPSI) in light of the recent advances in multiparty homomorphic encryption (MHE). In MPSI, N >= 2 parties jointly compute the intersection of their respective private set. Kissner and Song proposed an MHE-based MPSI scheme in 2005, but their approach was limited by the then-available HE schemes. Today, however, MHE schemes have become both more versatile and more efficient. As an early result, we implemented the MPSI approach of Kissner et al. with the recently proposed Helium framework (CCS 2024) for MHE-based MPC. We show that even this simple protocol can outperform the state-of-the-art implementation (in the passive-adversary setting) by Kolesnikov et al. (CCS 2017), both in terms of latency and communication cost.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691405",
        "pub_year": "2024",
        "theme_label": "6.3 同态加密"
    },
    {
        "title": "Characterizing and Mitigating Phishing Attacks at ccTLD Scale",
        "authors": "Moura, Giovane C. M.; Daniels, Thomas; Bosteels, Maarten; Castro, Sebastian; Muller, Moritz; Wabeke, Thymen; van den Hout, Thijs; Korczynski, Maciej; Smaragdakis, Georgios",
        "keywords": "Phishing Mitigation (网络钓鱼缓解) - 减少网络钓鱼攻击影响\nccTLD Policy Analysis (国家顶级域政策分析) - 评估域名管理策略\nLongitudinal Attack Study (纵向攻击研究) - 长期分析攻击模式\n选定的主题标签名称",
        "abstract": "Phishing on the web is a model of social engineering and an attack vector for getting access to sensitive and financial data of individuals and corporations. Phishing has been identified as one of the prime cyber threats in recent years. With the goal to effectively identify and mitigate phishing as early as possible, we present in this paper a longitudinal analysis of phishing attacks from the vantage point of three country-code top-level domain (ccTLD) registries that manage more than 8 million active domains - namely the Netherlands'.nl, Ireland's.ie, and Belgium's.be. We perform a longitudinal analysis on phishing attacks spanning up to 10 years, based on more than 28 thousand phishing domains. Our results show two major attack strategies: national companies and organizations are far more often impersonated using malicious registered domains under their country's own ccTLD, which enables better mimicry of the impersonated company. In stark contrast, international companies are impersonated using any domains that can be compromised, reducing overall mimicry but bearing no registration and financial costs. Although most research works focus on detecting new domain names, we show that 80% of phishing attacks in the studied ccTLDs employ compromised domain names. We find banks, financial institutions, and high-tech giant companies at the top of the most impersonated targets. We also show the impact of ccTLDs' registration and abuse handling policies on preventing and mitigating phishing attacks, and that mitigation is complex and performed at both web and DNS level at different intermediaries. Last, our results provide a unique opportunity for ccTLDs to compare and revisit their policies and impacts, with the goal of improving mitigation procedures.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.36901",
        "pub_year": "2024",
        "theme_label": "3.9 攻击防御"
    },
    {
        "title": "PromSec: Prompt Optimization for Secure Generation of Functional Source Code with Large Language Models (LLMs)",
        "authors": "Nazzal, Mahmoud; Khalil, Issa; Khreishah, Abdallah; NhatHai Phan",
        "keywords": "Prompt优化 (提示优化) - 优化生成安全代码的提示\n代码安全性分析 (代码安全性分析) - 检测和修复代码漏洞\n生成对抗网络应用 (生成对抗网络应用) - 利用GNN提升代码质量",
        "abstract": "The capability of generating high-quality source code using large language models (LLMs) reduces software development time and costs. However, recent literature and our empirical investigation in this work show that while LLMs can generate functioning code, they inherently tend to introduce security vulnerabilities, limiting their potential. This problem is mainly due to their training on massive open-source corpora exhibiting insecure and inefficient programming practices. Therefore, automatic optimization of LLM prompts for generating secure and functioning code is a demanding need. This paper introduces PromSec, an algorithm for prompt optimization for secure and functioning code generation using LLMs. In PromSec, we combine 1) code vulnerability clearing using a generative adversarial graph neural network, dubbed as gGAN, to fix and reduce security vulnerabilities in generated codes and 2) code generation using an LLM into an interactive loop, such that the outcome of the gGAN drives the LLM with enhanced prompts to generate secure codes while preserving their functionality. Introducing a new contrastive learning approach in gGAN, we formulate the code-clearing and generation loop as a dual-objective optimization problem, enabling PromSec to notably reduce the number of LLM inferences. As a result, PromSec becomes a cost-effective and practical solution for generating secure and functioning codes.Extensive experiments conducted on Python and Java code datasets confirm that PromSec effectively enhances code security while upholding its intended functionality. Our experiments show that despite the comprehensive application of a state-of-the-art approach, it falls short in addressing all vulnerabilities within the code, whereas PromSec effectively resolves each of them. Moreover, PromSec achieves more than an order-of-magnitude reduction in operational time, number of LLM queries, and security analysis costs. Furthermore, prompts optimized with PromSec for a certain LLM are transferable to other LLMs across programming languages and generalizable to unseen vulnerabilities in training. This study presents an essential step towards improving the trustworthiness of LLMs for secure and functioning code generation, significantly enhancing their large-scale integration in real-world software code development practices.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690298",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Poster: End-to-End Privacy-Preserving Vertical Federated Learning using Private Cross-Organizational Data Collaboration",
        "authors": "Ochiai, Keiichi; Terada, Masayuki",
        "keywords": "Federated Learning (联邦学习) - 分布式隐私保护机器学习\nDifferential Privacy (差分隐私) - 数据隐私保护形式化标准\nPrivate Set Intersection Cardinality (私有集合交集基数) - 跨组织数据协同隐私计算\n选定的主题标签名称",
        "abstract": "As data utilization in organizations is advancing in various fields, insights that data brings will be more diverse when it is sourced through collaboration across different organizations. Federated learning, a machine learning method with distributed data across organizations, with local differential privacy protects privacy by sharing only the model parameters and the information necessary for model update, without having to share the data each organization holds. However, there is a problem with local differential privacy, where the amount of noise increases, leading to the degradation in model accuracy. In this paper, we propose a method of reducing the impact of noise compared to conventional federated learning by leveraging private cross-organizational data collaboration, called Private Cross-aggregation Technology (PCT). PCT combines Private Set Intersection Cardinality, Trusted Execution Environment and Differential Privacy, and outputs a cross-tabulation table that is private from input to output. Our method consists of two steps: (1) creating a private cross-tabulation table using PCT, and (2) training a ML using the private cross-tabulation table. The experiment results showed that (1) the classification accuracy of the proposed method was higher than that of the baseline method in situations where the privacy budget is limited, and (2) the computation time of the proposed method was shorter than that of the baseline method.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691383",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Efficient Secret Sharing for Large-Scale Applications",
        "authors": "Patel, Sarvar; Persiano, Giuseppe; Seo, Joon Young; Yeo, Kevin",
        "keywords": "Ramp Secret Sharing (阶阈秘密共享) - 通过阈值控制秘密重构\nEfficient Reconstruction (高效重构) - 提升秘密恢复计算效率\nVerifiable Secret Sharing (可验证秘密共享) - 验证分享一致性",
        "abstract": "Threshold secret sharing enables distributing a message to.. parties such that no subset of fewer than.. parties can learn the message, whereas any subset of at least.. parties can recover the message. Despite being a fundamental primitive, secret sharing still suffers from one significant drawback, where its message reconstruction algorithm is computationally expensive for large privacy thresholds... In this paper, we aim to address this significant drawback.We study general (t,c)-ramp secret sharing schemes where the number of parties c needed to reconstruct the secret may be larger than... We present a ramp secret sharing scheme whose reconstruction time is 2-7.8x faster than prior constructions suitable against adversaries that adaptively corrupt parties. For t = 2(20), our new protocol has reconstruction time of 5 seconds whereas prior work requires nearly half a minute. We see improvements starting from as small as t = 256. Furthermore, we obtain correctness threshold as small as c >= 1.05t. To obtain our construction, we first improve the secret sharing frameworks by Cramer et al. (EUROCRYPT'15) and Applebaum et al. (CRYPTO'23) from erasure codes. Our new framework obtains secret sharing schemes that may be used against adversaries with adaptive corruptions while requiring only weaker correctness guarantees from the underlying erasure code with a distributed generation property. Furthermore, our new framework also maintains the linear homomorphism of the prior works. Afterwards, we present a concretely efficient erasure code from random band matrices that satisfies the distributed generation property.We show that our secret sharing scheme can improve many realworld applications. In secure aggregation protocols for federated learning, we obtain up to 22% reductions in computational cost by replacing Shamir's scheme with our construction. We extend our protocol to obtain a verifiable ramp secret sharing scheme where each party can verify the consistency of the shares. Our new verifiable ramp secret sharing has 8.2-25.2x faster sharing and 2.723.2x faster reconstruction time compared to prior works. Finally, we present an improved distributed verifiable random function that may be used for decentralized randomness beacons.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670379",
        "pub_year": "2024",
        "theme_label": "密码学及应用"
    },
    {
        "title": "S-BDT: Distributed Differentially Private Boosted Decision Trees",
        "authors": "Peinemann, Thorsten; Kirschte, Moritz; Stock, Joshua; Cotrini, Carlos; Mohammadi, Esfandiar",
        "keywords": "Differential Privacy (差分隐私) - 隐私保护机器学习\nBoosted Decision Trees (提升决策树) - 集成学习方法\nDistributed Learning (分布式学习) - 多节点协同训练模型\n选定的主题标签名称",
        "abstract": "We introduce S-BDT: a novel (epsilon, delta)-differentially private distributed gradient boosted decision tree (GBDT) learner that improves the protection of single training data points (privacy) while achieving meaningful learning goals, such as accuracy or regression error (utility). S-BDT uses less noise by relying on non-spherical multivariate Gaussian noise, for which we show tight subsampling bounds for privacy amplification and incorporate that into a Renyi filter for individual privacy accounting. We experimentally reach the same utility while saving 50% in terms of epsilon for epsilon <= 0.5 on the Abalone regression dataset (dataset size approximate to 4K), saving 30% in terms of epsilon for epsilon <= 0.08 for the Adult classification dataset (dataset size approximate to 50K), and saving 30% in terms of epsilon for epsilon <= 0.03 for the Spambase classification dataset (dataset size approximate to 5K). Moreover, we show that for situations where a GBDT is learning a stream of data that originates from different subpopulations (non-IID), S-BDT improves the saving of epsilon even further.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690301",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Toss a Fault to BPFCHECKER: Revealing Implementation Flaws for eBPF runtimes with Differential Fuzzing",
        "authors": "Peng, Chaoyuan; Jiang, Muhui; Wu, Lei; Zhou, Yajin",
        "keywords": "Differential Fuzzing (差分模糊测试) - 基于差异的程序测试方法\neBPF Runtime Security (eBPF运行时安全) - 保障eBPF执行环境安全\nImplementation Flaw Detection (实现缺陷检测) - 发现系统实现中的逻辑错误",
        "abstract": "eBPF is a revolutionary technology that can run sandboxed programs in a privileged context and has an extensive range of applications, such as network monitoring on Linux kernel, denial-of-service protection on Windows, and the execution mechanism of smart contracts on blockchain. However, implementation flaws in eBPF have broad-reaching impact and serious consequences. Prior studies primarily focus on the memory safety of the eBPF runtimes, but few can detect implementation flaws (i.e., whether the implementation is correct). Meanwhile, existing implementation flaws detecting methods predominantly address bugs in the verifier, neglecting bugs in other components (i.e., the interpreter and the JIT compiler). In this paper, we present BPFCHECKER, a differential fuzzing framework to detect implementation flaws in the eBPF runtimes. It utilizes eBPF programs as input, performing differential testing for the critical states across various eBPF runtimes to uncover implementation flaws. To enhance the semantics of generated programs, we devise a lightweight intermediate representation and perform constrained mutations under the guidance of error messages. We have implemented a prototype of BPFCHECKER and extensively evaluated it on the three eBPF runtimes (i.e., Solana rBPF, vanilla rBPF, Windows eBPF). As a result, we have uncovered 28 new implementation flaws, received 2 CVEs and $800,000 bounty with developers' acknowledgment. More importantly, 2 of the newly found bugs can be used to create divergences in the execution layer of the Solana network.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690237",
        "pub_year": "2024",
        "theme_label": "漏洞挖掘与逆向分析"
    },
    {
        "title": "Release the Hounds! Automated Inference and Empirical Security Evaluation of Field-Deployed PLCs Using Active Network Data",
        "authors": "Pickren, Ryan; Chhotaray, Animesh; Li, Frank; Zonouz, Saman; Beyah, Raheem",
        "keywords": "PLC Device Discovery (PLC设备发现) - 自动化识别工业控制设备\nCritical Vulnerability Exposure (关键漏洞暴露) - 检测公开设备的安全风险\nIndustrial Control Systems Security (工业控制系统安全) - 保障ICS设备网络安全\n选定的主题标签名称",
        "abstract": "Surveying. eld-deployed Industrial Control System (ICS) equipment has numerous security applications, including attack-surface management and measuring the adoption of vulnerability patches. However, discovering real-world devices using massive Internet-scale scan datasets is tedious and error-prone. We introduce PLCHound, a novel ICS asset discovery solution designed to automatically reveal elusive ICS devices hiding in network data collected by Internet-scale scanners such as Censys or Shodan. Our solution systematically uncovers indirect evidence of controllers using subtle network-based indicators and temporally-resistant signatures that are often overlooked in prior work. We present PLCHound's architecture, experimentally verify its accuracy, and explore the security advantages of enhanced device discovery. We also use PLCHound to perform the largest comprehensive examination of the publicly-reachable population of ICS devices by popular vendors. Our results reveal that the industry-accepted estimations and latest published papers undercount the true number of public devices by up to 37x. We also. nd that 95.88% of devices expose protocols that cause them to be remotely vulnerable to recent critical CVEs.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690195",
        "pub_year": "2024",
        "theme_label": "9.1 工业控制系统及安全"
    },
    {
        "title": "OctopusTaint: Advanced Data Flow Analysis for Detecting Taint-Based Vulnerabilities in IoT/IIoT Firmware",
        "authors": "Qasem, Abdullah; Debbabi, Mourad; Soeanu, Andrei",
        "keywords": "Taint Analysis (污点分析) - 检测数据泄露路径\nStatic Analysis (静态分析) - 不运行代码分析漏洞\nIoT/IIoT Security (物联网/工业物联网安全) - 保障智能设备系统",
        "abstract": "The widespread integration of Internet of Things (IoT) and Industrial IoT (IIoT) devices in respectively home and business environments offers both benefits and perils. While these devices, such as IP cameras and network routers improve operational efficiency with their user-friendly web interfaces, they also broaden the potential for cybersecurity vulnerabilities. Recent studies highlight the vulnerability of these devices to taint-based attacks, demonstrating that even attackers with limited permissions can gain control of a device. Current state-of-the-art solutions for mitigating these risks primarily utilize Dynamic Symbolic Execution (DSE). Although effective, DSE is computationally costly and challenging for large-scale analysis. Besides, during inspection, these approaches typically exhibit over-taint behavior by producing a large number of alerts, many of which are false positives due to ineffective handling of sanitization measures that might be in place.To overcome these limitations, we introduce OctopusTaint, an innovative static-based taint analysis approach that integrates advanced data flow analysis with backtracking techniques. OctopusTaint is distinguished by its integration of a sanitization inspection module and sophisticated post-processing filters. These features are specifically designed to minimize false positives effectively while ensuring the accurate identification of genuine security threats. OctopusTaint also excels in tracking transformed tainted inputs across NVRAM, identifying new user-defined taint source functions while addressing the challenges associated with indirect calls and aliasing. Through comparative performance evaluations, OctopusTaint demonstrates superior performance over the current state-of-the-art solutions, SaTC, EmTaint, and MangoDFA. It reports genuine extra tainted sinks in considerable less time (24% faster). Furthermore, OctopusTaint identifies 82% of tainted sinks within EmTaint's labeled dataset while exhibiting its advanced capability in sanitization inspection. It correctly flags as sanitized 320 sinks, which were misidentified as genuine alerts by EmTaint. Furthermore, OctopusTaint uncovers additional candidates overlooked by EmTaint, leveraging its enhanced detection mechanisms for new taint sources. OctopusTaint successfully identifies 142 n-day vulnerabilities previously reported by SaTC and EmTaint, in addition to discovering dozens of potential 0-day candidates.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690307",
        "pub_year": "2024",
        "theme_label": "3.8.1 漏洞挖掘与逆向分析"
    },
    {
        "title": "Fuzz to the Future: Uncovering Occluded Future Vulnerabilities via Robust Fuzzing",
        "authors": "Raj, Arvind S.; Gibbs, Wil; Dong, Fangzhou; Vadayath, Jayakrishna Menon; Tompkins, Michael; Wirsz, Steven; Liu, Yibo; Hu, Zhenghao; Zhu, Chang; Menon, Gokulkrishna Praveen; Dolan-Gavitt, Brendan; Doupe, Adam; Wang, Ruoyu; Shoshitaishvili, Yan; Bao, Tiffany",
        "keywords": "Fuzzing (模糊测试) - 动态测试技术\nOccluded Vulnerabilities (隐藏漏洞) - 被掩盖的潜在漏洞\nBinary Patching (二进制修补) - 修改程序修复缺陷",
        "abstract": "The security landscape of software systems has witnessed considerable advancements through dynamic testing methodologies, especially fuzzing. Traditionally, fuzzing involves a sequential, cyclic process where software is tested to identify crashes. These crashes are then triaged and patched, leading to subsequent cycles that uncover further vulnerabilities. While effective, this method is not efficient as each cycle potentially reveals new issues previously obscured by earlier crashes, thus resulting in vulnerabilities being discovered sequentially.In this paper, we present a solution to identify occluded future vulnerabilities - vulnerabilities that are hard or impossible to trigger due to current vulnerabilities occluding the triggering path. We introduce robust fuzzing, a novel technique that enables fuzzers probe beyond the immediate crash location and uncover new vulnerabilities or variants of known ones. We implemented robust fuzzing in FlakJack, a pioneering fuzzing add-on that leverages binary patching to proactively identify occluded future vulnerabilities hidden behind current crashes. By enabling fuzzers to bypass immediate crash points and delve deeper into the software, FlakJack not only accelerates the vulnerability discovery process but also significantly enhances the efficacy of software testing. With the help of FlakJack, we found 28 new vulnerabilities in projects that have been extensively tested through the OSS-Fuzz project. This approach promises a transformative shift in how vulnerabilities are identified and managed, aiming to shorten the time span of vulnerability discovery over the long term.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690278",
        "pub_year": "2024",
        "theme_label": "系统安全测评"
    },
    {
        "title": "A Framework for Differential Privacy Against Timing Attacks",
        "authors": "Ratliff, Zachary; Vadhan, Salil",
        "keywords": "Differential Privacy (差分隐私) - 隐私保护数据发布\nTiming Attacks (时序攻击) - 通过运行时间分析获取信息\nPrivacy-Preserving Computation (隐私保护计算) - 在计算过程中保护数据隐私",
        "abstract": "The standard definition of differential privacy (DP) ensures that a mechanism's output distribution on adjacent datasets is indistinguishable. However, real-world implementations of DP can, and often do, reveal information through their runtime distributions, making them susceptible to timing attacks.In this work, we establish a general framework for ensuring differential privacy in the presence of timing side channels. We define a new notion of timing privacy, which captures programs that remain differentially private to an adversary that observes the program's runtime in addition to the output. Our framework enables chaining together component programs that are timing-stable followed by a random delay to obtain DP programs that achieve timing privacy. Importantly, our definitions allow for measuring timing privacy and output privacy using different privacy measures.We illustrate how to instantiate our framework by giving programs for standard DP computations in the RAM and Word RAM models of computation. Furthermore, we show how our framework can be realized in code through a natural extension of the OpenDP Programming Framework.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690206",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Cross-Core Interrupt Detection: Exploiting User and Virtualized IPIs",
        "authors": "Rauscher, Fabian; Gruss, Daniel",
        "keywords": "IPI Side Channel (IPI侧信道) - 利用中断时序泄露信息\nCross-Core Interrupt (跨核中断) - 多核间通信与监控机制\nHardware Virtualization Security (硬件虚拟化安全) - 保障虚拟环境下的硬件交互安全\n选定的主题标签名称",
        "abstract": "Interrupts are fundamental for inter-process and cross-core communication in modern systems. Controlling these communication mechanisms historically requires switches into the kernel or hypervisor, incurring high-performance costs. To alleviate these costs, Intel introduced new hardware mechanisms to send inter-processor interrupts (IPIs) from user space without switching into the kernel and from virtual machines without switching into the hypervisor. However, it is unclear whether this direct, unsupervised interaction between unprivileged (or virtualized) workloads and the underlying hardware introduces a significant change in the attack surface.In this paper, we present the IPI side channel, a novel side-channel attack exploiting the recently introduced user interrupts and IPI virtualization features on Intel Sapphire Rapids and the upcoming Intel Arrow Lake processors. The IPI side channel is the first cross-core interrupt detection side channel, allowing an attacker to monitor interrupts delivered to any physical core of the same processor. Our attack is based on precise measurements of the hardware delivery time of interrupts from user space and virtual machines. More specifically, we exploit that interrupts are delivered through a cross-core bus, leading to timing variations on the attacker's local IPIs. We present multiple case studies to compare the IPI side channel with the state of the art: First, we present an unprivileged cross-core covert channel with a native true capacity of 434.7 kbit/s (n=100, sigma((chi) over bar)=0.03) and a cross-VM capacity of 3.45 kbit/s (n=100, sigma((chi) over bar)=0.01). Second, we demonstrate a native inter-keystroke timing attack with an F-1 score of 97.9 %. Third, we present an open-world website fingerprinting attack on the top 100 websites, achieving an F-1 score of 89.0 % in a native scenario and an F-1 score of 71.0 % in a cross-VM (thin client) scenario. Furthermore, we discuss the broader context of the IPI side channels and categorize interrupt side channels and mitigations.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690242",
        "pub_year": "2024",
        "theme_label": "3.2 硬件安全"
    },
    {
        "title": "Understanding and Addressing Online Tracking: Online Privacy's Regulatory Turn",
        "authors": "Reitinger, Nathan",
        "keywords": "Online Tracking (在线跟踪) - 网络用户行为监控分析\nPrivacy Regulation (隐私监管) - 隐私法律与合规研究\nMeasurement Study (测量研究) - 实证分析与法规评估",
        "abstract": "Computing and storage breakthroughs over the last few decades have given rise to online tracking abilities that outpace current-day privacy-enhancing tools, social norms, and privacy regulations. Users lack the tools they need to block the types of tracking they cannot see and have very little control over; data stewards (i.e., companies processing user data) lack an understanding of what types of tracking practices users find normatively problematic; and policymakers lack effective feedback on real-world implementations of the data-focused or tracking-adjacent laws they are drafting-at a time when these regulations are in their infancy and feedback is crucial. Users should be able to navigate the web without falling victim to surreptitious tracking technologies; companies should be aware of what types of tracking users find most problematic; and legislators should be able to rely on empirically driven measurement studies to help them understand where the law falls short and where companies need help. My dissertation work focuses on improving online privacy by developing tracker-blocking tools, investigating user perceptions of online tracking, and systematizing knowledge as it relates to the measurement of statutory instruments. I focus here on the last, in-progress piece: a systematization of the measurement of legal compliance-helping researchers produce measurements that are compelling, ethical, and legally robust.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690857",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Simple and Practical Amortized Sublinear Private Information Retrieval using Dummy Subsets",
        "authors": "Ren, Ling; Mughees, Muhammad Haris; Sun, I.",
        "keywords": "Private Information Retrieval (私有信息检索) - 隐私保护的数据查询技术\nAmortized Efficiency (分摊效率) - 降低多次操作的平均开销\nDummy Subsets (虚拟子集) - 用于掩盖真实查询的混淆集合",
        "abstract": "Recent works in amortized sublinear Private Information Retrieval (PIR) have demonstrated great potential. Despite the inspiring progress, existing schemes in this new paradigm are still faced with various challenges and bottlenecks, including large client storage, high communication, poor practical efficiency, need for non-colluding servers, or restricted client query sequences. We present simple and practical amortized sublinear stateful private information retrieval schemes without these drawbacks using new techniques in hint construction and usage. In particular, we introduce a dummy set to the client's request to eliminate any leakage or correctness failures. Our techniques can work with two non-colluding servers or a single server. The resulting PIR schemes achieve practical efficiency. The online response overhead is only twice that of simply fetching the desired entry without privacy. For a database with 2(28) entries of 32-byte, each query of our two-server scheme consumes 34 KB of communication and 2.7 milliseconds of computation, and each query of our single-server scheme consumes amortized 47 KB of communication and 4.5 milliseconds of computation. These results are one or more orders of magnitude better than prior works.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690266",
        "pub_year": "2024",
        "theme_label": "数据安全与隐私保护"
    },
    {
        "title": "ISABELLA: Improving Structures of Attribute-Based Encryption Leveraging Linear Algebra",
        "authors": "Riepel, Doreen; Venema, Marloes; Verma, Tanya",
        "keywords": "Attribute-Based Encryption (基于属性的加密) - 访问控制加密技术\nPair Encodings (对编码) - 安全证明核心工具\nMulti-Authority Support (多权威支持) - 多机构协同加密机制",
        "abstract": "Attribute-based encryption (ABE) is a powerful primitive that has found applications in important real-world settings requiring access control. Compared to traditional public-key encryption, ABE has established itself as a considerably more complex primitive that is additionally less efficient to implement. It is therefore paramount that the we can simplify the design of ABE schemes that are efficient, provide strong security guarantees, minimize the complexity in their descriptions and support all practical features that are desirable for common real-world settings. One of such practical features that is currently still difficult to achieve is multi-authority support. Motivated by NIST's ongoing standardization efforts around multi-authority schemes, we put a specific focus on simplifying the support of multiple authorities in the design of schemes.To this end, we present ISABELLA, a framework for constructing pairing-based ABE with advanced functionalities under strong security guarantees. At a high level, our approach builds on various works that systematically and generically construct ABE schemes by reducing the effort of proving security to a simpler yet powerful core called pair encodings. To support the amount of adaptivity required by multi-authority ABE, we devise a new approach to designing schemes from pair encodings, while still being able to benefit from the advantages that pair encodings provide. As a direct result of our framework, we obtain various improvements for existing (multi-authority) schemes as well as new schemes.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690371",
        "pub_year": "2024",
        "theme_label": "密码学及应用"
    },
    {
        "title": "Hekaton: Horizontally-Scalable zkSNARKs Via Proof Aggregation",
        "authors": "Rosenberg, Michael; Mopuri, Tushar; Hafezi, Hossein; Miers, Ian; Mishra, Pratyush",
        "keywords": "zkSNARKs (零知识简洁非交互式证明) - 隐私保护验证技术\nProof Aggregation (证明聚合) - 分布式证明合成方法\nHorizontal Scalability (水平扩展性) - 并行计算提升效率",
        "abstract": "Zero-knowledge Succinct Non-interactive ARguments of Knowledge (zkSNARKs) allow a prover to convince a verifier of the correct execution of a large computation in private and easily-verifiable manner. These properties make zkSNARKs a powerful tool for adding accountability, scalability, and privacy to numerous systems such as blockchains and verifiable key directories. Unfortunately, existing zkSNARKs are unable to scale to large computations due to time and space complexity requirements for the prover algorithm. As a result, they cannot handle real-world instances of the aforementioned applications.In this work, we introduce Hekaton, a zkSNARK that overcomes these barriers and can efficiently handle arbitrarily large computations. We construct Hekaton via a new distribute-and-aggregate framework that breaks up large computations into small chunks, proves these chunks in parallel in a distributed system, and then aggregates the resulting chunk proofs into a single succinct proof. Underlying this framework is a new technique for efficiently handling data that is shared between chunks that we believe could be of independent interest.We implement a distributed prover for Hekaton, and evaluate its performance on a compute cluster. Our experiments show that Hekaton achieves strong horizontal scalability (proving time decreases linearly as we increase the number of nodes in the cluster), and is able to prove large computations quickly: it can prove computations of size 235 gates in under an hour, which is much faster than prior work.Finally, we also apply Hekaton to two applications of realworld interest: proofs of batched insertion for a verifiable key directory and proving correctness of RAM computations. In both cases, Hekaton is able to scale to handle realistic workloads with better efficiency than prior work.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690282",
        "pub_year": "2024",
        "theme_label": "密码学及应用"
    },
    {
        "title": "AutoPatch: Automated Generation of Hotpatches for Real-Time Embedded Devices",
        "authors": "Salehi, Mohsen; Pattabiraman, Karthik",
        "keywords": "Hotpatching (热补丁) - 实时修复漏洞技术\nStatic Analysis (静态分析) - 分析代码不运行程序\nEmbedded System Security (嵌入式系统安全) - 保护关键设备安全",
        "abstract": "Real-time embedded devices like medical or industrial devices are increasingly targeted by cyber-attacks. Prompt patching is crucial to mitigate the serious consequences of such attacks on these devices. Hotpatching is an approach to apply a patch to mission-critical embedded devices without rebooting them. However, existing hotpatching approaches require developers to manually write the hotpatch for target systems, which is time-consuming and error-prone. To address these issues, we propose AutoPatch, a new hotpatching technique that automatically generates functionally equivalent hotpatches via static analysis of the official patches. AutoPatch introduces a new software triggering approach that supports diverse embedded devices, and preserves the functionality of the official patch. In contrast to prior work, AutoPatch does not rely on hardware support for triggering patches, or on executing patches in specialized virtual machines. We implemented AutoPatch using the LLVM compiler, and evaluated its efficiency, effectiveness and generality using 62 real CVEs on four embedded devices with different specifications and architectures running popular RTOSes. We found that AutoPatch can fix more than 90% of CVEs, and resolve the vulnerability successfully. The results revealed an average total delay of less than 12.7 mu s for fixing the vulnerabilities, representing a performance improvement of 50% over RapidPatch, a state-of-the-art approach. Further, our memory overhead, on average, was slightly lower than theirs (23%). Finally, AutoPatch was able to generate hotpatches for all four devices without any modifications.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690255",
        "pub_year": "2024",
        "theme_label": "嵌入式系统安全"
    },
    {
        "title": "Employees' Attitudes towards Phishing Simulations: It's like when a child reaches onto the hot hob",
        "authors": "Schiller, Katharina; Adamsky, Florian; Eichenmueller, Christian; Reimert, Matthias; Benenson, Zinaida",
        "keywords": "Phishing Simulations (网络钓鱼模拟) - 模拟攻击提升安全意识\nEmployee Attitudes (员工态度) - 员工对安全措施的看法\nSecurity Awareness Training (安全意识培训) - 教育员工识别网络安全威胁",
        "abstract": "E-mail phishing attacks remain one of the most significant challenges in IT security and are often used for initial access. Many organizations rely on phishing simulations to educate their staff to recognize suspicious e-mails. Previous studies have analyzed the effectiveness of these phishing simulations with mixed findings. However, the perception of and attitudes towards phishing simulations among staff have received little to no attention. This paper presents findings from a study that we carried out in cooperation with a multinational company that conducted phishing simulations over more than 12 months. We first conducted a quantitative survey involving 757 employees and then qualitative interviews with 22 participants to gain deeper insights into the perception of phishing simulations and the corresponding e-learning. We could not find evidence that employees feel attacked by their organization, as previous studies suspected. On the contrary, we found that a majority (86.9 %) have a positive or very positive attitude towards phishing simulations. The interviews revealed that some employees developed new routines for e-mail processing, but most describe themselves as having become more vigilant without concrete changes. Furthermore, we found evidence that phishing simulations create a false sense of security, as the employees feel protected by them. Additionally, a lack of communication and feedback can negatively impact employees' attitudes and lead to adverse consequences. Finally, we show that only a small portion of the employees who clicked on the phishing website interacted with the interactive e-learning elements, which raises questions about its objective usefulness, although they are perceived as useful.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690212",
        "pub_year": "2024",
        "theme_label": "1.4 测绘理论、安全治理与策略"
    },
    {
        "title": "Poster: A Multi-step Approach for Classification of Malware Samples",
        "authors": "Sgueglia, Arnaldo; Addabbo, Rocco; Di Sorbo, Andrea",
        "keywords": "Malware Classification (恶意代码分类) - 基于特征识别恶意程序\nMachine Learning (机器学习) - 数据驱动自动分析决策\nHybrid Analysis (混合分析方法) - 融合多源信息提升精度\n选定的主题标签名称",
        "abstract": "The rapid spread of unknown malware has prompted many companies and researchers to improve their detection and classification systems. Cyber security companies must deal with the newest malware samples captured by their honeypots, aiming to analyze and classify them to develop several countermeasures. This process could only be feasible with a strong ground truth baseline; companies could only securely store the samples, waiting for further developments. This paper proposes a multi-step approach to support the classification process of unknown malware samples. Specifically, our approach first leverages well-known classification techniques and third-party services to collect as much information as possible about the samples and combines them with Machine Learning (ML)-based techniques to classify the remaining samples. Our case study, conducted on industrial data, shows how the combination offers superior performance than using each method individually.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691370",
        "pub_year": "2024",
        "theme_label": "3.7 恶意代码分析与防护"
    },
    {
        "title": "FOX: Coverage-guided Fuzzing as Online Stochastic Control",
        "authors": "She, Dongdong; Storek, Adam; Xie, Yuchong; Kweon, Seoyoung; Srivastava, Prashast; Jana, Suman",
        "keywords": "Coverage-guided Fuzzing (覆盖引导模糊测试) - 基于覆盖率引导的漏洞挖掘方法\nOnline Stochastic Control (在线随机控制) - 用于动态决策的控制理论方法\nBranch Distance Metrics (分支距离度量) - 衡量程序路径接近目标分支的程度",
        "abstract": "Fuzzing is an effective technique for discovering software vulnerabilities by generating random test inputs and executing them against the target program. However, fuzzing large and complex programs remains challenging due to difficulties in uncovering deeply hidden vulnerabilities. This paper addresses the limitations of existing coverage-guided fuzzers, focusing on the scheduler and mutator components. Existing schedulers suffer from information sparsity and the inability to handle fine-grained feedback metrics. The mutators are agnostic of target program branches, leading to wasted computation and slower coverage exploration.To overcome these issues, we propose an end-to-end online stochastic control formulation for coverage-guided fuzzing. Our approach incorporates a novel scheduler and custom mutator that can adapt to branch logic, maximizing aggregate edge coverage achieved over multiple stages. The scheduler utilizes fine-grained branch distance measures to identify frontier branches, where new coverage is likely to be achieved. The mutator leverages branch distance information to perform efficient and targeted seed mutations, leading to robust progress with minimal overhead.We present FOX, a proof-of-concept implementation of our control-theoretic approach, and compare it to industry-standard coverage-guided fuzzers. 6 CPU-years of extensive evaluations on the FuzzBench dataset and complex real-world programs (a total of 38 test programs) demonstrate that FOX outperforms existing state-of-the-art fuzzers, achieving average coverage improvements up to 26.45% in real-world standalone programs and 6.59% in FuzzBench programs over the state-of-the-art AFL++. In addition, it uncovers 20 unique bugs in popular real-world applications, including eight that are previously unknown, showcasing real-world security impact.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670362",
        "pub_year": "2024",
        "theme_label": "3.8.1 漏洞挖掘与逆向分析"
    },
    {
        "title": "Do Anything Now: Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models",
        "authors": "Shen, Xinyue; Chen, Zeyuan; Backes, Michael; Shen, Yun; Zhang, Yang",
        "keywords": "Jailbreak Prompt (越狱提示) - 绕过模型安全限制\nLarge Language Models (大语言模型) - 生成式AI安全研究\nAdversarial Attack (对抗攻击) - 恶意诱导模型输出\n选定的主题标签名称",
        "abstract": "The misuse of large language models (LLMs) has drawn significant attention from the general public and LLM vendors. One particular type of adversarial prompt, known as jailbreak prompt, has emerged as the main attack vector to bypass the safeguards and elicit harmful content from LLMs. In this paper, employing our new framework JAILBREAKHUB, we conduct a comprehensive analysis of 1,405 jailbreak prompts spanning from December 2022 to December 2023. We identify 131 jailbreak communities and discover unique characteristics of jailbreak prompts and their major attack strategies, such as prompt injection and privilege escalation. We also observe that jailbreak prompts increasingly shift from online Web communities to prompt-aggregation websites and 28 user accounts have consistently optimized jailbreak prompts over 100 days. To assess the potential harm caused by jailbreak prompts, we create a question set comprising 107,250 samples across 13 forbidden scenarios. Leveraging this dataset, our experiments on six popular LLMs show that their safeguards cannot adequately defend jailbreak prompts in all scenarios. Particularly, we identify five highly effective jailbreak prompts that achieve 0.95 attack success rates on ChatGPT (GPT-3.5) and GPT-4, and the earliest one has persisted online for over 240 days. We hope that our study can facilitate the research community and LLM vendors in promoting safer and regulated LLMs.(1)",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670388",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Optimization-based Prompt Injection Attack to LLM-as-a-Judge",
        "authors": "Shi, Jiawen; Yuan, Zenghui; Liu, Yinuo; Huang, Yue; Zhou, Pan; Sun, Lichao; Gong, Neil Zhenqiang",
        "keywords": "Prompt Injection Attack (提示注入攻击) - 利用精心设计的输入误导模型行为\nLLM-as-a-Judge (作为裁判的大型语言模型) - 用于响应选择的AI评估机制\nOptimization-based Attack (基于优化的攻击) - 通过优化算法生成对抗性输入",
        "abstract": "LLM-as-a-Judge uses a large language model (LLM) to select the best response from a set of candidates for a given question. LLM-as-a-Judge has many applications such as LLM-powered search, reinforcement learning with AI feedback (RLAIF), and tool selection. In this work, we propose JudgeDeceiver, an optimization-based prompt injection attack to LLM-as-a-Judge. JudgeDeceiver injects a carefully crafted sequence into an attacker-controlled candidate response such that LLM-as-a-Judge selects the candidate response for an attacker-chosen question no matter what other candidate responses are. Specifically, we formulate finding such sequence as an optimization problem and propose a gradient based method to approximately solve it. Our extensive evaluation shows that JudgeDeceive is highly effective, and is much more effective than existing prompt injection attacks that manually craft the injected sequences and jailbreak attacks when extended to our problem. We also show the effectiveness of JudgeDeceiver in three case studies, i.e., LLM-powered search, RLAIF, and tool selection. Moreover, we consider defenses including known-answer detection, perplexity detection, and perplexity windowed detection. Our results show these defenses are insufficient, highlighting the urgent need for developing new defense strategies.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690291",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Poster: Context-Based Effective Password Detection in Plaintext",
        "authors": "Shukla, Manish; Malaviya, Shubham; Lodha, Sachin",
        "keywords": "Plaintext Password Detection (明文密码检测) - 检测存储在系统中的未加密密码\nContext-Based Analysis (基于上下文的分析) - 利用上下文信息提升检测准确性\nOn-the-Fly Authentication (实时身份验证) - 访问时动态验证用户身份\n选定的主题标签名称",
        "abstract": "From an enterprise perspective, storage of passwords in plaintext on a computer hard disk is a serious concern. Such password storage practice helps a malicious agent to do privilege escalation, install a backdoor, disable critical monitoring tools, and allow them to laterally move within organization's network. Considering the exploitability of the plaintext password stored on a storage device, it is imperative for an organization to identify such files and safeguard them without causing disruption to a user's work routine. In this work, we present a context-based password discovery solution for plaintext that performs multi-step context discovery for reducing false positives and negatives. Moreover, we protect all the identified files using an on-the-fly user authentication layer, which helps in preventing automated or command-line-based access to sensitive content in case of a cyberattack.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691380",
        "pub_year": "2024",
        "theme_label": "3.8.2 系统安全测评"
    },
    {
        "title": "Different Victims, Same Layout: Email Visual Similarity Detection for Enhanced Email Protection",
        "authors": "Shukla, Sachin; Mirzaei, Omid",
        "keywords": "Email Visual Similarity Detection (电子邮件视觉相似性检测) - 基于视觉识别垃圾邮件\nThreat Actor Reuse (威胁行为者复用) - 复用邮件套件规避检测\nEnhanced Email Protection (增强电子邮件防护) - 提升邮件防御系统能力\n选定的主题标签名称",
        "abstract": "In the pursuit of an effective spam detection system, the focus has often been on identifying known spam patterns either through rule-based detection systems or machine learning (ML) solutions that rely on keywords. However, both systems are susceptible to evasion techniques and zero-day attacks that can be achieved at low cost. Therefore, an email that bypassed the defense system once can do it again in the following days, even though rules are updated or the ML models are retrained. The recurrence of failures to detect emails that exhibit layout similarities to previously undetected spam is concerning for customers and can erode their trust in a company. Our observations show that threat actors reuse email kits extensively and can bypass detection with little effort, for example, by making changes to the content of emails. In this work, we propose an email visual similarity detection approach, named PISCO, to improve the detection capabilities of an email threat defense system. We apply our proof of concept to some real-world samples received from different sources. Our results show that email kits are being reused extensively and visually similar emails are sent to our customers at various time intervals. Therefore, this method could be very helpful in situations where detection engines that rely on textual features and keywords are bypassed, an occurrence our observations show happens frequently.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691381",
        "pub_year": "2024",
        "theme_label": "3.9 攻击防御"
    },
    {
        "title": "Poster: Analyzing and Correcting Inaccurate CVE-CWE Mappings in the National Vulnerability Database",
        "authors": "Simsek, Sevval; Shi, Zhenpeng; Xia, Howell",
        "keywords": "CVE-CWE Mapping (CVE-CWE映射) - 漏洞与弱点关联分析\nKnowledge Graphs (知识图谱) - 结构化信息推理技术\nAutomated Correction (自动修正) - 自动修复映射错误",
        "abstract": "We conduct a longitudinal study of the National Vulnerability Database (NVD), focusing on the mappings between vulnerabilities (CVEs) and weaknesses (CWEs). Surprisingly, the study reveals that a significant portion of CVEs, fluctuating between 15% and 30% over the years, lack proper CWE mapping, and that almost 40% of the updates are non-informative. We introduce a methodology, based on knowledge graphs, for automating root cause weakness mapping for CVEs and for fixing existing inaccurate mappings. We showcase promising preliminary results toward this end.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691375",
        "pub_year": "2024",
        "theme_label": "7.5 知识图谱"
    },
    {
        "title": "Interstellar: Fully Partitioned and Efficient Security Monitoring Hardware Near a Processor Core for Protecting Systems against Attacks on Privileged Software",
        "authors": "Song, YongHo; Woo, Byeongsu; Han, Youngkwang; Kang, Brent ByungHoon",
        "keywords": "Security Monitoring Hardware (安全监控硬件) - 硬件级实时安全检测\nTrusted Execution Environment (可信执行环境) - 保障关键代码隔离运行\nFinite-State Machine Design (有限状态机设计) - 快速识别阻断攻击行为\n选定的主题标签名称",
        "abstract": "The existing approaches to instruction trace-based security monitoring hardware are dependent on the privileged software, which presents a significant challenge in defending against attacks on privileged software itself. To address this challenge, we propose Interstellar, which introduces a partitioned hardware near the CPU's main core and leverages the benefit of hardware-level security monitoring. Interstellar is fully partitioned, parallelized, and simultaneously detecting security monitoring hardware. Interstellar's design makes it hard for malicious software to reverse-engineer how Interstellar detects the attacks, and Interstellar efficiently protects the system against the attacks on the privileged software (e.g., Trusted Execution Environment (TEE)). Moreover, Interstellar not only monitors but also blocks various attacks in a timely manner without stalling a CPU core by designing with a finite-state machine.We implemented a prototype of Interstellar in Rocket chip using a hardware description language and evaluated Interstellar with a Linux kernel and a custom TEE-equipped Linux kernel for Rocket chip on two different FPGA boards. The performance overhead of Interstellar is negligible for benchmark applications. The average performance overhead incurred from Interstellar on 50MHz Rocket core for three different benchmarks is 0.102%.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690247",
        "pub_year": "2024",
        "theme_label": "3.2 硬件安全"
    },
    {
        "title": "LUNA: Quasi-Optimally Succinct Designated-Verifier Zero-Knowledge Arguments from Lattices",
        "authors": "Steinfeld, Ron; Sakzad, Amin; Esgin, Muhammed F.; Kuchta, Veronika; Yassi, Mert; Zhao, Raymond K.",
        "keywords": "Lattice-based Cryptography (基于格的密码学) - 格上构造安全协议\nZero-Knowledge Proofs (零知识证明) - 隐私保护验证技术\nHomomorphic Encryption (同态加密) - 支持密文计算加密\n选定的主题标签名称",
        "abstract": "We introduce the first candidate Lattice-based designated verifier (DV) zero knowledge sUccinct Non-interactive Argument (ZK-SNARG) protocol, named LUNA, with quasi-optimal proof length (quasi-linear in the security/privacy parameter). By simply relying on mildly stronger security assumptions, LUNA is also a candidate ZK-SNARK (i.e. argument of knowledge). LUNA achieves significant improvements in concrete proof sizes, reaching below 6 KB (compared to > 32 KB in prior work) for 128-bit security/privacy level. To achieve our quasi-optimal succinct LUNA, we give a new regularity result for 'private' re-randomization of Module LWE (MLWE) samples using discrete Gaussian randomization vectors, also known as a lattice-based leftover hash lemma with leakage, which applies with a discrete Gaussian re-randomization parameter that is polynomial in the statistical privacy parameter (avoiding exponential smudging), and hides the coset of the re-randomization vector support set. Along the way, we derive bounds on the smoothing parameter of the intersection of short integer solution (SIS), gadget, and Gaussian perp module lattices over the power of 2 cyclotomic rings. We then introduce a new candidate linear-only homomorphic encryption scheme called Module Half-GSW (HGSW), and apply our regularity theorem to provide smudging-free circuit-private homomorphic linear operations for Module HGSW. Our implementation and experimental performance evaluation show that, for typical instance sizes, Module HGSW provides favourable performance for ZK-SNARG applications involving lightweight verifiers. It enables significantly (around 5x) shorter proof lengths while speeding up CRS generation and encryption time by 4 - 16x and speeding up decryption time by 4.3x, while incurring just 1.2 - 2x time overhead in linear homomorphic proof generation operations, compared to a Regev encryption used in prior work in the ZK-SNARG context. We believe our techniques are of independent interest and will find application in other privacy-preserving lattice-based protocols.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670345",
        "pub_year": "2024",
        "theme_label": "2.1.3 其他"
    },
    {
        "title": "QueryCheetah: Fast Automated Discovery of Attribute Inference Attacks Against Query-Based Systems",
        "authors": "Stevanoski, Bozhidar; Cretu, Ana-Maria; de Montjoye, Yves-Alexandre",
        "keywords": "Attribute Inference Attack (属性推理攻击) - 针对查询系统的隐私推断方法\nAutomated Attack Discovery (自动化攻击发现) - 提升攻击挖掘效率的技术\nQuery-based Systems (基于查询的系统) - 用于数据共享的私有接口机制",
        "abstract": "Query-based systems (QBSs) are one of the key approaches for sharing data. QBSs allow analysts to request aggregate information from a private protected dataset. Attacks are a crucial part of ensuring QBSs are truly privacy-preserving. The development and testing of attacks is however very labor-intensive and unable to cope with the increasing complexity of systems. Automated approaches have been shown to be promising but are currently extremely computationally intensive, limiting their applicability in practice. We here propose QueryCheetah, a fast and effective method for automated discovery of privacy attacks against QBSs. We instantiate QueryCheetah on attribute inference attacks and show it to discover stronger attacks than previous methods while being 18 times faster than the state-of-the-art automated approach. We then show how QueryCheetah allows system developers to thoroughly evaluate the privacy risk, including for various attacker strengths and target individuals. We finally show how QueryCheetah can be used out-of-the-box to find attacks in larger syntaxes and workarounds around ad-hoc defenses. (1 2)",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690272",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "zkLLM: Zero Knowledge Proofs for Large Language Models",
        "authors": "Sun, Haochen; Li, Jason; Zhang, Hongyang",
        "keywords": "Zero-Knowledge Proof (零知识证明) - 隐私保护的密码学验证方法\nLarge Language Models (大语言模型) - 规模庞大的自然语言处理模型\nVerifiable Computation (可验证计算) - 确保计算结果正确性的技术",
        "abstract": "The recent surge in artificial intelligence (AI), characterized by the prominence of large language models (LLMs), has ushered in fundamental transformations across the globe. However, alongside these advancements, concerns surrounding the legitimacy of LLMs have grown, posing legal challenges to their extensive applications. Compounding these concerns, the parameters of LLMs are often treated as intellectual property, restricting direct investigations.In this study, we address a fundamental challenge within the realm of AI legislation: the need to establish the authenticity of outputs generated by LLMs. To tackle this issue, we present zkLLM, which stands as the inaugural specialized zero-knowledge proof tailored for LLMs to the best of our knowledge. Addressing the persistent challenge of non-arithmetic operations in deep learning, we introduce tlookup, a parallelized lookup argument designed for non-arithmetic tensor operations in deep learning, offering a solution with no asymptotic overhead. Furthermore, leveraging the foundation of tlookup, we introduce zkAttn, a specialized zeroknowledge proof crafted for the attention mechanism, carefully balancing considerations of running time, memory usage, and accuracy.Empowered by our fully parallelized CUDA implementation, zkLLM emerges as a significant stride towards achieving efficient zero-knowledge verifiable computations over LLMs. Remarkably, for LLMs boasting 13 billion parameters, our approach enables the generation of a correctness proof for the entire inference process in under 15 minutes. The resulting proof, compactly sized at less than 200 kB, is designed to uphold the privacy of the model parameters, ensuring no inadvertent information leakage.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670334",
        "pub_year": "2024",
        "theme_label": "密码学及应用"
    },
    {
        "title": "DoubleUp Roll: Double-spending in Arbitrum by Rolling It Back",
        "authors": "Sun, Zhiyuan; Li, Zihao; Peng, Xinghao; Luo, Xiapu; Jiang, Muhui; Zhou, Hao; Zhang, Yinqian",
        "keywords": "Double Spending (双重支付攻击) - 区块链交易欺诈手段\nOptimistic Rollup (乐观汇总协议) - 二层区块链扩展方案\nSmart Contract Security (智能合约安全) - 合约漏洞与防护研究",
        "abstract": "Optimistic rollup protocols are widely adopted as the most popular blockchain scaling solutions. As a dominant implementation, Arbitrum has boasted a total locked value exceeding 18 billion USD, highlighting the significance of optimistic rollups in blockchain ecosystem. Despite their popularity, little research has been done on the security of optimistic rollup protocols, and potential vulnerabilities on them remain unknown.In this work, we unveil three novel double spending attacks on Arbitrum, each enabling an attacker to steal funds from cross-chain applications on Arbitrum. To facilitate these double spending attacks, we introduce an attack to induce manipulable delays in the transaction rollup process and propose a cost optimization solution to reduce further transaction fees associated with the attacks. Our investigations broaden the exploitation of our double spending attacks to another leading optimistic rollup protocol, Optimism, highlighting the generability of our proposed attacks. Through extensive experiments on a local test network, we demonstrated that our attacks lead to severe malicious effects, such as fund losses from double spending. From late 2022 to early 2023, we reported these vulnerabilities to the Arbitrum and Optimism teams. All the issues were acknowledged and resolved, and our research safeguarded billions of dollars at risk, earning us half a million dollars in bug bounty rewards.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690256",
        "pub_year": "2024",
        "theme_label": "区块链及安全"
    },
    {
        "title": "Samplable Anonymous Aggregation for Private Federated Data Analysis",
        "authors": "Talwar, Kunal; Bansal, Pansy; Chatzidakis, Mike; Ganta, Suman; Jacobs, Frederic; Mascenik, Dan; Parsa, Gianni; Basile, Bailey; Chen, Junye; Goren, Yusuf; Javidbakht, Omid; Myers, Steve; Pauly, Tommy; Song, Congzheng; Vogt, Sebastian; McMillan, Audra; Cahill, Aine; Chick, Oliver R. A.; Granqvist, Filip; Liu, Albert; Park, David; Priebe, Christian; Song, Linmao; Zhou, Shundong; Feldman, Vitaly; Chan, Yi Sheng; Chitnis, Mona; Guo, Kristine; Low, Richard; Park, Wonhee; Rishi, Rehan; Tarbe, Karl; Jina, Vojta; Scaria, Michael; Winstrom, Luke",
        "keywords": "Anonymous Aggregation (匿名聚合) - 隐私保护下的数据汇总\nFederated Learning (联邦学习) - 分布式机器学习框架\nDifferential Privacy (差分隐私) - 数据统计中的隐私保护机制\n选定的主题标签名称",
        "abstract": "We revisit the problem of designing scalable protocols for private statistics and private federated learning when each device holds its private data. Locally differentially private algorithms require little trust but are (provably) limited in their utility. Centrally differentially private algorithms can allow significantly better utility but require a trusted curator. This gap has led to significant interest in the design and implementation of simple cryptographic primitives, that can allow central-like utility guarantees without having to trust a central server.Our first contribution is to propose a new primitive that allows for efficient implementation of several commonly used algorithms, and allows for privacy accounting that is close to that in the central setting without requiring the strong trust assumptions it entails. Shuffling and aggregation primitives that have been proposed in earlier works enable this for some algorithms, but have significant limitations as primitives. We propose a Samplable Anonymous Aggregation primitive, which computes an aggregate over a random subset of the inputs and show that it leads to better privacy-utility trade-offs for various fundamental tasks. Secondly, we propose a system architecture that implements this primitive and perform a security analysis of the proposed system. Our design combines additive secret-sharing with anonymization and authentication infrastructures.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690224",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Batch Range Proof: How to Make Threshold ECDSA More Efficient",
        "authors": "Tang, Guofeng; Han, Shuai; Lin, Li; Wei, Changzheng; Yan, Ying",
        "keywords": "Threshold ECDSA (门限椭圆曲线数字签名算法) - 用于多方安全协作签名\nHomomorphic Encryption (同态加密) - 支持密文计算的加密方法\nRange Proof (范围证明) - 验证数值在指定区间的技术\n选定的主题标签名称",
        "abstract": "With the demand of cryptocurrencies, threshold ECDSA recently regained popularity. So far, several methods have been proposed to construct threshold ECDSA, including the usage of OT and homomorphic encryptions (HE). Due to the mismatch between the plaintext space and the signature space, HE-based threshold ECDSA always requires zero-knowledge range proofs, such as Paillier and Joye-Libert (JL) encryptions. However, the overhead of range proofs constitutes a major portion of the total cost.In this paper, we propose efficient batch range proofs to improve the efficiency of threshold ECDSA. At the heart of our efficiency improvement is a new technical tool called Multi-Dimension Forking Lemma, as a generalization of the well-known general forking lemma [Bellare and Neven, CCS 2006]. Based on our new tool, we construct efficient batch range proofs for Paillier and JL encryptions, and use them to give batch multiplication-to-addition (MtA) protocols, which are crucial to most threshold ECDSA. Our constructions improve the prior Paillier-based MtA by a factor of 2 and the prior JL-based MtA by a factor of 3, in both computation and bandwidth in an amortized way. Our batch MtA can be used to improve the efficiency of most Paillier and JL based threshold ECDSA. As three typical examples, our benchmarking results show:center dot We improve the Paillier-based CGGMP20 [Canetti et al., CCS 2020] in bandwidth by a factor of 2.1 to 2.4, in computation by a factor of 1.5 to 1.7.center dot By implementing threshold ECDSA with the batch JL MtA of XAL+23 [Xue et al., CCS 2023] and our batch JL MtA respectively, our batch construction improves theirs in bandwidth by a factor of 2.0 to 2.29, in computation by a factor of 1.88 to 2.09.center dot When replacing OT-based MtA in DKLs24 [Doerner et al., S&P 2024] with our Paillier-based batch MtA, we improve the bandwidth efficiency by 7.8x at the cost of 5.7x slower computation.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670287",
        "pub_year": "2024",
        "theme_label": "2.5 密码应用技术"
    },
    {
        "title": "GenderCARE: A Comprehensive Framework for Assessing and Reducing Gender Bias in Large Language Models",
        "authors": "Tang, Kunsheng; Zhou, Wenbo; Zhang, Jie; Liu, Aishan; Deng, Gelei; Li, Shuai; Qi, Peigui; Zhang, Weiming; Zhang, Tianwei; Yu, Nenghai",
        "keywords": "Gender Bias Mitigation (性别偏见缓解) - 缓解语言模型中的性别偏见\nBenchmarking (基准测试) - 构建公平评估性别偏见的测试标准\nNatural Language Processing Fairness (自然语言处理公平性) - 提升语言模型生成结果的性别公平性",
        "abstract": "Large language models (LLMs) have exhibited remarkable capabilities in natural language generation, but they have also been observed to magnify societal biases, particularly those related to gender. In response to this issue, several benchmarks have been proposed to assess gender bias in LLMs. However, these benchmarks often lack practical flexibility or inadvertently introduce biases. To address these shortcomings, we introduce GenderCARE, a comprehensive framework that encompasses innovative Criteria, bias Assessment, Reduction techniques, and Evaluation metrics for quantifying and mitigating gender bias in LLMs. To begin, we establish pioneering criteria for gender equality benchmarks, spanning dimensions such as inclusivity, diversity, explainability, objectivity, robustness, and realisticity. Guided by these criteria, we construct GenderPair, a novel pair-based benchmark designed to assess gender bias in LLMs comprehensively. Our benchmark provides standardized and realistic evaluations, including previously overlooked gender groups such as transgender and non-binary individuals. Furthermore, we develop effective debiasing techniques that incorporate counterfactual data augmentation and specialized fine-tuning strategies to reduce gender bias in LLMs without compromising their overall performance. Extensive experiments demonstrate a significant reduction in various gender bias benchmarks, with reductions peaking at over 90% and averaging above 35% across 17 different LLMs. Importantly, these reductions come with minimal variability in mainstream language tasks, remaining below 2%. By offering a realistic assessment and tailored reduction of gender biases, we hope that our GenderCARE can represent a significant step towards achieving fairness and equity in LLMs. More details are available at https://github.com/kstanghere/GenderCARE-ccs24.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670284",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "DPad-HE: Towards Hardware-friendly Homomorphic Evaluation using 4-Directional Manipulation",
        "authors": "Tang, Wenxu; Zheng, Fangyu; Fan, Guang; Zhou, Tian; Lin, Jingqiang; Jing, Jiwu",
        "keywords": "Homomorphic Encryption (同态加密) - 支持密文计算\nModule Learning with Errors (模学习误差) - 硬件友好加密\nGadget Decomposition Manipulation (辅助分解操作) - 优化密钥转换\n选定的主题标签名称",
        "abstract": "Module Learning with Errors (MLWE) based approaches for Fully Homomorphic Encryption (FHE) have garnered attention due to their potential to enhance hardware-friendliness and implementation efficiency. However, despite these advantages, their overall performance still trails behind traditional schemes based on Ring Learning with Errors (RLWE). This indicates that while MLWE-based constructions hold promise, there remain significant challenges to overcome in bridging the performance gap with RLWE-based FHE schemes.By uncovering the reasons for the unsatisfactory performance of prior schemes and pinpointing the fundamental differences in the design of MLWE-based FHE compared to traditional approaches, the paper introduces DPad-HE with a novel design incorporating manipulation in the module rank dimension. The newly introduced operations, rank-up, and rank-down, effectively regulate the scale of gadget decomposition, reducing the computational workload of key-switching by several times. Taking CKKS as a case study, the evaluation showcases the comprehensive advantages of DPad-HE over the state-of-the-art MLWE-based scheme, resulting in a performance boost of 1.26x to 5.71x, a reduction in key size from 1/3 to 3/4, with enhanced noise control. To test the hardware-friendliness of the solution, DPad-HE is also implemented on GPU. Notably, DPad-HE demonstrates that, for the first time, the execution latency of MLWE-based schemes can achieve comparable performance with traditional RLWE ones, especially on the GPU platform where a speedup up to 1.41x is witnessed. Additionally, this paper provides a lightweight conversion method between RLWE and MLWE ciphertexts, allowing for flexible selection of RLWE and MLWE settings during a single complete evaluation process. This opens up new possibilities for both RLWE-based and MLWE-based FHEs.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690280",
        "pub_year": "2024",
        "theme_label": "6.3 同态加密"
    },
    {
        "title": "ERACAN: Defending Against an Emerging CAN Threat Model",
        "authors": "Tang, Zhaozhou; Serag, Khaled; Zonouz, Saman; Celik, Z. Berkay; Xu, Dongyan; Beyah, Raheem",
        "keywords": "Controller Area Network (控制器局域网) - 车载通信协议安全\nThreat Model (威胁模型) - 安全防护设计依据\nAttack Detection and Defense (攻击检测与防御) - 实时安全防护机制",
        "abstract": "The Controller Area Network (CAN) is a pivotal communication protocol extensively utilized in vehicles, aircraft, factories, and diverse cyber-physical systems (CPSs). The extensive CAN security literature resulting from decades of wide usage may create an impression of thorough scrutiny. However, a closer look reveals its reliance on a specific threat model with a limited range of abilities. Notably, recent works show that this model is outdated and that a more potent and versatile model could soon become the norm, prompting the need for a new defense paradigm. Unfortunately, the security impact of this emerging model on CAN systems has not received sufficient attention, and the defense systems addressing it are almost nonexistent. In this paper, we introduce ERACAN, the first comprehensive defense system against this new threat model. We first begin with a threat analysis to ensure that ERACAN comprehensively understands this model's capabilities, evasion tactics, and propensity to enable new attacks or enhance existing ones. ERACAN offers versatile protection against this spectrum of threats, providing attack detection, classification, and optional prevention abilities. We implement and evaluate ERACAN on a testbed and a real vehicle's CAN bus to demonstrate its low latency, real-time operation, and protective capabilities. ERACAN achieves detection rates of 100% and 99.7%+ for all attacks launched by the conventional and the enhanced threat models, respectively.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690267",
        "pub_year": "2024",
        "theme_label": "网络与系统安全"
    },
    {
        "title": "Atomic and Fair Data Exchange via Blockchain",
        "authors": "Tas, Ertem Nusret; Seres, Istvan Andras; Zhang, Yinuo; Melczer, Mark; Kelkar, Mahimna; Bonneau, Joseph; Nikolaenko, Valeria",
        "keywords": "Fair Data Exchange (公平数据交换) - 数据与支付原子性互换\nVerifiable Encryption (可验证加密) - 加密数据正确性可验证\nBlockchain Protocol (区块链协议) - 链上原子性执行机制\n选定的主题标签名称",
        "abstract": "We introduce a blockchain Fair Data Exchange (FDE) protocol, enabling a storage server to transfer a data file to a client atomically: the client receives the file if and only if the server receives an agreed-upon payment. We put forth a new definition for a cryptographic scheme that we name verifiable encryption under committed key (VECK), and we propose two instantiations for this scheme. Our protocol relies on a blockchain to enforce the atomicity of the exchange and uses VECK to ensure that the client receives the correct data (matching an agreed-upon commitment) before releasing the payment for the decrypting key. Our protocol is trust-minimized and requires only constant-sized on-chain communication, concretely 3 signatures, 1 verification key, and 1 secret key, with most of the data stored and communicated off-chain. It also supports exchanging only a subset of the data, can amortize the server's work across multiple clients, and offers a general framework to design alternative FDE protocols using different commitment schemes. A prominent application of our protocol is the Danksharding data availability scheme on Ethereum, which commits to data via KZG polynomial commitments. We also provide an open-source implementation for our protocol with both instantiations for VECK, demonstrating our protocol's efficiency and practicality on Ethereum.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690248",
        "pub_year": "2024",
        "theme_label": "8.2 智能合约及安全"
    },
    {
        "title": "Poster: Security of Login Interfaces in Modern Organizations",
        "authors": "Tchokodeu, Kevin Nsieyanji; Schulmann, Haya; Sobol, Gil; Waidner, Michael",
        "keywords": "Login Interface Security (登录界面安全) - 研究登录页面的安全性问题\nVulnerability Analysis (漏洞分析) - 分析系统中的安全隐患与缺陷\nAccess Control Implementation (访问控制实现) - 控制用户对资源的访问权限\n选定的主题标签名称",
        "abstract": "Login pages, including those for processes like sign-up, registration, and password recovery are interfaces that implement access control to company services or functionalities. Insufficient security on these pages could allow malicious individuals to gain access to services and network of an organization and launch attacks. In this work, we perform a comprehensive study of the security of 73.4k login interfaces of the 100-top European companies from the Fortune report, which we call EU100. We find over 9 million vulnerabilities, which we analyze from a technical perspective, and categorize them according to the hosting model. Our work provides details on the most commonly observed vulnerabilities on login pages across different sectors and according to the hosting strategy adopted by each company.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691413",
        "pub_year": "2024",
        "theme_label": "5.6 身份认证与管理"
    },
    {
        "title": "Data Poisoning Attacks to Locally Differentially Private Frequent Itemset Mining Protocols",
        "authors": "Tong, Wei; Chen, Haoyu; Niu, Jiacheng; Zhong, Sheng",
        "keywords": "Data Poisoning Attack (数据投毒攻击) - 恶意操纵训练数据以破坏模型\nLocal Differential Privacy (本地差分隐私) - 保护用户隐私的统计学习机制\nFrequent Itemset Mining (频繁项集挖掘) - 数据分析中的常见模式发现方法\n选定的主题标签名称",
        "abstract": "Local differential privacy (LDP) provides a way for an untrusted data collector to aggregate users' data without violating their privacy. Various privacy-preserving data analysis tasks have been studied under the protection of LDP, such as frequency estimation, frequent itemset mining, and machine learning. Despite its privacy-preserving properties, recent research has demonstrated the vulnerability of certain LDP protocols to data poisoning attacks. However, existing data poisoning attacks are focused on basic statistics under LDP, such as frequency estimation and mean/variance estimation. As an important data analysis task, the security of LDP frequent itemset mining has yet to be thoroughly examined. In this paper, we aim to address this issue by presenting novel and practical data poisoning attacks against LDP frequent itemset mining protocols. By introducing a unified attack framework with composable attack operations, our data poisoning attack can successfully manipulate the state-of-the-art LDP frequent itemset mining protocols and has the potential to be adapted to other protocols with similar structures. We conduct extensive experiments on three datasets to compare the proposed attack with four baseline attacks. The results demonstrate the severity of the threat and the effectiveness of the proposed attack.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670298",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Distributed PIR: Scaling Private Messaging via the Users' Machines",
        "authors": "Tovey, Elkana; Weiss, Jonathan; Gilad, Yossi",
        "keywords": "Distributed PIR (分布式私有信息检索) - 基于客户端协作的隐私查询\nMetadata privacy (元数据隐私) - 保护通信行为不被窥探\nScalable messaging system (可扩展消息系统) - 提升私密通信性能与规模",
        "abstract": "This paper presents a new architecture for metadata-private messaging that counters scalability challenges by offloading most computations to the clients. At the core of our design is a distributed private information retrieval (PIR) protocol, where the responder delegates its work to alleviate PIR's computational bottleneck and catches misbehaving delegates by efficiently verifying their results. We introduce DPIR, a messaging system that uses distributed PIR to let a server storing messages delegate the work to the system's clients, such that each client contributes proportional processing to the number of messages it reads. The server removes clients returning invalid results, which DPIR leverages to integrate an incentive mechanism for honest client behavior by conditioning messaging through DPIR on correctly processing PIR requests from other users. The result is a metadata-private messaging system that asymptotically improves scalability over prior work with the same threat model. We show through experiments on a prototype implementation that DPIR concretely improves performance by 3.25x and 4.31x over prior work [1, 3] and that the performance gap grows with the user base size.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670350",
        "pub_year": "2024",
        "theme_label": "密码学及应用"
    },
    {
        "title": "Staving off the IoT Armageddon",
        "authors": "Tsudik, Gene",
        "keywords": "Internet of Things (物联网) - 设备互联与安全挑战\nSecurity Framework (安全框架) - 构建系统防护体系\nThreat Mitigation (威胁缓解) - 降低潜在攻击影响",
        "abstract": "nan",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690379",
        "pub_year": "2024",
        "theme_label": "物联网及安全"
    },
    {
        "title": "Crystalor: Recoverable Memory Encryption Mechanism with Optimized Metadata Structure",
        "authors": "Ueno, Rei; Haneda, Hiromichi; Homma, Naofumi; Inoue, Akiko; Minematsu, Kazuhiko",
        "keywords": "Recoverable Memory Encryption (可恢复内存加密) - 支持崩溃后数据恢复\nMetadata Optimization (元数据优化) - 减少存储开销提升性能\nProvable Security (可证安全) - 形式化验证确保机制安全\n选定的主题标签名称",
        "abstract": "This study presents an efficient recoverable memory encryption mechanism, named Crystalor. Existing memory encryption mechanisms, such as Intel SGX integrity tree, offer neither crash consistency nor recoverability, which results in attack surfaces and causes a non-trivial limitation of practical availability. Although the crash consistency of encrypted memory has been studied in the research field of microarchitecture, existing mechanisms lack formal security analysis and cannot incorporate with metadata optimization mechanisms, which are essential to achieve a practical performance. Crystalor efficiently realizes provably-secure recoverable memory encryption with metadata optimization. To establish Crystalor with provable security and practical performance, we develop a dedicated universal hash function PXOR-Hash and a microarchitecture equipped with PXOR-Hash. Crystalor incurs almost no latency overhead under the nominal operations for the recoverability, while it has a simple construction in such a way as to be compatible with existing microarchitectures. We evaluate its practical performance through both algorithmic analyses and system-level simulation in comparison with the state-of-the-art ones, such as SCUE. Crystalor requires 29-62% fewer clock cycles per memory read/write operation than SCUE for protecting a 4 TB memory. In addition, Crystalor and SCUE require 312 GB and 554 GB memory overheads for metadata, respectively, which indicates that Crystalor achieves a memory overhead reduction of 44%. The results of the system-level simulation using the gem5 simulator indicate that Crystalor achieves a reduction of up to 11.5% in the workload execution time compared to SCUE. Moreover, Crystalor achieves a higher availability and memory recovery several thousand times faster than SCUE, as Crystalor offers lazy recovery.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670273",
        "pub_year": "2024",
        "theme_label": "2.4 密码工程技术"
    },
    {
        "title": "Crossing Shifted Moats: Replacing Old Bridges with New Tunnels to Confidential Containers",
        "authors": "Valdez, Enriquillo; Ahmed, Salman; Gu, Zhongshu; de Dinechin, Christophe; Cheng, Pau-Chen; Jamjoom, Hani",
        "keywords": "Confidential Containers (机密容器) - 保护云原生工作负载\nControl Interface Security (控制接口安全) - 防范主机侧攻击风险\nTrust Boundary Realignment (信任边界重构) - 调整安全模型对齐\n选定的主题标签名称",
        "abstract": "The Confidential Containers (CoCo) project, as an open-source community initiative, inherits the system architecture of Kata Containers while integrating confidential computing to protect cloud-native container workloads. However, there exists a misalignment in the threat model and trusted computing base (TCB) between Kata Containers and confidential computing. The shifted trust boundaries could potentially expose a range of vulnerabilities, particularly in scenarios where a malicious actor on the host gains access to the CoCo's unprotected control interface. This paper conducts a thorough examination of CoCo's system architecture, exploring the attack surface resulting from the discord in trust boundaries. We have assessed all API endpoints of CoCo's control interface, categorizing them based on their security properties. Drawing from these insights, we have developed a bifurcation approach to splitting CoCo's control interface. This involves establishing an owner-side controller and minimizing the capabilities of the existing host-side controller. Under this framework, the host-side controller is exclusively responsible for allocating and recycling compute resources, while dedicated workload owners can directly manage their containers through alternative secure tunnels. This approach ensures seamless integration with cloud-native orchestration layers and aligns CoCo with the threat model of confidential computing. By doing so, it effectively prevents untrusted hosts from accessing confidential data and interfering with the execution of workloads within protected domains.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670352",
        "pub_year": "2024",
        "theme_label": "3.5 可信计算与虚拟化安全"
    },
    {
        "title": "Poster: Formalizing Cognitive Biases for Cybersecurity Defenses",
        "authors": "Vang, Jasmine; Revelle, Matthew",
        "keywords": "Cognitive Biases (认知偏差) - 利用心理倾向影响决策\nFirst-Order Logic (一阶逻辑) - 形式化表达关系与规则\nCybersecurity Defenses (网络安全防御) - 构建对抗攻击的策略",
        "abstract": "As network attacks are becoming increasingly sophisticated, there is a need to develop new defense techniques. Recent work has demonstrated the successful use of cognitive biases to obstruct progress in network attacks by constructing scenarios which exploit biases in attackers. While informal definitions of many cognitive biases are well-established, the lack of definitions in a formal language limits the ability to construct scenarios in an automated fashion. This work proposes formal definitions using first-order logic to encapsulate the complex relationships between actions and biases.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691403",
        "pub_year": "2024",
        "theme_label": "1.6 人的安全行为与管理"
    },
    {
        "title": "Functional Adaptor Signatures: Beyond All-or-Nothing Blockchain-based Payments",
        "authors": "Vanjani, Nikhil; Soni, Pratik; Thyagarajan, Sri AravindaKrishnan",
        "keywords": "Functional Adaptor Signatures (功能性适配器签名) - 新型密码学原语\nFunctional Encryption (功能性加密) - 支持函数计算的加密技术\nBlockchain-based Fair Exchange (基于区块链的公平交换) - 利用区块链实现安全交易\n选定的主题标签名称",
        "abstract": "In scenarios where a seller holds sensitive data.., like employee / patient records or ecological data, and a buyer seeks to obtain an evaluation of specific function f on this data, solutions in trustless digital environments like blockchain-based Web3 systems typically fall into two categories: (1) Smart contract-powered solutions and (2) cryptographic solutions leveraging tools such as adaptor signatures. The former approach offers atomic transactions where the buyer learns the function evaluation f(x) (and not x entirely) upon payment. However, this approach is often inefficient, costly, lacks privacy for the seller's data, and is incompatible with systems that do not support smart contracts with required functionalities. In contrast, the adaptor signature-based approach addresses all of the above issues but comes with an all-or-nothing guarantee, where the buyer fully extracts x and does not support functional extraction of the sensitive data. In this work, we aim to bridge the gap between these approaches, developing a solution that enables fair functional sales of information while offering improved efficiency, privacy, and compatibility similar to adaptor signatures.Towards this, we propose functional adaptor signatures (FAS) a novel cryptographic primitive that achieves all the desired properties as listed above. Using FAS, the seller can publish an advertisement committing to x. The buyer can pre-sign the payment transaction w.r.t. a function f, and send it along with the transaction to the seller. The seller adapts the pre-signature into a valid (buyer's) signature and posts the payment and the adapted signature on the blockchain to get paid. Finally, using the pre-signature and the posted signature, the buyer efficiently extracts f(x), and completes the sale. We formalize the security properties of FAS, among which is a new notion called witness privacy to capture seller's privacy, which ensures the buyer does not learn anything beyond f(x). We present multiple variants of witness privacy, namely, witness hiding, witness indistinguishability, and zero-knowledge, to capture varying levels of leakage about x beyond f(x) to a malicious buyer.We introduce two efficient constructions of FAS supporting linear functions (like statistics/aggregates, kernels in machine learning, etc.), that satisfy the strongest notion of witness privacy. One construction is based on prime-order groups and compatible with Schnorr signatures for payments, and the other is based on lattices and compatible with a variant of Lyubashevsky's signature scheme. A central conceptual contribution of our work lies in revealing a surprising connection between functional encryption, a well-explored concept over the past decade, and adaptor signatures, a relatively new primitive in the cryptographic landscape. On a technical level, we avoid heavy cryptographic machinery and achieve improved efficiency, by making black-box use of building blocks like inner product functional encryption (IPFE) while relying on certain security-enhancing techniques for the IPFE in a non-black-box manner. We implement our FAS construction for Schnorr signatures and show that for reasonably sized seller witnesses, the different operations are quite efficient even for commodity hardware.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690240",
        "pub_year": "2024",
        "theme_label": "密码学及应用"
    },
    {
        "title": "Verifiably Correct Lifting of Position-Independent x86-64 Binaries to Symbolized Assembly",
        "authors": "Verbeek, Freek; Naus, Nico; Ravindran, Binoy",
        "keywords": "Binary Lifting (二进制提升) - 将机器码还原为高级表示\nSymbolic Assembly (符号化汇编) - 保留语义的可重编译代码\nFormal Verification (形式化验证) - 用逻辑证明确保转换正确",
        "abstract": "We present an approach to lift position-independent x86-64 binaries to symbolized NASM. Symbolization is a decompilation step that enables binary patching: functions can be modified, and instructions can be interspersed. Moreover, it is the first abstraction step in a larger decompilation chain. The produced NASM is recompilable, and we extensively test the recompiled binaries to see if they exhibit the same behavior as the original ones. In addition to testing, the produced NASM is accompanied with a certificate, constructed in such a way that if all theorems in the certificate hold, symbolization has occurred correctly. The original and recompiled binary are lifted again with a third-party decompiler (Ghidra). These representations, as well as the certificate, are loaded into the Isabelle/HOL theorem prover, where proof scripts ensure that correctness can be proven automatically. We have applied symbolization to various stripped binaries from various sources, from various compilers, and ranging over various optimization levels. We show how symbolization enables binary-level patching, by tackling challenges originating from industry.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690244",
        "pub_year": "2024",
        "theme_label": "系统软件安全"
    },
    {
        "title": "Data Independent Order Policy Enforcement: Limitations and Solutions",
        "authors": "Wadhwa, Sarisht; Zanolini, Luca; Asgaonkar, Aditya; D'Amato, Francesco; Fang, Chengrui; Zhang, Fan; Nayak, Kartik",
        "keywords": "Order Policy Enforcement (顺序策略执行) - 保障交易排序公平性\nRational Collusion (理性共谋) - 参与者利益驱动的合谋行为\nAutomated Market Makers (自动化做市商) - 去中心化交易的核心机制",
        "abstract": "Order manipulation attacks such as frontrunning and sandwiching have become an increasing concern in blockchain applications such as DeFi. To protect from such attacks, several recent works have designed order policy enforcement (OPE) protocols to order transactions fairly in a data-independent fashion. However, while the manipulation attacks are motivated by monetary profits, the defenses assume honesty among a significantly large set of participants. In existing protocols, if all participants are rational, they may be incentivized to collude and circumvent the order policy without incurring any penalty.This work makes two key contributions. First, we explore whether the need for the honesty assumption is fundamental. Indeed, we show that it is impossible to design OPE protocols under some requirements when all parties are rational. Second, we explore the tradeoffs needed to circumvent the impossibility result. In the process, we propose a novel concept of rationally binding transactions that allows us to construct AnimaguSwap(1), the first contentoblivious Automated Market Makers (AMM) interface that is secure under rationality. We report on a prototype implementation of Animagu-Swap and performance evaluation results demonstrating its practicality.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670367",
        "pub_year": "2024",
        "theme_label": "8.2 智能合约及安全"
    },
    {
        "title": "ProphetFuzz: Fully Automated Prediction and Fuzzing of High-Risk Option Combinations with Only Documentation via Large Language Model",
        "authors": "Wang, Dawei; Zhou, Geng; Chen, Li; Li, Dan; Miao, Yukai",
        "keywords": "Fuzz Testing (模糊测试) - 自动化漏洞挖掘技术\nLarge Language Model (大语言模型) - 驱动预测高风险选项\nOption Combination Vulnerability (选项组合漏洞) - 软件安全测试难点\n选定的主题标签名称",
        "abstract": "Vulnerabilities related to option combinations pose a significant challenge in software security testing due to their vast search space. Previous research primarily addressed this challenge through mutation or filtering techniques, which inefficiently treated all option combinations as having equal potential for vulnerabilities, thus wasting considerable time on non-vulnerable targets and resulting in low testing efficiency. In this paper, we utilize carefully designed prompt engineering to drive the large language model (LLM) to predict high-risk option combinations (i.e., more likely to contain vulnerabilities) and perform fuzz testing automatically without human intervention. We developed a tool called ProphetFuzz and evaluated it on a dataset comprising 52 programs collected from three related studies. The entire experiment consumed 10.44 CPU years. ProphetFuzz successfully predicted 1748 high-risk option combinations at an average cost of only $8.69 per program. Results show that after 72 hours of fuzzing, ProphetFuzz discovered 364 unique vulnerabilities associated with 12.30% of the predicted high-risk option combinations, which was 32.85% higher than that found by state-of-the-art in the same timeframe. Additionally, using ProphetFuzz, we conducted persistent fuzzing on the latest versions of these programs, uncovering 140 vulnerabilities, with 93 confirmed by developers and 21 awarded CVE numbers.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690231",
        "pub_year": "2024",
        "theme_label": "3.8.1 漏洞挖掘与逆向分析"
    },
    {
        "title": "CiMSAT: Exploiting SAT Analysis to Attack Compute-in-Memory Architecture Defenses",
        "authors": "Wang, Jianfeng; Yang, Huazhong; Deng, Shuwen; Li, Xueqing",
        "keywords": "Compute-in-Memory (存算一体) - 一种融合存储与计算的高效架构\nHardware Obfuscation (硬件混淆) - 利用电路设计隐藏关键信息\nSAT-based Attack (基于SAT的攻击) - 利用布尔可满足性进行逆向解析",
        "abstract": "Compute-in-memory (CiM) architecture is an emerging energy-efficient processing paradigm that has attracted widespread attention in AI and Internet of Things (IoT) applications. To protect statically stored sensitive data in CiM, designers have implemented various hardware obfuscation techniques in CiM architectures. However, we observe that existing CiM obfuscation defense strategies are based on straightforward static-key deployment strategies, which pose vulnerabilities from the perspective of key-pruning algorithms for de-obfuscation.This work proposes CiMSAT, a CiM de-obfuscation methodology based on Boolean satisfiability (SAT) theory. We conduct the first security analysis specifically tailored to the storage and mixed-signal computing features of CiM architecture, which are two key challenges to de-obfuscate existing state-of-the-art CiM defenses. To model storage units, we innovatively fit and utilize the no-inference-value obfuscated data for function approximation. To reconstruct mixed-signal circuits, we design bias-tolerant SAT to address the biases introduced by the approximation. With the proposed workflow, we investigate and evaluate all the existing 14 CiM obfuscation architectures using our de-obfuscation framework. We model a total of 176 defense vectors derived from different defense techniques and parameters, among which 158 (90%) can be de-obfuscated and returned the keys within 1,000 seconds and 172 (98%) defenses can be recovered within 105 seconds (approximately one day). We further reload the keys into CiM simulators with obfuscation, achieving an average of 97% and 95% accuracy recovery in widely adopted MNIST and CIFAR-10 classification applications in CiM obfuscation, respectively.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690251",
        "pub_year": "2024",
        "theme_label": "硬件安全"
    },
    {
        "title": "OSMART: Whitebox Program Option Fuzzing",
        "authors": "Wang, Kelin; Chen, Mengda; He, Liang; Su, Purui; Cai, Yan; Chen, Jiongyi; Zhang, Bin; Feng, Chao; Tang, Chaojing",
        "keywords": "Option Fuzzing (选项模糊测试) - 系统化测试程序配置组合\nWhitebox Analysis (白盒分析) - 基于程序逻辑的测试方法\nControl and Data Dependency (控制与数据依赖) - 捕捉程序执行逻辑关系",
        "abstract": "Program options are ubiquitous and serve as a fundamental mechanism for configuring and customizing software behaviors. Given their widespread use, testing program options becomes essential to ensure that the software behaves as expected across various configurations. Existing option-aware fuzzers either mutate options as if they were standard program inputs or employ NLP techniques to deduce relationships among options from the documentation. However, there has not been a whitebox approach that generates option combinations by capturing the inherent execution logic of the program.This paper presents OSmart, a whitebox approach designed to systematically extract program options and effective option combinations that precisely encapsulate the intrinsic execution logic of the program, incorporating both data dependency and control dependency. OSMART successfully inferred 12,560 option combinations from 56 programs. Additionally, OSMART uncovered that more than 67% of evaluated programs have undocumented options. By integrated with AFL++, OSMART discovered 40.3% more paths, which led to the detection of 51 new bugs and the assignment of 18 CVE IDs. Finally, we also compared OSMART with four state-of-the-art option-aware fuzzers on a public benchmark and our tool achieved higher line coverage in 66.7% (20/30) of the evaluated programs.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690228",
        "pub_year": "2024",
        "theme_label": "3.8.1 漏洞挖掘与逆向分析"
    },
    {
        "title": "Moderator: Moderating Text-to-Image Diffusion Models through Fine-grained Context-based Policies",
        "authors": "Wang, Peiran; Li, Qiyu; Yu, Longxuan; Wang, Ziyao; Li, Ang; Jin, Haojian",
        "keywords": "Policy-based Moderation (基于策略的内容管控) - 基于规则的图像生成限制\nContext-aware Model Editing (上下文感知模型编辑) - 考虑语境的模型修改\nText-to-Image Diffusion Models (文本到图像扩散模型) - 根据文本生成图像的AI模型",
        "abstract": "We present Moderator, a policy-based model management system that allows administrators to specify fine-grained content moderation policies and modify the weights of a text-to-image (TTI) model to make it significantly more challenging for users to produce images that violate the policies. In contrast to existing general-purpose model editing techniques, which unlearn concepts without considering the associated contexts, Moderator allows admins to specify what content should be moderated, under which context, how it should be moderated, and why moderation is necessary. Given a set of policies, Moderator first prompts the original model to generate images that need to be moderated, then uses these self-generated images to reverse fine-tune the model to compute task vectors for moderation and finally negates the original model with the task vectors to decrease its performance in generating moderated content. We evaluated Moderator with 14 participants to play the role of admins and found they could quickly learn and author policies to pass unit tests in approximately 2.29 policy iterations. Our experiment with 32 stable diffusion users suggested that Moderator can prevent 65% of users from generating moderated content under 15 attempts and require the remaining users an average of 8.3 times more attempts to generate undesired content.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690327",
        "pub_year": "2024",
        "theme_label": "信息内容安全"
    },
    {
        "title": "RefleXnoop: Passwords Snooping on NLoS Laptops Leveraging Screen-Induced Sound Reflection",
        "authors": "Wang, Penghao; Hu, Jingzhi; Liu, Chao; Luo, Jun",
        "keywords": "Non-line-of-sight Attack (非视线攻击) - 利用间接路径实施安全威胁\nAcoustic Emanation Analysis (声学泄露分析) - 通过声音推断输入信息\nNeural Fusion Model (神经融合模型) - 多源数据融合与特征解析",
        "abstract": "Password inference attacks by covert wireless side-channels jeopardize information safety, even for people with high security awareness and vigilance against snoopers. Yet, with limited spatial resolution, existing attacks cannot accurately infer password input on QWERTY keyboards in distance, creating psychological safety in using laptops publicly. To refute this false belief, we propose RefleXnoop, enabling an attacker to snoop a victim's typing details on a non-line-of-sight (NLoS) laptop. Apart from passively overhearing keystroke acoustic emanations, RefleXnoop actively probes with ultrasound, whose larger bandwidth and lower noise floor offers a finer resolution. To further maximize its performance, RefleXnoop exploits the laptop's screen reflection to enhance diversity in sound acquisition, and it innovates in neural models to effectively fuse the diversified sound acquisitions and to achieve robust feature-to-key translation. We implement RefleXnoop with commodity hardware and conduct extensive evaluation on it; the results demonstrate that RefleXnoop achieves 85% top-100 accuracy for inferring 8-character passwords on laptop QWERTY-keyboard and in multiple noisy environments.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670341",
        "pub_year": "2024",
        "theme_label": "信息泄漏分析"
    },
    {
        "title": "SeMalloc: Semantics-Informed Memory Allocator",
        "authors": "Wang, Ruizhe; Xu, Meng; Asokan, N.",
        "keywords": "SemaType (语义类型) - 捕获堆对象语义信息的类型系统\nMemory Allocation Security (内存分配安全) - 提升内存分配安全性以防御漏洞\nUse-after-free Mitigation (悬垂指针缓解) - 防止悬垂指针漏洞被利用",
        "abstract": "Use-after-free (UAF) is a critical and prevalent problem in memory unsafe languages. While many solutions have been proposed, balancing security, run-time cost, and memory overhead (an impossible trinity) is hard.In this paper, we show one way to balance the trinity by passing more semantics about the heap object to the allocator for it to make informed allocation decisions. More specifically, we propose a new notion of thread-, context-, and flow-sensitive type, SemaType, to capture the semantics and prototype a SemaType-based allocator that aims for the best trade-off amongst the impossible trinity. In SeMalloc, only heap objects allocated from the same call site and via the same function call stack can possibly share a virtual memory address, which effectively stops type-confusion attacks and makes UAF vulnerabilities harder to exploit.Through extensive empirical evaluation, we showthat SeMalloc is realistic: (a) SeMalloc is effective in thwarting all real-world vulnerabilities we tested; (b) benchmark programs run even slightly faster with SeMalloc than the default heap allocator, at a memory overhead averaged from 41% to 84%; and (c) SeMalloc balances security and overhead strictly better than other closely related works.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670363",
        "pub_year": "2024",
        "theme_label": "系统软件安全"
    },
    {
        "title": "CANCAL: Towards Real-time and Lightweight Ransomware Detection and Response in Industrial Environments",
        "authors": "Wang, Shenao; Dong, Feng; Yang, Hangfeng; Xu, Jingheng; Wang, Haoyu",
        "keywords": "Ransomware Detection (勒索软件检测) - 实时识别恶意加密行为\nLightweight System (轻量级系统) - 降低资源消耗与高效处理\nIndustrial Security (工业环境安全) - 保障关键基础设施防护",
        "abstract": "Ransomware attacks have emerged as one of the most significant cybersecurity threats. Despite numerous methods proposed for detecting and defending against ransomware, existing approaches face two fundamental limitations in large-scale industrial applications: (1) Behavior-based detection engines suffer from the enormous overhead of monitoring all processes and resource constraints for model inference, failing to meet the requirements for real-time detection; (2) Decoy-based detection engines generate an overwhelming number of false positives in large-scale industrial clusters, leading to intolerable disruptions to critical processes and excessive inspection efforts from security analysts. To address these challenges, we propose CANCAL, a real-time and lightweight ransomware detection system. Specifically, instead of indiscriminately analyzing all processes, CANCAL selectively filters suspicious processes by the monitoring layers and then performs in-depth behavioral analysis to isolate ransomware activities from benign operations, minimizing alert fatigue while ensuring lightweight computational and storage overhead. The experimental results on a large-scale industrial environment (1,761 ransomware, similar to 3 million events, continuous test over 5 months) indicate that CANCAL achieves a remarkable 99.65% true positive rate on 555,678 unknown ransomware behavior events, with near-zero false positives. CANCAL is as effective as state-of-the-art techniques while enabling rapid inference within 30ms and real-time response within a maximum of 3 seconds. CANCAL dramatically reduces average CPU utilization by 91.04% (from 6.7% to 0.6%) and peak CPU utilization by 76.69% (from 26.6% to 6.2%), while avoiding 76.50% (from 3,192 to 750) of the inspection efforts from security analysts. By the time of this writing, CANCAL has been integrated into a commercial product and successfully deployed on 3.32 million endpoints for over a year. From March 2023 to April 2024, CANCAL successfully detected and thwarted 61 ransomware attacks. A detailed manual forensic analysis of 27 ransomware attacks from March to June 2023 (including 13 n-day exploits and 5 high-risk zero-day attacks) demonstrates the effectiveness of CANCAL in combating sophisticated and unknown ransomware threats in real-world scenarios.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690269",
        "pub_year": "2024",
        "theme_label": "恶意代码分析与防护"
    },
    {
        "title": "Curator Attack: When Blackbox Differential Privacy Auditing Loses Its Power",
        "authors": "Wang, Shiming; Xiang, Liyao; Cheng, Bowei; Ji, Zhe; Sun, Tianran; Wang, Xinbing",
        "keywords": "Differential Privacy (差分隐私) - 隐私保护数据分析方法\nBlackbox Auditing (黑盒审计) - 不依赖内部知识的隐私检测\nPrivacy Auditing Tools (隐私审计工具) - 评估隐私保护水平的工具\n选定的主题标签名称",
        "abstract": "A surge in data-driven applications enhances everyday life but also raises serious concerns about private information leakage. Hence many privacy auditing tools are emerging for checking if the data sanitization performed meets the privacy standard of the data owner. Blackbox auditing for differential privacy is particularly gaining popularity for its effectiveness and applicability to a wide range of scenarios. Yet, we identified that blackbox auditing is essentially flawed with its setting - small probabilities/densities are ignored due to inaccurate observation. Our argument is based on a solid false positive analysis from a hypothesis testing perspective, which is missed out by prior blackbox auditing tools. This oversight greatly reduces the reliability of these tools, as it allows malicious or incapable data curators to pass the auditing with an overstated privacy guarantee, posing significant risks to data owners. We demonstrate the practical existence of such threats in classical differential privacy mechanisms against four representative blackbox auditors with experimental validations. Our findings aim to reveal the limitations of blackbox auditing tools, empower the data owner with the awareness of risks in using these tools, and encourage the development of more reliable differential privacy auditing methods.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690367",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "Dye4AI: Assuring Data Boundary on Generative AI Services",
        "authors": "Wang, Shu; Sun, Kun; Zhai, Yan",
        "keywords": "Data Boundary Assurance (数据边界保障) - 确保用户数据不被滥用\nGenerative AI Security (生成式人工智能安全) - 保障AI服务的数据安全\nDye Testing System (染色测试系统) - 检测数据流动与模型演化\n选定的主题标签名称",
        "abstract": "Generative artificial intelligence (AI) is versatile for various applications, but security and privacy concerns with third-party AI vendors hinder its broader adoption in sensitive scenarios. Hence, it is essential for users to validate the AI trustworthiness and ensure the security of data boundaries. In this paper, we present a dye testing system named Dye4AI, which injects crafted trigger data into human-AI dialogue and observes AI responses towards specific prompts to diagnose data flow in AI model evolution. Our dye testing procedure contains 3 stages: trigger generation, trigger insertion, and trigger retrieval. First, to retain both uniqueness and stealthiness, we design a new trigger that transforms a pseudo-random number to a intelligible format. Second, with a custom-designed three-step conversation strategy, we insert each trigger item into dialogue and confirm the model memorizes the new trigger knowledge in the current session. Finally, we routinely try to recover triggers with specific prompts in new sessions, as triggers can present in new sessions only if AI vendors leverage user data for model fine-tuning. Extensive experiments on six LLMs demonstrate our dye testing scheme is effective in ensuring the data boundary, even for models with various architectures and parameter sizes. Also, larger and premier models tend to be more suitable for Dye4AI, e.g., trigger can be retrieved in OpenLLaMa-13B even with only 2 insertions per trigger item. Moreover, we analyze the prompt selection in dye testing, providing insights for future testing systems on generative AI services.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670299",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "The Invisible Polyjuice Potion: An Effective Physical Adversarial Attack Against Face Recognition",
        "authors": "Wang, Ye; Liu, Zeyan; Luo, Bo; Hui, Rongqing; Li, Fengjun",
        "keywords": "Physical Adversarial Attack (物理对抗攻击) - 利用物理扰动欺骗人脸识别系统\nInfrared Laser Perturbation (红外激光扰动) - 通过激光干扰实现隐蔽攻击\nFace Recognition Security (人脸识别安全) - 研究人脸系统漏洞与防御方法\n选定的主题标签名称",
        "abstract": "Face recognition systems have been targeted by recent physical adversarial machine learning attacks, which attach or project visible patterns on adversaries' faces to trick backend FR models. While these attacks have demonstrated effectiveness in the literature, they often rely on visibly suspicious patterns, are susceptible to environmental noise, or exhibit limited success rates in practice. In this paper, we propose a novel physical adversarial attack against deep face recognition systems, namely Agile (adversarial glasses with infrared laser). It generates adjustable, invisible laser perturbations and emits them into the camera CMOS to launch dodging and impersonation attacks against facial biometrics systems. To do so, we first theoretically model physical adversarial perturbations and convert them to the digital domain. The generated synthesized attack signals are utilized to guide real-world laser settings. Our experiments with real-world attackers and a benchmark face database show that Agile is highly effective in DoS, dodging, and impersonation attacks. More importantly, the candidate impersonation target and optimal attack settings identified by Agile's attack synthesis approach are highly consistent with real-world physical attack results. The grey-box and black-box evaluation against commercial FR models also confirms the effectiveness of the Agile attack.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670382",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Payout Races and Congested Channels: A Formal Analysis of Security in the Lightning Network",
        "authors": "Weintraub, Ben; Kumble, Satwik Prabhu; Nita-Rotaru, Cristina; Roos, Stefanie",
        "keywords": "Lightning Network (闪电网络) - 基于比特币的支付通道协议\nFormal Verification (形式化验证) - 用逻辑方法证明系统安全性\nPayment Channel Security (支付通道安全) - 确保链下交易无风险",
        "abstract": "The Lightning Network, a payment channel network with a market cap of over 192M USD, is designed to resolve Bitcoin's scalability issues through fast off-chain transactions. There are multiple Lightning Network client implementations, all of which conform to the same textual specifications known as BOLTs. Several vulnerabilities have been manually discovered, but to-date there have been few works systematically analyzing the security of the Lightning Network.In this work, we take a foundational approach to analyzing the security of the Lightning Network with the help of formal methods. Based on the BOLTs' specifications, we build a detailed formal model of the Lightning Network's single-hop payment protocol and verify it using the Spin model checker. Our model captures both concurrency and error semantics of the payment protocol. We then define several security properties which capture the correct intermediate operation of the protocol, ensuring that the outcome is always certain to both channel peers, and using themwe re-discover a known attack previously reported in the literature along with a novel attack, referred to as a Payout Race. A Payout Race consists of a particular sequence of events that can lead to an ambiguity in the protocol in which innocent users can unwittingly lose funds. We confirm the practicality of this attack by reproducing it in a local testbed environment.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670315",
        "pub_year": "2024",
        "theme_label": "区块链及安全"
    },
    {
        "title": "Exploiting Temporal Vulnerabilities for Unauthorized Access in Intent-Based Networking",
        "authors": "Weintraub, Ben; Kim, Jiwon; Tao, Ran; Nita-Rotaru, Cristina; Okhravi, Hamed; Tian, Dave (Jing); Ujcich, Benjamin E.",
        "keywords": "Intent-Based Networking (基于意图的网络) - 网络策略自动化配置\nTemporal Vulnerabilities (时间性漏洞) - 规则切换期安全风险\nNetwork Security Enforcement (网络安全执行) - 安全策略动态实施\n选定的主题标签名称",
        "abstract": "Intent-based networking (IBN) enables network administrators to express high-level goals and network policies without needing to specify low-level forwarding configurations, topologies, or protocols. Administrators can define intents that capture the overall behavior they want from the network, and an IBN controller compiles such intents into low-level configurations that get installed in the network and implement the desired behavior.We discovered that current IBN specifications and implementations do not specify that flow rule installation orderings should be enforced, which leads to temporal vulnerabilities where, for a limited time, attackers can exploit indeterminate connectivity behavior to gain unauthorized network access.In this paper, we analyze the causes of such temporal vulnerabilities and their security impacts with a representative case study via the ONOS IBN implementation. We devise the Phantom Link attack and demonstrate a working exploit to highlight the security impacts. To defend against such attacks, we propose Spotlight, a detection method that can alert a system administrator of risky intent updates prone to exploitable temporal vulnerabilities. Spotlight is effective in identifying risky updates using realistic network topologies and policies. We show that Spotlight can detect risky updates in a mean time of 0.65 seconds for topologies of over 1,300 nodes.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670301",
        "pub_year": "2024",
        "theme_label": "3.12 网络基础设施安全"
    },
    {
        "title": "Membership Inference Attacks Against In-Context Learning",
        "authors": "Wen, Rui; Li, Zheng; Backes, Michael; Zhang, Yang",
        "keywords": "Membership Inference (成员推断攻击) - 隐私泄露风险分析\nIn-Context Learning (上下文学习) - 基于提示的语言模型适配\nLarge Language Models Privacy (大语言模型隐私) - 模型输出带来的隐私威胁",
        "abstract": "Adapting Large Language Models (LLMs) to specific tasks introduces concerns about computational efficiency, prompting an exploration of efficient methods such as In-Context Learning (ICL). However, the vulnerability of ICL to privacy attacks under realistic assumptions remains largely unexplored. In this work, we present the first membership inference attack tailored for ICL, relying solely on generated texts without their associated probabilities. We propose four attack strategies tailored to various constrained scenarios and conduct extensive experiments on four popular large language models. Empirical results show that our attacks can accurately determine membership status in most cases, e.g., 95% accuracy advantage against LLaMA, indicating that the associated risks are much higher than those shown by existing probability-based attacks. Additionally, we propose a hybrid attack that synthesizes the strengths of the aforementioned strategies, achieving an accuracy advantage of over 95% in most cases. Furthermore, we investigate three potential defenses targeting data, instruction, and output. Results demonstrate combining defenses from orthogonal dimensions significantly reduces privacy leakage and offers enhanced privacy assurances.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690306",
        "pub_year": "2024",
        "theme_label": "人工智能安全"
    },
    {
        "title": "Verifiable Security Policies for Distributed Systems",
        "authors": "Wolf, Felix A.; Muller, Peter",
        "keywords": "Security Policies (安全策略) - 策略规范与验证\nDistributed Systems (分布式系统) - 多节点协同安全\nFormal Verification (形式化验证) - 逻辑证明安全性",
        "abstract": "In the context of secure information flow, security policies express the classification and declassification of data. Existing policy frameworks are tightly linked to a programming language, which limits their flexibility and complicates reasoning, for instance, during audits. We present a framework for the specification and verification of security policies for distributed systems, where attackers may observe the I/O performed by a program, but not its memory. Our policies are expressed over the I/O behaviors of programs and, thereby, language-agnostic. We present techniques to reason formally about policies, and to verify that an implementation satisfies a given policy. We formalize these verification techniques in Isabelle/HOL. An evaluation on several case studies, including an implementation of the WireGuard VPN key exchange protocol, demonstrates that our policies are expressive, and that verification is amenable to SMT-based verification.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690303",
        "pub_year": "2024",
        "theme_label": "1.4 测绘理论、安全治理与策略"
    },
    {
        "title": "Provable Security for PKI Schemes",
        "authors": "Wrotniak, Sara; Leibowitz, Hemi; Syta, Ewa; Herzberg, Amir",
        "keywords": "Provable Security (可证安全) - 密码学中形式化证明安全性\nPKI Schemes (公钥基础设施方案) - 管理数字证书与密钥的框架\nCertificate Transparency (证书透明度) - 提高CA可信度的审计机制\n选定的主题标签名称",
        "abstract": "PKI schemes provide a critical foundation for applied cryptographic protocols. However, there are no rigorous security specifications for realistic PKI schemes, and therefore, no PKI schemes were proven secure. Cryptographic systems that use PKI are analyzed by adopting overly simplified models of PKI, often simply assuming securely-distributed public keys. This is problematic given the extensive reliance on PKI, the multiple failures of PKI systems, and the complexity of both proposed and deployed systems, which involve complex requirements and models.We present game-based security specifications for PKI schemes and analyze important and widely deployed PKIs: PKIX and two variants of Certificate Transparency (CT). These PKIs are based on the X.509v3 standard and its CRL revocation mechanism. Our analysis identified a few subtle vulnerabilities and provides reduction-based proofs showing that the PKIs ensure specific requirements under specific models (assumptions). To our knowledge, this is the first reduction-based proof of security for a realistic PKI scheme, e.g., supporting certificate chains.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670374",
        "pub_year": "2024",
        "theme_label": "2.2.3 可证安全"
    },
    {
        "title": "TokenScout: Early Detection of Ethereum Scam Tokens via Temporal Graph Learning",
        "authors": "Wu, Cong; Chen, Jing; Zhao, Ziming; He, Kun; Xu, Guowen; Wu, Yueming; Wang, Haijun; Li, Hongwei; Liu, Yang; Xiang, Yang",
        "keywords": "Temporal Graph Learning (时序图学习) - 通过时间动态分析图结构数据\nScam Token Detection (诈骗代币检测) - 识别恶意加密货币交易行为\nContrastive Learning (对比学习) - 通过样本对比提升特征区分能力\n选定的主题标签名称",
        "abstract": "Decentralized finance has experienced phenomenal growth, revolutionizing the landscape of financial transactions and asset management via blockchain. Yet, this swift growth brings with it substantial challenges, notably the surge in scam tokens, imposing significant security threats on cryptocurrency investments and trading. Existing detection methods of scam token, primarily relying on analyzing contract codes or transaction patterns, struggle to catch increasingly sophisticated tactics employed by scammers. For example, contract-based analysis are unable to identify scams lacking overt malicious code, e.g., most rugpulls, while transaction-based methods generally lack the foresight to early-detect potential risks. In this paper, we present TokenScout, the first temporal graph neural network-based framework for scam token early detection. TokenScout formulates token transfer data as a dynamic temporal attributed multigraph and leverages the temporal graph learning model to learn graph representations. It also builds a graph representation refining model based on contrastive learning to learn a more discriminative representation space for risk identification. We evaluated TokenScout using a comprehensive dataset of 214,084 standard ERC20 tokens from 2015 to February 2023. TokenScout achieves a balanced accuracy of 98.41%. Additionally, from March to May 2023, deploying TokenScout on Ethereum effectively identified 706 rugpulls, 174 honeypots, and 90 Ponzi schemes, thereby alerting to potential risks exceeding $240 million.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690234",
        "pub_year": "2024",
        "theme_label": "8.2 智能合约及安全"
    },
    {
        "title": "Legilimens: Practical and Unified Content Moderation for Large Language Model Services",
        "authors": "Wu, Jialin; Deng, Jiangyi; Pang, Shengyuan; Chen, Yanjiao; Xu, Jiayang; Li, Xinfeng; Xu, Wenyuan",
        "keywords": "Content Moderation (内容审核) - 审核生成内容的安全合规性\nLarge Language Models (大语言模型) - 用于对话与安全特征提取\nJailbreaking Defense (越狱防御) - 防御对抗性攻击与滥用",
        "abstract": "Given the societal impact of unsafe content generated by large language models (LLMs), ensuring that LLM services comply with safety standards is a crucial concern for LLM service providers. Common content moderation methods are limited by an effectiveness-and-efficiency dilemma, where simple models are fragile while sophisticated models consume excessive computational resources. In this paper, we reveal for the first time that effective and efficient content moderation can be achieved by extracting conceptual features from chat-oriented LLMs, despite their initial fine-tuning for conversation rather than content moderation. We propose a practical and unified content moderation framework for LLM services, named Legilimens, which features both effectiveness and efficiency. Our red-team model-based data augmentation enhances the robustness of Legilimens against state-of-the-art jailbreaking. Additionally, we develop a framework to theoretically analyze the cost-effectiveness of Legilimens compared to other methods.We have conducted extensive experiments on five host LLMs, seventeen datasets, and nine jailbreaking methods to verify the effectiveness, efficiency, and robustness of Legilimens against normal and adaptive adversaries. A comparison of Legilimens with both commercial and academic baselines demonstrates the superior performance of Legilimens. Furthermore, we confirm that Legilimens can be applied to few-shot scenarios and extended to multi-label classification tasks.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690322",
        "pub_year": "2024",
        "theme_label": "信息内容安全"
    },
    {
        "title": "Image-Perfect Imperfections: Safety, Bias, and Authenticity in the Shadow of Text-To-Image Model Evolution",
        "authors": "Wu, Yixin; Shen, Yun; Backes, Michael; Zhang, Yang",
        "keywords": "Text-to-Image Models (文本到图像模型) - 生成图像的AI技术\nSafety in Generative AI (生成式AI安全性) - 防止有害内容生成\nBias and Authenticity (偏见与真实性) - 图像内容公平性与伪造检测",
        "abstract": "Text-to-image models, such as Stable Diffusion (SD), undergo iterative updates to improve image quality and address concerns such as safety. Improvements in image quality are straightforward to assess. However, how model updates resolve existing concerns and whether they raise new questions remain unexplored. This study takes an initial step in investigating the evolution of text-to-image models from the perspectives of safety, bias, and authenticity. Our findings, centered on Stable Diffusion, indicate that model updates paint a mixed picture. While updates progressively reduce the generation of unsafe images, the bias issue, particularly in gender, intensifies. We also find that negative stereotypes either persist within the same Non-White race group or shift towards other Non-White race groups through SD updates, yet with minimal association of these traits with the White race group. Additionally, our evaluation reveals a new concern stemming from SD updates: State-of-the-art fake image detectors, initially trained for earlier SD versions, struggle to identify fake images generated by updated versions. We show that fine-tuning these detectors on fake images generated by updated versions achieves at least 96.6% accuracy across various SD versions, addressing this issue. Our insights highlight the importance of continued efforts to mitigate biases and vulnerabilities in evolving text-to-image models.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690288",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Boosting Practical Control-Flow Integrity with Complete Field Sensitivity and Origin Awareness",
        "authors": "Xiang, Hao; Cheng, Zehui; Li, Jinku; Ma, Jianfeng; Lu, Kangjie",
        "keywords": "Control-Flow Integrity (控制流完整性) - 保障程序执行路径安全\nEquivalence Class Optimization (等价类优化) - 精确分析间接调用目标\nMemory Protection Keys (内存保护键) - 硬件辅助存储安全机制",
        "abstract": "Control-flow integrity (CFI) is a strong and efficient defense mechanism against memory-corruption attacks. The practical versions of CFI, which have been integrated into compilers, employ static analysis to collect all possibly valid target functions of indirect calls. They are however less effective because the static analysis is imprecise. While more precise CFI techniques have been proposed, such as dynamic CFI, they are not yet practical due to issues on performance, compatibility, and deployability. We believe that to be practical, CFI based on static analysis is still the promising direction. However, these years have not seen much progress on the effectiveness of such practical CFI.This paper aims to boost the effectiveness of practical CFI by dramatically optimizing the target-function sets (aka equivalence class or EC) of indirect calls. We first identify two fundamental limitations that lead to the imprecision of static indirect-call analysis: incomplete field sensitivity due to variable field indexes and the unawareness of the origins of point-to targets. We then propose two novel analysis techniques, complete field sensitivity and origin awareness, which handle variable field indexes and distinguish target origins. The techniques dramatically reduce the size of target functions. To enforce the origin awareness, we further employ Intel Memory Protection Keys to safely store the origin information. We implement our techniques as a system called ECCut. The evaluation results show that compared to the mainline LLVM CFI, ECCut achieves a substantial reduction of 94.8% and 90.3% in the average and the largest EC sizes. While compared to the state-of-the-art origin-aware CFI (i.e., OS-CFI), ECCut reduces the average and the largest EC sizes by 90.2% and 89.3% respectively. Additionally, ECCut introduces an acceptable performance overhead (7.2% on average) observed across a comprehensive range of C/C++ benchmark tests in SPEC CPU2006, SPEC CPU2017, and six real-world applications.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670308",
        "pub_year": "2024",
        "theme_label": "系统软件安全"
    },
    {
        "title": "Accurate and Efficient Recurring Vulnerability Detection for IoT Firmware",
        "authors": "Xiao, Haoyu; Zhang, Yuan; Shen, Minghang; Lin, Chaoyang; Zhang, Can; Liu, Shengli; Yang, Min",
        "keywords": "Firmware Vulnerability Detection (固件漏洞检测) - 检测物联网固件中的重复漏洞\nExploitation-based Signature (基于利用的签名) - 通过动态利用过程生成漏洞特征\nConcolic Execution (混合执行技术) - 结合符号执行与具体执行提取漏洞特征\n选定的主题标签名称",
        "abstract": "IoT firmware faces severe threats to security vulnerabilities. As an important method to detect vulnerabilities, recurring vulnerability detection has not been systematically studied in IoT firmware. In fact, existing methods would meet significant challenges from two aspects. First, firmware vulnerabilities are usually reported in texts without too much code-level information, e.g., security patches. Second, firmware images are released as binaries, making the analysis of known vulnerabilities and the detection of unknown vulnerabilities quite difficult.This paper presents FIRMREC, the first recurring vulnerability detection approach for IoT firmware. FIRMREC features several new techniques to enable accurate and efficient vulnerability detection.First, it proposes a new exploitation-based vulnerability signature representation for firmware, which does not use syntactic code features but the semantic features along the dynamic vulnerability exploitation procedure (thus is more resilient to binary code changes and fits the context of binary-only firmware). Second, given a vulnerability report, it designs concolic execution-based vulnerability signature extraction to understand the vulnerability exploitation procedure and generate an exploitation-based vulnerability signature. Third, based on known vulnerability signatures, it employs a two-stage pipeline to accurately and efficiently detect recurring vulnerabilities.With a dataset of 320 firmware images, FIRMREC efficiently detects 642 vulnerabilities. Till now, 53 CVEs have been assigned. Compared with SaTC, jTrans, and Greenhouse, FIRMREC detects more vulnerabilities and is more accurate.Our study shows that recurring vulnerabilities are quite prevalent in IoT firmware but require new techniques to detect.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670275",
        "pub_year": "2024",
        "theme_label": "3.8.1 漏洞挖掘与逆向分析"
    },
    {
        "title": "Measuring Compliance Implications of Third-party Libraries' Privacy Label Disclosure Guidelines",
        "authors": "Xiao, Yue; Zhang, Chaoqi; Qin, Yue; Alharbi, Fares Fahad S.; Xing, Luyi; Liao, Xiaojing",
        "keywords": "Privacy Label Compliance (隐私标签合规性) - 检测第三方库数据实践声明的准确性\nThird-party Libraries (第三方库) - 分析其在应用隐私披露中的作用\nAutomated Compliance Checking (自动化合规检查) - 利用工具评估隐私政策与实现一致性",
        "abstract": "Privacy label disclosure guideline, which specifies the data usage practices of third-party libraries (TPL), is a valuable resource for iOS app developers to accurately complete their iOS privacy labels. This is particularly important given the mandatory requirement for all apps on the App Store to disclose their data practices via privacy labels. However, it is essential to ensure the accuracy and compliance of these guidelines to ensure that accurate TPL data usage has been provided to app developers. Despite the significance of these guidelines, there is little understanding of how accurate and compliant they are in reflecting the actual data practices of third-party libraries used in iOS apps. To address this issue, our study implements a tool called Colaine to automatically check the compliance of privacy label disclosure guidelines, taking into account the configurable data practices in TPLs. Colaine analyzed 107 TPLs associated with 1,605 different configurations, shedding light on the prevalence and seriousness of privacy label disclosure guideline non-compliance issues.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670371",
        "pub_year": "2024",
        "theme_label": "系统安全测评"
    },
    {
        "title": "Poster: Cyber Security Economics Model (CYSEM)",
        "authors": "Xin, Tong; He, Ying; Zamani, Efpraxia D.; Luo, Cunjin",
        "keywords": "Cyber Security Economics (网络安全经济学) - 安全投资决策量化分析\nCyber Threat Intelligence (网络威胁情报) - 威胁数据收集与分析\nFAIR Model (信息风险因子分析模型) - 风险量化评估框架",
        "abstract": "The increasing sophistication of cyberattacks and the evolution of security risks make it challenging for organizations to understand their impact on businesses. The habitual reliance on the judgment of cyber security experts and communication gaps between cyber security team and board members, responsible for making strategic cyber security investment decisions further weaken organization's capability to respond to cyber threats. Existing research lacks a transparent approach to quantify security risks and their impact on businesses. This paper introduces a novel CYSEM that express security risk in financial terms, through integrating Cyber Threat Intelligence (CTI) with the Factor Analysis of Information Risk (FAIR) model, elaborated with cyber security cost typologies. CYSEM facilitates communication among multi-stakeholders and improves transparency and quality of investment decision-making at the strategic level. We evaluate the CYSEM using a case study, which has showed its effectiveness in understanding the impact of cyber threat from an economics perspective.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691398",
        "pub_year": "2024",
        "theme_label": "1.4 测绘理论、安全治理与策略"
    },
    {
        "title": "Fuzzing JavaScript Engines with a Graph-based IR",
        "authors": "Xu, Haoran; Jiang, Zhiyuan; Wang, Yongjun; Fan, Shuhui; Xu, Shenglin; Xie, Peidai; Fu, Shaojing; Payer, Mathias",
        "keywords": "Fuzzing (模糊测试) - 程序缺陷发现技术\nGraph-based IR (基于图的中间表示) - 控制与数据流建模\nSemantic Mutation (语义变异) - 保持程序意义的变异操作",
        "abstract": "Mutation-based fuzzing effectively discovers defects in JS engines. High-quality mutations are key for the performance of mutation-based fuzzers. The choice of the underlying representation (e.g., a sequence of tokens, an abstract syntax tree, or an intermediate representation) defines the possible mutation space and subsequently influences the design of mutation operators. Current program representations in JS engine fuzzers center around abstract syntax trees and customized bytecode-level intermediate languages. However, existing efforts struggle to generate semantically valid and meaningful mutations, limiting the discovery of defects in JS engines.Our proposed graph-based intermediate representation, FlowIR, directly represents the JS control flow and data flow as the mutation target. FlowIR is essential for the implementation of powerful semantic mutation. It supports mutation operators at the data flow and control flow level, thereby expanding the granularity of mutation operators. Experimental results show that our method is more effective in discovering new bugs. Our prototype, FuzzFlow, outperforms state-of-the-art fuzzers in generating valid test cases and exploring code coverage. In our evaluation, we detected 37 new defects in thoroughly tested mainstream JS engines.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690336",
        "pub_year": "2024",
        "theme_label": "系统安全测评"
    },
    {
        "title": "Camel: Communication-Efficient and Maliciously Secure Federated Learning in the Shuffle Model of Differential Privacy",
        "authors": "Xu, Shuangqing; Zheng, Yifeng; Hua, Zhongyun",
        "keywords": "Federated Learning (联邦学习) - 分布式机器学习框架\nDifferential Privacy (差分隐私) - 隐私数据统计分析保护\nSecret Sharing (秘密共享) - 安全多方计算基础技术\n选定的主题标签名称",
        "abstract": "Federated learning (FL) has rapidly become a compelling paradigm that enables multiple clients to jointly train a model by sharing only gradient updates for aggregation, without revealing their local private data. In order to protect the gradient updates which could also be privacy-sensitive, there has been a line of work studying local differential privacy (LDP) mechanisms to provide a formal privacy guarantee. With LDP mechanisms, clients locally perturb their gradient updates before sharing them out for aggregation. However, such approaches are known for greatly degrading the model utility, due to heavy noise addition. To enable a better privacy-utility trade-off, a recently emerging trend is to apply the shuffle model of DP in FL, which relies on an intermediate shuffling operation on the perturbed gradient updates to achieve privacy amplification. Following this trend, in this paper, we present Camel, a new communication-efficient and maliciously secure FL framework in the shuffle model of DP. Camel first departs from existing works by ambitiously supporting integrity check for the shuffle computation, achieving security against malicious adversary. Specifically, Camel builds on the trending cryptographic primitive of secret-shared shuffle, with custom techniques we develop for optimizing system-wide communication efficiency, and for lightweight integrity checks to harden the security of server-side computation. In addition, we also derive a significantly tighter bound on the privacy loss through analyzing the Renyi differential privacy (RDP) of the overall FL process. Extensive experiments demonstrate that Camel achieves better privacy-utility trade-offs than the state-of-the-art work, with promising performance.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690200",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "PhyScout: Detecting Sensor Spoofing Attacks via Spatio-temporal Consistency",
        "authors": "Xu, Yuan; Deng, Gelei; Han, Xingshuo; Li, Guanlin; Qiu, Han; Zhang, Tianwei",
        "keywords": "Sensor Spoofing Detection (传感器欺骗检测) - 攻击识别与防御\nSpatio-temporal Consistency (时空一致性) - 环境特征时空关联分析\nAutonomous Vehicle Security (自动驾驶车辆安全) - 保障自动驾驶感知安全\n选定的主题标签名称",
        "abstract": "Existing defense approaches against sensor spoofing attacks suffer from the limitations of limited specific attack types, requiring GPU computation, exhibiting considerable detection latency and struggling with the interpretability of corner cases. We developed PhyScout, a holistic sensor spoofing defense framework to overcome the above limitations. Our framework capitalizes on the observation that human drivers can rapidly and accurately identify spoofing attacks by performing spatio-temporal consistency checks of their environment. We commence by defining the generalized conflicts that different sensor spoofing attacks produce regarding the spatio-temporal consistency. These conflicts are subsequently unified and formalized through a least squares problem approach. This process is modeled using image-based feature point extraction and matching techniques, followed by the design of a risk identification method for each conflict.We evaluate PhyScout across various environments, including simulators, datasets, and real-world scenarios. Compared to existing defense solutions, PhyScout offers rapid identification of sensor attacks (within 100ms) with low performance overhead (CPU-based), and conflict visualization. It demonstrates a fresh paradigm in autonomous vehicle security and presents new avenues for future research in robust and efficient defense mechanisms against sensor spoofing attacks. More video demos are at our anonymous website https://sites.google.com/view/physcout.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670290",
        "pub_year": "2024",
        "theme_label": "3.9.1 攻击行为监测发现"
    },
    {
        "title": "Stealing Trust: Unraveling Blind Message Attacks in Web3 Authentication",
        "authors": "Yan, Kailun; Zhang, Xiaokuan; Diao, Wenrui",
        "keywords": "Web3 Authentication (Web3 认证) - 用户身份验证机制\nBlind Message Attack (盲消息攻击) - 欺骗用户签名消息\nDynamic Detection Tool (动态检测工具) - 实时识别认证漏洞\n选定的主题标签名称",
        "abstract": "As the field of Web3 continues its rapid expansion, the security of Web3 authentication, often the gateway to various Web3 applications, becomes increasingly crucial. Despite its widespread use as a login method by numerous Web3 applications, the security risks of Web3 authentication have not received much attention. This paper investigates the vulnerabilities in the Web3 authentication process and proposes a new type of attack, dubbed blind message attacks. In blind message attacks, attackers trick users into blindly signing messages from target applications by exploiting users' inability to verify the source of messages, thereby achieving unauthorized access to the target application. We have developed Web3AuthChecker, a dynamic detection tool that interacts with Web3 authentication-related APIs to identify vulnerabilities. Our evaluation of real-worldWeb3 applications shows that a staggering 75.8% (22/29) of Web3 authentication deployments are at risk of blind message attacks. In response to this alarming situation, we implemented Web3AuthGuard on the open-source wallet MetaMask to alert users of potential attacks. Our evaluation results show that Web3AuthGuard can successfully raise alerts in 80% of the tested Web3 authentications. We have responsibly reported our findings to vulnerable websites and have been assigned two CVE IDs.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670323",
        "pub_year": "2024",
        "theme_label": "5.6 身份认证与管理"
    },
    {
        "title": "MaskPrint: Take the Initiative in Fingerprint Protection to Mitigate the Harm of Data Breach",
        "authors": "Yan, Yihui; Yang, Zhice",
        "keywords": "Fingerprint Protection (指纹保护) - 防止指纹信息泄露与滥用\nData Breach Mitigation (数据泄露缓解) - 减少因数据泄露带来的安全风险\nUser-transparent Authentication (用户透明认证) - 用户无感知的安全认证机制\n选定的主题标签名称",
        "abstract": "The privacy of fingerprints is a growing concern due to the risk of data breaches and subsequent attacks. A key issue is that the information of the same fingerprint may exist on multiple devices, and device-level protection mechanisms are fundamentally limited in their coverage. Consequently, information leakage from any device potentially affects all enrolled fingerprint recognition devices. In this paper, we introduce a novel fingerprint enrollment method called MaskPrint, which allows users to enroll in various fingerprint recognition systems using distinct information. This approach can largely mitigate the risk of data breaches, providing a user-transparent, device-agnostic fingerprint protection measure. Our method involves collecting the original fingerprint information, selecting a minimum feature set, synthesizing protective fingerprints, and fabricating physical ones for enrollment. Users can complete these procedures on their own. We validate the effectiveness and usability of MaskPrint on commercial fingerprint recognition systems.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670364",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "SWIDE: A Semantic-aware Detection Engine for Successful Web Injection Attacks",
        "authors": "Yang, Ronghai; Wang, Xianbo; Luo, Kaixuan; Lei, Xin; Li, Ke; Xin, Jiayuan; Lau, Wing Cheong",
        "keywords": "Web Injection Detection (Web注入检测) - 检测Web攻击是否成功\nSemantic Analysis (语义分析) - 分析代码意图与行为\nObfuscation Resilience (混淆抗性) - 突破载荷混淆技术\n选定的主题标签名称",
        "abstract": "Web attacks, a primary vector for system breaches, pose a significant challenge within the cybersecurity landscape. The growing intensity of web attack attempts has led to alert fatigue where enterprises are inundated by excessive alerts. Although extensive research is being conducted on automated methods for detecting web attacks, it remains an open problem to identify whether the attacks are successful. Towards this end, we present SWIDE (Successful Web Injection Detection Engine), an engine to pinpoint successful web injection attacks (e.g., PHP command injection, SQL injection). This enables enterprises to focus exclusively on those crucial threats. Our methodology builds on two insights: Firstly, while attackers tend to apply payload obfuscation techniques to evade detection, all successful web injection attacks must comply with the programming language syntax to be executable; Secondly, these attacks inevitably produce observable effects, such as returning execution result or creating backdoors for future access by the attacker. Consequently, we leverage advanced syntactic and semantic analysis to 1) detect malicious syntax features in obfuscated payloads and 2) perform semantic analysis of the payload to recover the intention of the attack. With a two-stage design, namely, attack identification and confirmation mechanisms, SWIDE can accurately identify successful attacks, even amidst intricate obfuscations. Unlike proof-of-concept studies, SWIDE has been deployed and validated in real-world environments through collaborations with a cybersecurity firm. Serving 5,045 enterprise users, our system identifies that roughly 15% of enterprises have suffered from successful attacks on a weekly basis - an alarmingly high rate. Moreover, we perform a detailed analysis of six months' data and discover 60 zero-day vulnerabilities exploited in the wild, including 12 high-risk ones acknowledged by relevant authorities. These findings underscore the practical effectiveness of SWIDE.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670304",
        "pub_year": "2024",
        "theme_label": "3.9.1 攻击行为监测发现"
    },
    {
        "title": "UWBAD: Towards Effective and Imperceptible Jamming Attacks Against UWB Ranging Systems with COTS Chips",
        "authors": "Yang, Yuqiao; Wu, Zhongjie; Zhang, Yongzhao; Chen, Ting; Li, Jun; Yang, Jie; Liu, Wenhao; Zhang, Xiaosong; Shi, Ruicong; Li, Jingwei; Jiang, Yu; Su, Zhuo",
        "keywords": "UWB Ranging (超宽带测距) - 用于精准定位与安全通信\nJamming Attacks (干扰攻击) - 阻断信号实现恶意干扰\nCOTS Chips (商用现成芯片) - 利用普通硬件实施攻击\n选定的主题标签名称",
        "abstract": "UWB ranging systems have been adopted in many critical and security sensitive applications due to its precise positioning and secure ranging capabilities. We present a practical jamming attack, namely UWBAD, against commercial UWB ranging systems, which exploits the vulnerability of the adoption of the normalized cross-correlation process in UWB ranging and can selectively and quickly block ranging sessions without prior knowledge of the configurations of the victim devices, potentially leading to severe consequences such as property loss, unauthorized access, or vehicle theft. UWBAD achieves more effective and less imperceptible jamming due to: (i) it efficiently blocks every ranging session by leveraging the field-level jamming, thereby exerting a tangible impact on commercial UWB ranging systems, and (ii) the compact, reactive, and selective system design based on COTS UWB chips, making it affordable and less imperceptible. We successfully conducted real attacks against commercial UWB ranging systems from the three largest UWB chip vendors on the market, e.g., Apple, NXP, and Qorvo. We reported our findings to Apple, related Original Equipment Manufacturers (OEM), and the Automotive Security Research Group. As of the writing of this paper, the related OEM has acknowledged this vulnerability in their automotive systems and has offered a $5, 000 reward as a bounty.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670349",
        "pub_year": "2024",
        "theme_label": "3.9.3 攻击行为阻断"
    },
    {
        "title": "Distributed Backdoor Attacks on Federated Graph Learning and Certified Defenses",
        "authors": "Yang, Yuxin; Li, Qiang; Jia, Jinyuan; Hong, Yuan; Wang, Binghui",
        "keywords": "Federated Graph Learning (联邦图学习) - 图数据分布式协同训练\nBackdoor Attack (后门攻击) - 恶意植入隐蔽触发器操控模型输出\nCertified Defense (认证防御) - 提供理论保证的安全防护机制",
        "abstract": "Federated graph learning (FedGL) is an emerging federated learning (FL) framework that extends FL to learn graph data from diverse sources without accessing the data. FL for non-graph data has shown to be vulnerable to backdoor attacks, which inject a shared backdoor trigger into the training data such that the trained back-doored FL model can predict the testing data containing the trigger as the attacker desires. However, FedGL against backdoor attacks is largely unexplored, and no effective defense exists.In this paper, we aim to address such significant deficiency. First, we propose an effective, stealthy, and persistent backdoor attack on FedGL. Our attack uses a subgraph as the trigger and designs an adaptive trigger generator that can derive the effective trigger location and shape for each graph. Our attack shows that empirical defenses are hard to detect/remove our generated triggers. To mitigate it, we further develop a certified defense for any backdoored FedGL model against the trigger with any shape at any location. Our defense involves carefully dividing a testing graph into multiple subgraphs and designing a majority vote-based ensemble classifier on these subgraphs. We then derive the deterministic certified robustness based on the ensemble classifier and prove its tightness. We extensively evaluate our attack and defense on six graph datasets. Our attack results show our attack can obtain > 90% backdoor accuracy in almost all datasets. Our defense results show, in certain cases, the certified accuracy for clean testing graphs against an arbitrary trigger with size 20 can be close to the normal accuracy under no attack, while there is a moderate gap in other cases. Source code is available at: https://github.com/Yuxin104/Opt- GDBA. The full report is at: https://arxiv.org/abs/2407.08935.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690187",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Watch the Rhythm: Breaking Privacy with Accelerometer at the Extremely-Low Sampling Rate of 5Hz",
        "authors": "Yao, Qingsong; Liu, Yuming; Sun, Xiongjia; Dong, Xuewen; Ji, Xiaoyu; Ma, Jianfeng",
        "keywords": "Accelerometer Eavesdropping (加速度计窃听) - 利用低频加速度计进行声音窃取\nRhythm Features (节奏特征) - 通过节奏模式识别语音内容\nPrivacy Threat (隐私威胁) - 极低采样率下的新型隐私攻击",
        "abstract": "Considering the threat from on-board eavesdropping with smartphone motion sensors, Android 12 has limited the maximum sampling rate of motion sensors to 200Hz for zero-privilege access to prevent potential wiretapping. Unfortunately, there have been some attacks targeting 200Hz, making it not a safe sampling rate any more. Smartphone manufacturers may further reduce the maximum sampling rate of the accelerometer in response to this privacy concern. It can be expected that, the maximum sampling rate will gradually decrease to a very low level, as the battle between manufacturers and adversaries continues. Existing on-board eavesdropping approaches, utilizing spectral features, cannot provide acceptable accuracy at very low sampling rates, not even at 50Hz.Therefore, this paper explores the feasibility of using the onboard accelerometer for privacy breaking with an extremely-low sampling rate, specifically, 5Hz. 5Hz is a minimum sampling rate to meet normal use, otherwise the applications can only choose to work without the accelerometer. Since the lowest fundamental frequency for humans is around 85Hz, such a low sampling rate poses a significant challenge for sound recognition. According to Nyquist's law, it seems impossible to capture 85Hz with the sampling rate of 5Hz. Fortunately, we observe that the rhythm features, including pause rhythm and intensity rhythm, of accelerometer data are relatively stable at various sampling rates. On this basis, we propose an eavesdropping approach with the accelerometer at an extremely-low sampling rate. Introducing the rhythm features, we achieve an accuracy of 95.09% at 50Hz and 78.66% at 5Hz for scene recognition. The accuracy is 90.60% at 50Hz and 47% at 5Hz for Chinese digits recognition, plus 96.63% at 50Hz and 58.67% at 5Hz for popular Chinese cities recognition. Furthermore, we achieve determination for typical places like bar, metro, bus, car, and quiet room, by analyzing the vibration of surroundings, with an average accuracy of 91.28%. Combining place determination with eavesdropping, our approach poses a serious threat to personal privacy. Since 5Hz is generally used for screen orientation detection, our attack can hide in any kind of application, not just in game or sport applications. We also suggest some countermeasures.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690370",
        "pub_year": "2024",
        "theme_label": "信息内容安全"
    },
    {
        "title": "A Comprehensive Analysis of Security Vulnerabilities and Attacks in Satellite Modems",
        "authors": "Yu, Lingjing; Hao, Jingli; Ma, Jun; Sun, Yong; Zhao, Yijun; Luo, Bo",
        "keywords": "Satellite Modems (卫星调制解调器) - 卫星通信终端设备安全\nSecurity Vulnerabilities (安全漏洞) - 系统薄弱点分析\nAttack Surfaces (攻击面) - 安全威胁暴露区域",
        "abstract": "Satellite modems are critical components in satellite communication networks. Especially, they determine the entire communication regime in traditional systems where the satellites only act as transparent relays. However, unlike satellites that are usually more isolated and better protected, satellite modems are accessible and susceptible to lower-cost attacks, potentially serving as a weak link in the chain of satellite communication security. We make the first attempt to shed light on satellite modem security. We first physically disassemble commodity satellite modems and systematically examine hardware and software modules. We perform a measurement study on the satellite modems that are exposed to the Internet. We identify 16 security vulnerabilities across three attack surfaces: satellite communication interface, ground network interface, and hardware. We further introduce AirSecAnalyzer, an automated security analyzer/fuzzer for the modems' satellite communication interface. Through comprehensive analysis and extensive experiments on 9 real-world satellite modems, we report 18 novel attacks that exploit the identified vulnerabilities. Our findings are expected to contribute as a valuable foundation for future research on the security of satellite modems and satellite communication networks.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670390",
        "pub_year": "2024",
        "theme_label": "网络与系统安全"
    },
    {
        "title": "PhySense: Defending Physically Realizable Attacks for Autonomous Systems via Consistency Reasoning",
        "authors": "Yu, Zhiyuan; Li, Ao; Wen, Ruoyao; Chen, Yijia; Zhang, Ning",
        "keywords": "Adversarial Attack Defense (对抗攻击防御) - 防御物理可实现性攻击\nAutonomous Vehicles Security (自动驾驶安全) - 保障自动驾驶系统安全性\nConsistency Reasoning (一致性推理) - 基于物理特性的多模态推理\n选定的主题标签名称",
        "abstract": "Autonomous vehicles (AVs) empowered by deep neural networks (DNNs) are bringing transformative changes to our society. However, they are generally susceptible to adversarial attacks, especially physically realizable perturbations that can mislead perception and cause catastrophic outcomes. While existing defenses have shown success, there remains a pressing need for improved robustness while maintaining efficiency to meet real-time system operations.To tackle these challenges, we introduce PhySense, a complementary solution that leverages multi-faceted reasoning for misclassification detection and correction. This defense is built on physical characteristics, including static and dynamic object attributes and their interrelations. To effectively integrate these diverse sources, we develop a system based on the conditional random field that models objects and relationships as a spatial-temporal graph for holistic reasoning on the perceived scene. To ensure the defense does not violate the timing requirement of the real-time cyberphysical control loop, we profile the run-time characteristics of the workloads to parallelize and pipeline the execution of the defense implementation. The efficacy of PhySense is experimentally validated through simulations of datasets and real-world driving tests. It also demonstrates resiliency against adaptive attacks, and the potential of applying underlying principles to other modalities beyond vision.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690236",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Towards Proactive Protection against Unauthorized Speech Synthesis",
        "authors": "Yu, Zhiyuan",
        "keywords": "Voice Cloaking (语音伪装) - 防止未经授权的语音克隆\nAdversarial Robustness (对抗鲁棒性) - 提升模型抗干扰能力\nSpeech Synthesis Defense (语音合成防御) - 主动防御生成式语音伪造",
        "abstract": "The rapid advancement of artificial speech synthesis technologies, fueled by generative AI (GenAI), presents both opportunities and potential threats to society. While offering unprecedented opportunities, these technologies have been exploited to create DeepFake speech for fraud, impersonation, and spreading disinformation, as evidenced by recent real-world incidents. Our research aims to address such emerging threats by exploring a novel, proactive approach to disrupt unauthorized speech synthesis.Grounded in adversarial robustness theories, the core defense strategy is to embed imperceptible voice cloaks into users' speech. These perturbations are designed to prevent accurate voice cloning when used in unauthorized synthesis processes. This concept has been realized and validated in our preliminary work, AntiFake, demonstrating the initial feasibility. Building on these foundations, we propose a line of research that seeks to understand the fundamental three-way trade-off across protection generalizability, audio quality, and computational efficiency, and further achieve balanced improvements across these dimensions.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690868",
        "pub_year": "2024",
        "theme_label": "信息内容安全"
    },
    {
        "title": "HyperTheft: Thieving Model Weights from TEE-Shielded Neural Networks via Ciphertext Side Channels",
        "authors": "Yuan, Yuanyuan; Liu, Zhibo; Sen Deng; Chen, Yanzuo; Wang, Shuai; Zhang, Yinqian; Su, Zhendong",
        "keywords": "Trusted Execution Environment (可信执行环境) - 安全隔离保护机制\nCiphertext Side Channel (密文侧信道) - 信息泄露分析技术\nNeural Network Weight Recovery (神经网络权重恢复) - 模型窃取攻击方法\n选定的主题标签名称",
        "abstract": "Trusted execution environments (TEEs) are widely employed to protect deep neural networks (DNNs) from untrusted hosts (e.g., hypervisors). By shielding DNNs as fully black-box via encryption, TEEs mitigate model weight leakage and its follow-up white-box attacks. However, this paper uncovers that the confidentiality of TEE-shielded DNNs can be violated due to an emerging threat towards TEEs: ciphertext side channels of TEEs create weight-dependent observations during a DNN's execution. Despite the potential of inferring DNN weights from ciphertext side channels, existing techniques are inapplicable due to their over-strong requirements and the high precision required by DNN weights. A DNN can have millions of weight elements, and even a few incorrectly recovered weight elements may make the DNN non-functional.We propose a novel viewpoint that focuses on the functionality of DNN weights, rather than each weight element's exact value. Accordingly, we design HyperTheft to directly generate weights that are functionality-equivalent to the victim DNN using ciphertext side channels. HyperTheft is established for highly practical settings; it exhibits the weakest requirement compared to prior methods. When only knowing a victim DNN's input type and task type (which are public and denote the minimal information required to use a DNN), HyperTheft can recover its weight using ciphertext side channels logged during the victim DNN's one execution. The whole procedure does not require attackers to 1) query the victim DNN, 2) have valid data that the DNN accepts, or 3) know the victim DNN's structure. Our evaluations generate more than 8K DNN weights which constantly achieve 77%similar to 97% test accuracy in different DNN runtimes, including various versions of PyTorch and DNN executables. Our recovered weights can subsequently enable training data leakage and severe bit-flip attacks.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690317",
        "pub_year": "2024",
        "theme_label": "2.4 密码工程技术"
    },
    {
        "title": "S2NeRF: Privacy-preserving Training Framework for NeRF",
        "authors": "Zhang, Bokang; Zhang, Yanglin; Zhang, Zhikun; Yang, Jinglan; Huang, Lingying; Wu, Junfeng",
        "keywords": "Privacy-preserving Training (隐私保护训练) - 保护数据隐私的模型训练方法\nSplit Learning (分割学习) - 客户端-服务器协同训练技术\nNeRF (神经辐射场) - 基于神经网络的3D场景建模\n选定的主题标签名称",
        "abstract": "Neural Radiance Fields (NeRF) have revolutionized 3D computer vision and graphics, facilitating novel view synthesis and influencing sectors like extended reality and e-commerce. However, NeRF's dependence on extensive data collection, including sensitive scene image data, introduces significant privacy risks when users upload this data for model training. To address this concern, we first propose a strawman solution: SplitNeRF, a training framework that incorporates split learning (SL) techniques to enable privacy-preserving collaborative model training between clients and servers without sharing local data. Despite its benefits, we identify vulnerabilities in SplitNeRF by developing two attack methods, Surrogate Model Attack and Scene-aided Surrogate Model Attack, which exploit the shared gradient data and few leaked scene images to reconstruct private scene information. To counter these threats, we introduce (SNeRF)-Ne-2, secure SplitNeRF that integrates effective defense mechanisms. By introducing decaying noise related to the gradient norm into the shared gradient information, (SNeRF)-Ne-2 preserves privacy while maintaining a high utility of the NeRF model. Our extensive evaluations across multiple datasets demonstrate the effectiveness of (SNeRF)-Ne-2 against privacy breaches, confirming its viability for secure NeRF training in sensitive applications.(1)",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690185",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "The HITCHHIKER's Guide to High-Assurance System Observability Protection with Efficient Permission Switches",
        "authors": "Zhang, Chuqi; Zeng, Jun; Zhang, Yiming; Ahmad, Adil; Zhang, Fengwei; Jin, Hai; Liang, Zhenkai",
        "keywords": "High-Assurance System Observability (高保证系统可观测性) - 确保日志安全与完整性\nEfficient Permission Switches (高效权限切换) - 利用硬件机制快速切换保护\nLog Protection Delay Reduction (日志保护延迟降低) - 显著提升实时日志处理性能\n选定的主题标签名称",
        "abstract": "Protecting system observability records (logs) from compromised OSs has gained significant traction in recent times, with several note-worthy approaches proposed. Unfortunately, none of the proposed approaches achieve high performance with tiny log protection delays. They also leverage risky environments for protection (e.g., many use general-purpose hypervisors or TrustZone, which have large TCB and attack surfaces). HITCHHIKER is an attempt to rectify this problem. The system is designed to ensure (a) in-memory protection of batched logs within a short and configurable real-time deadline by efficient hardware permission switching, and (b) an end-to-end high-assurance environment built upon hardware protection primitives with debloating strategies for secure log protection, persistence, and management. Security evaluations and validations show that HITCHHIKER reduces log protection delay by 93.3-99.3% compared to the state-of-the-art, while reducing TCB by 9.4-26.9x. Performance evaluations show HITCHHIKER incurs a geometric mean of less than 6% overhead on diverse real-world programs, improving on the state-of-the-art approach by 61.9-77.5%.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690188",
        "pub_year": "2024",
        "theme_label": "3.2 硬件安全"
    },
    {
        "title": "Unbalanced Private Set Union with Reduced Computation and Communication",
        "authors": "Zhang, Cong; Chen, Yu; Liu, Weiran; Peng, Liqiang; Hao, Meng; Wang, Anyu; Wang, Xiaoyun",
        "keywords": "Private Set Union (私有集合联合) - 隐私保护下的集合运算\nOblivious Key-Value Store (不经意键值存储) - 数据隐私与高效检索结合\nBatch Private Information Retrieval (批量私密信息检索) - 高效获取加密数据",
        "abstract": "Private set union (PSU) is a cryptographic protocol that allows two parties to compute the union of their sets without revealing anything else. Despite some efficient PSU protocols that have been proposed, they mainly focus on the balanced setting, where the sets held by the parties are of similar size. Recently, Tu et al. (CCS 2023) proposed the first unbalanced PSU protocol which achieves sublinear communication complexity in the size of the larger set.In this paper, we are interested in improving the efficiency of the unbalanced PSU protocol. We find that oblivious key-value store (OKVS) data structure plays an essential role in the most recently proposed PSU constructions and formalize unbalanced PSU as an OKVS decoding process with sublinear communication. Our key insight lies in when OKVS satisfies sparsity property, obtaining the necessary decoding information precisely aligns with the batch private information retrieval (BatchPIR) problem. We give two concrete constructions of unbalanced PSU protocols based on different OKVS encoding strategies. The first is based on oblivious PRF (OPRF) and a newly introduced cryptographic protocol called permuted private equality test, while the second is based on re-randomizable public key encryption. Both our two constructions achieve sublinear communication complexity in the size of the larger set.We implement our two unbalanced PSU protocols and compare them with the state-of-the-art unbalanced PSU of Tu et al. Experiments show that our protocols achieve a 1.3 - 5.6x speedup in running time and 2.1 - 11.8x shrinking in communication cost, depending on set sizes and network environments.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690308",
        "pub_year": "2024",
        "theme_label": "2.5 密码应用技术"
    },
    {
        "title": "Inbox Invasion: Exploiting MIME Ambiguities to Evade Email Attachment Detectors",
        "authors": "Zhang, Jiahe; Chen, Jianjun; Wang, Qi; Zhang, Hangyu; Wang, Chuhan; Zhuge, Jianwei; Duan, Haixin",
        "keywords": "Email Security (电子邮件安全) - 防御邮件中的恶意攻击\nParsing Ambiguity (解析歧义) - 不同解析器处理差异\nMalware Evasion (恶意软件逃逸) - 绕过检测机制的行为\n选定的主题标签名称",
        "abstract": "Email attachments have become a favored delivery vector for malware campaigns. In response, email attachment detectors are widely deployed to safeguard email security. However, an emerging threat arises when adversaries exploit parsing discrepancies between email detectors and clients to evade detection. Currently, uncovering these vulnerabilities still depends on manual, ad hoc methods. In this paper, we perform the first systematic evaluation of email attachment detection against parsing ambiguity vulnerabilities. We propose a novel testing methodology, MIMEminer, to systematically discover evasion vulnerabilities in email systems. We evaluated our methodology against 16 content detectors of popular email services like Gmail and iCloud, and 7 popular email clients like Outlook and Thunderbird. In total, we discovered 19 new evasion methods affecting all tested email services and clients. We further analyzed these vulnerabilities and identified three primary categories of malware evasions. We have responsibly reported those identified vulnerabilities to the affected providers to help with the remediation of such vulnerabilities and received acknowledgments from Google Gmail, Apple iCloud, Coremail, Tencent, Amavis and Perl MIME-tools.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670386",
        "pub_year": "2024",
        "theme_label": "3.7 恶意代码分析与防护"
    },
    {
        "title": "Language-based Sandboxing",
        "authors": "Zhang, Jialun",
        "keywords": "Language-based Sandboxing (语言级沙箱) - 通过编程语言机制实现隔离\nComposability (可组合性) - 特性组合增强系统安全性\nWhole-program Properties (全程序属性) - 分析和保障程序整体行为安全",
        "abstract": "Existing sandboxing techniques require a lot of manual efforts in retrofitting legacy programs and do not provide a unified framework for reasoning about whole-program properties. To address these issues, we propose a language-based approach that makes sandbox a first-class concept in the language. The composability of sandboxes with other language features can enable programmers to do faster compartmentalization and end-to-end reasoning of safety properties.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690866",
        "pub_year": "2024",
        "theme_label": "网络与系统安全"
    },
    {
        "title": "BadMerging: Backdoor Attacks Against Model Merging",
        "authors": "Zhang, Jinghuai; Chi, Jianfeng; Li, Zheng; Cai, Kunlin; Zhang, Yang; Tian, Yuan",
        "keywords": "Backdoor Attack (后门攻击) - 恶意植入模型的隐蔽漏洞\nModel Merging (模型融合) - 多模型集成提升性能方法\nAdversarial Security (对抗安全) - 针对AI模型的安全威胁",
        "abstract": "Fine-tuning pre-trained models for downstream tasks has led to a proliferation of open-sourced task-specific models. Recently, Model Merging (MM) has emerged as an effective approach to facilitate knowledge transfer among these independently fine-tuned models. MM directly combines multiple fine-tuned task-specific models into a merged model without additional training, and the resulting model shows enhanced capabilities in multiple tasks. Although MM provides great utility, it may come with security risks because an adversary can exploit MM to affect multiple downstream tasks. However, the security risks of MM have barely been studied. In this paper, we first find that MM, as a new learning paradigm, introduces unique challenges for existing backdoor attacks due to the merging process. To address these challenges, we introduce BadMerging, the first backdoor attack specifically designed for MM. Notably, BadMerging allows an adversary to compromise the entire merged model by contributing as fewas one backdoored task-specific model. BadMerging comprises a two-stage attack mechanism and a novel feature-interpolation-based loss to enhance the robustness of embedded backdoors against the changes of different merging parameters. Considering that a merged model may incorporate tasks from different domains, BadMerging can jointly compromise the tasks provided by the adversary (on-task attack) and other contributors (off-task attack) and solve the corresponding unique challenges with novel attack designs. Extensive experiments show that BadMerging achieves remarkable attacks against various MM algorithms. Our ablation study demonstrates that the proposed attack designs can progressively contribute to the attack performance. Finally, we show that prior defense mechanisms fail to defend against our attacks, highlighting the need for more advanced defense. Our code is available at: https://github.com/jzhang538/BadMerging.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690284",
        "pub_year": "2024",
        "theme_label": "人工智能安全"
    },
    {
        "title": "Membership Inference Attacks against Vision Transformers: Mosaic MixUp Training to the Defense",
        "authors": "Zhang, Qiankun; Yuan, Di; Zhang, Boyu; Yuan, Bin; Du, Bingqian",
        "keywords": "Membership Inference Attack (成员推理攻击) - 隐私泄露风险分析\nVision Transformer (视觉变换模型) - 图像处理前沿架构\nMosaic MixUp Training (马赛克混合训练) - 防御隐私攻击方法\n选定的主题标签名称",
        "abstract": "Vision transformers (ViTs) have demonstrated great success in various fundamental CV tasks, mainly benefiting from their self-attention-based transformer architectures, and the paradigm of pre-training followed by fine-tuning. However, such advantages may lead to significant data privacy risks, such as membership inference attacks (MIAs), which remain unclear. This paper presents the first comprehensive study on MIAs and corresponding defenses against ViTs. Our first contribution is a rollout-attention-based MIA method (RAMIA), based on an experimental observation that the attention, more precisely the rollout attention, behaves disproportionately for members and non-members. We evaluate RAMIA on the standard ViT architecture proposed by Google (ICLR 2021), achieving high accuracy, precision, and recall performance. Further, inspired by another experimental observation on a strong connection between positional embeddings (PEs) and attentions, we propose a novel framework for training ViTs, named Mosaic MixUp Training (MMUT), as a defense against RAMIA. Intuitively, MMUT mixes up private images and public ones at a patch level, and mosaics the corresponding PEs with a global learnable mosaic embedding. Our empirical results show MMUT achieves a much better accuracy-privacy trade-off than some common defense mechanisms. Extensive experiments are conducted to rigorously evaluate both RAMIA and MMUT.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690268",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "SAFARI: Speech-Associated Facial Authentication for AR/VR Settings via Robust VIbration Signatures",
        "authors": "Zhang, Tianfang; Ji, Qiufan; Ye, Zhengkun; Rahman, Md Mojibur; Akanda, Redoy; Mahdad, Ahmed Tanvir; Shi, Cong; Wang, Yan; Saxena, Nitesh; Chen, Yingying",
        "keywords": "Speech Authentication (语音认证) - 基于语音特征的身份验证\nFacial Vibration Biometrics (面部振动生物特征) - 利用面部肌肉振动提取生物特征\nAR/VR Security (增强现实/虚拟现实安全) - 保障AR/VR设备使用中的安全性",
        "abstract": "In AR/VR devices, the voice interface, serving as one of the primary AR/VR control mechanisms, enables users to interact naturally using speeches (voice commands) for accessing data, controlling applications, and engaging in remote communication/meetings. Voice authentication can be adopted to protect against unauthorized speech inputs. However, existing voice authentication mechanisms are usually susceptible to voice spoofing attacks and are unreliable under the variations of phonetic content. In this work, we propose SAFARI, a spoofing-resistant and text-independent speech authentication system that can be seamlessly integrated into AR/VR voice interfaces. The key idea is to elicit phonetic-invariant biometrics from the facial muscle vibrations upon the headset. During speech production, a user's facial muscles are deformed for articulating phoneme sounds. The facial deformations associated with the phonemes are referred to as visemes. They carry rich biometrics of the wearer's muscles, tissue, and bones, which can propagate through the head and vibrate the headset. SAFARI aims to derive reliable facial biometrics from the viseme-associated facial vibrations captured by the AR/VR motion sensors. Particularly, it identifies the vibration data segments that contain rich viseme patterns (prominent visemes) less susceptible to phonetic variations. Based on the prominent visemes, SAFARI learns on the correlations among facial vibrations of different frequencies to extract biometric representations invariant to the phonetic context. The key advantages of SAFARI are that it is suitable for commodity AR/VR headsets (no additional sensors) and is resistant to voice spoofing attacks as the conductive property of the facial vibrations prevents biometric disclosure via the air media or the audio channel. To mitigate the impacts of body motions in AR/VR scenarios, we also design a generative diffusion model trained to reconstruct the viseme patterns from the data distorted by motion artifacts. We conduct extensive experiments with two representative AR/VR headsets and 35 users under various usage and attack settings. We demonstrate that SAFARI can achieve over 96% true positive rate on verifying legitimate users while successfully rejecting different kinds of spoofing attacks with over 97% true negative rates.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670358",
        "pub_year": "2024",
        "theme_label": "身份认证与管理"
    },
    {
        "title": "Multi-User Security of CCM Authenticated Encryption Mode",
        "authors": "Zhang, Xiangyang; Shen, Yaobin; Wang, Lei",
        "keywords": "CCM authenticated encryption mode (CCM认证加密模式) - 用于安全通信的加密方案\nMulti-user security (多用户安全性) - 分析多个用户场景下的密码学安全\nSecurity bound analysis (安全边界分析) - 确定加密方案的安全强度上限\n选定的主题标签名称",
        "abstract": "The CCM authenticated encryption mode has gained widespread usage and standardization. Notably, in conjunction with GCM and ChaCha20-Poly1305, CCM is recommended to be used in TLS 1.3 that underlies in https. Since TLS 1.3 is currently utilized by a large number of users, it is imperative to assess the security of these schemes in the multi-user model. Concrete multi-user security analysis for GCM and ChaCha20-Poly1305 have been scrutinized in literature. However, the formal multi-user security analysis for CCM falls behind that for GCM and ChaCha20-Poly1305. Furthermore, in the associated IETF document, the multi-user security bound for CCM is derived by naive generic reduction and falls considerably short of our expectations. In this paper, we bridge the gap by establishing a concrete multi-user security bound for CCM. Our new bound surpasses that derived from generic reduction and it indicates that CCM maintains birthday-bound security in the multi-user model as in the single-user model.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670385",
        "pub_year": "2024",
        "theme_label": "2.3.1 密码算法设计与分析"
    },
    {
        "title": "Collapse Like A House of Cards: Hacking Building Automation System Through Fuzzing",
        "authors": "Zhang, Yue; Ling, Zhen; Cash, Michael; Zhang, Qiguang; Morales-Gonzalez, Christopher; Sun, Qun Zhou; Fu, Xinwen",
        "keywords": "Building Automation System (楼宇自动化系统) - 智能建筑核心控制系统\nFuzzing (模糊测试) - 自动化漏洞挖掘技术\nProtocol Security (协议安全) - 通信规范的安全评估\n选定的主题标签名称",
        "abstract": "Building Automation Systems (BAS) play a pivotal role in modern smart buildings, integrating sensors, controllers, and software to manage crucial functions such as HVAC, lighting, and more. The global smart building market is on the rise, underscoring the importance of securing BAS networks. This paper introduces the Building Automation System Evaluator (BASE), a specialized fuzzer designed to assess the security of BAS networks. BAS networks typically involve a BAS client communicating with a BAS server through BAS protocols (e.g., BACnet, KNX), each presenting unique challenges in BAS network fuzzing. These challenges encompass complex packet structures and sequencing in BAS protocols, closed-source clients with indeterminable code coverage, and unobservable server status with limited throughput. BASE automatically identifies protocol structures, dynamically instruments clients for code coverage analysis, and monitors responses for new coverage areas. Collected timestamps are used to estimate the input scan intervals of servers, optimizing throughput. We evaluated BASE on various BAS servers and clients, uncovering 13 new vulnerabilities. Furthermore, we present three attack case studies, highlighting the real-world security implications of these vulnerabilities in BAS systems, such as delayed fire detection, loss of climate control, and security breaches. We reported our findings to the respective vendors, who acknowledged the implications, and some have subsequently patched their systems based on our reports.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690216",
        "pub_year": "2024",
        "theme_label": "3.8.1 漏洞挖掘与逆向分析"
    },
    {
        "title": "When Compiler Optimizations Meet Symbolic Execution: An Empirical Study",
        "authors": "Zhang, Yue; Sirlanci, Melih; Wang, Ruoyu; Lin, Zhiqiang",
        "keywords": "Compiler Optimization (编译器优化) - 提升程序性能的代码转换技术\nDynamic Symbolic Execution (动态符号执行) - 程序分析与漏洞挖掘技术\nBinary Code Analysis (二进制代码分析) - 对可执行文件进行安全与行为分析\n选定的主题标签名称",
        "abstract": "Compiler optimizations intend to transform a program into a semantic-equivalent one with improved performance, but it is unclear how these optimizations may impact the performance of dynamic symbolic execution (DSE) on binary code. To systematically understand the impact of compiler optimizations on two popular DSE techniques (i.e., symbolic exploration and symbolic tracing), this paper presents an empirical study that quantifies 209 GCC compilation flags and 73 Clang compilation flags to reveal both positive and negative optimizations to DSE. Our data set contains 992 unique test cases, which are produced from 3,449 source files in the GCC test suite. After analyzing 2,978,976 binary programs that we compiled with two compilers and various compilation flags, we found that although some optimizations make DSE faster, most optimizations will actually slow down DSE. Our analysis further reveals root causes behind these impacts. The most positive impacts that optimizations have on DSE come from the reduction of the number of instructions and program paths, whereas negative impacts are caused by a series of unexpected behaviors, including increased numbers of instructions or program paths, library function inlining preventing DSE engines from using function summaries, and arithmetic optimizations leading to more sophisticated constraints. Being the first in-depth analysis on why compiler flags influence the performance of DSE, this project sheds light on program transformations that can be applied before performing DSE tasks for better performance.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670372",
        "pub_year": "2024",
        "theme_label": "3.8.2 系统安全测评"
    },
    {
        "title": "Gopher: High-Precision and Deep-Dive Detection of Cryptographic API Misuse in the Go Ecosystem",
        "authors": "Zhang, Yuexi; Li, Bingyu; Lin, Jingqiang; Li, Linghui; Bai, Jiaju; Jia, Shijie; Wu, Qianhong",
        "keywords": "Cryptographic API Misuse (密码API误用) - 检测密码接口错误使用\nGopher Detection Framework (Gopher检测框架) - 实现高精度漏洞扫描\nGo Ecosystem Security (Go生态安全) - 保障Go语言环境安全",
        "abstract": "The complexity of cryptographic APIs and developers' expertise gaps often leads to their improper use, seriously threatening information security. Existing cryptographic API misuse detection tools that rely on black/white-list methods require experts to manually establish detection rules. They struggle to dynamically update rules and scale to cover numerous unofficial cryptographic libraries. Furthermore, as these tools are primarily aimed at non-Go languages, they have limited applicability and accuracy in the Go ecosystem, which is extensively used for security-centric applications.To mitigate these challenges, we present Gopher, a novel cryptographic misuse detection framework, that excels in encapsulated API and cross-library detection. In this framework, we have designed CryDict to convert rules into unified and standardized constraints, capable of deriving newusage rules and elucidating implicit knowledge during scanning. Gopher leverages CryDict to create a logical separation between rule formulation and Detector detection, enabling dynamic updating of constraints and enhancing detection capabilities. This significantly improves the Gopher's compatibility and scalability. Utilizing Gopher, we have conducted an extensive analysis of the Go ecosystem, examining 19,313 Go projects. In our rigorous testing, Gopher demonstrated a remarkable 98.9% accuracy rate and identified 64.1% of previously undetected misuses. This scrutiny has surfaced numerous hidden security vulnerabilities, and highlighted misuse tendencies across diverse project categories.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690276",
        "pub_year": "2024",
        "theme_label": "密码学及应用"
    },
    {
        "title": "ArcEDB: An Arbitrary-Precision Encrypted Database via (Amortized) Modular Homomorphic Encryption",
        "authors": "Zhang, Zhou; Bian, Song; Zhao, Zian; Mao, Ran; Zhou, Haoyi; Hua, Jiafeng; Jin, Yier; Guan, Zhenyu",
        "keywords": "Fully Homomorphic Encryption (全同态加密) - 支持密文直接计算\nArbitrary-Precision Computation (任意精度计算) - 提升加密数据精度\nEncrypted Database (加密数据库) - 保障数据查询安全",
        "abstract": "Fully homomorphic encryption (FHE) based database outsourcing is drawing growing research interests. At its current state, there exist two primary obstacles against FHE-based encrypted databases (EDBs): i) low data precision, and ii) high computational latency. To tackle the precision-performance dilemma, we introduce ArcEDB, a novel FHE-based SQL evaluation infrastructure that simultaneously achieves high data precision and fast query evaluation. Based on a set of new plaintext encoding schemes, we are able to execute arbitrary-precision ciphertext-to-ciphertext homomorphic comparison orders of magnitude faster than existing methods. Meanwhile, we propose efficient conversion algorithms between the encoding schemes to support highly composite SQL statements, including advanced filter-aggregation and multi-column synchronized sorting. We perform comprehensive experiments to study the performance characteristics of ArcEDB. In particular, we show that ArcEDB can be up to 57x faster in homomorphic filtering and up to 20x faster over end-to-end SQL queries when compared to the state-of-the-art FHE-based EDB solutions. Using ArcEDB, a SQL query over a 10K-row time-series EDB with 64-bit timestamps only runs for under one minute.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670384",
        "pub_year": "2024",
        "theme_label": "同态加密"
    },
    {
        "title": "MiniCAT: Understanding and Detecting Cross-Page Request Forgery Vulnerabilities in Mini-Programs",
        "authors": "Zhang, Zidong; Hou, Qinsheng; Ying, Lingyun; Diao, Wenrui; Gu, Yacong; Li, Rui; Guo, Shanqing; Duan, Haixin",
        "keywords": "MiniCPRF (跨页面请求伪造) - 新型小程序安全漏洞\nMini-program Security (小程序安全) - 研究小程序中的安全隐患\nAutomated Analysis Framework (自动化分析框架) - 提升漏洞检测效率",
        "abstract": "Mini-programs are lightweight apps running in super apps (such as WeChat, Baidu, Alipay, and TikTok), an emerging paradigm in the era of mobile computing. With the growing popularity of mini-programs, there is an increasing concern for their security and privacy. In essence, mini-programs are WebView-based apps. This means that they may be vulnerable to the same security risks associated with web apps. In this work, we discovered a new mini-program vulnerability called MiniCPRF (Cross-Page Request Forgery in Mini-Programs). The exploit of this vulnerability is easy, and the attack consequences are severe, leading to unauthorized operations, such as free shopping, and the exposure of confidential information, such as credit card numbers. The root causes of MiniCPRF can be attributed to multiple design flaws in both mini-programs and their super apps, including the insecure routing mechanism, lack of message integrity check, and plain-text storage. To evaluate the impacts of MiniCPRF, we designed an automated analysis framework called MiniCAT. It can automatically crawl mini-programs, perform static analysis on them, and generate detection reports. In large-scale real-world evaluations with MiniCAT, we identified that 32.0% (13,349/41,726) of analyzable mini-programs are potentially vulnerable to MiniCPRF, including some famous ones with millions of users, such as Sohu and Wen-juanxing. Following the responsible disclosure principle, we have reported verified vulnerable mini-programs to the corresponding vendors and developers, and three real-world cases have been confirmed by CNVD. Additionally, we suggest mitigation strategies to resolve the security issue related to MiniCPRF.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670294",
        "pub_year": "2024",
        "theme_label": "3.8.1 漏洞挖掘与逆向分析"
    },
    {
        "title": "Poster: Enhancing Network Traffic Analysis with Pre-trained Side-channel Feature Imputation",
        "authors": "Zhao, Faqi; Ma, Duohe; Li, Wenhao; Liu, Feng; Wang, Wen",
        "keywords": "Pre-trained Framework (预训练框架) - 利用预训练提升模型泛化能力\nSide-channel Analysis (侧信道分析) - 通过间接信息推断加密流量特征\nNetwork Traffic Imputation (网络流量补全) - 恢复丢失或碎片化的流量数据\n选定的主题标签名称",
        "abstract": "The recent advances in learning-based methodologies has underscored their efficacy in deducing patterns from the side-channel features of encrypted network traffic. Nonetheless, the distribution of these features has been identified as susceptible, particularly in the expansive and intricate network topologies characteristic of the modern Internet. The unpredictability of traffic bursts can result in packet loss during retransmission, thereby generating fragmented feature patterns. Unfortunately, current approaches struggle to adapt to such fragmented features, often leading to a substantial decline in performance. To surmount this challenge, this paper introduces a pre-training-based augmentation framework, denoted as Nuwa, which imputes the side-channel features of encrypted network traffic. The crux of Nuwa lies in its ability to reconstruct the side-channel features, with a particular focus on the temporal attributes of the missing packets within a traffic session. Nuwa is comprised of a word-level Sequence2Embedding module, a Traffic Noise-based Self-supervised Pre-trained Masking Strategy, and a Traffic Side-Channel Feature Imputation Module. Experiments across four diverse real-world scenarios substantiate Nuwa's capacity to restore the performance of prevalent temporal models while maintaining the integrity of the imputed features.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3691401",
        "pub_year": "2024",
        "theme_label": "4.9 加密流量识别与密态对抗"
    },
    {
        "title": "Compositional Verification of Composite Byzantine Protocols",
        "authors": "Zhao, Qiyuan; Pirlea, George; Grzeszkiewicz, Karolina; Gilbert, Seth; Sergey, Ilya",
        "keywords": "Compositional Verification (组合验证) - 组合验证方法研究\nByzantine Fault Tolerance (拜占庭容错) - 容错机制与协议设计\nFormal Verification (形式化验证) - 数学证明确保系统正确性\n选定的主题标签名称",
        "abstract": "Byzantine Fault-Tolerant (BFT) protocols are known to be difficult to design and to reason about. To address this challenge, on one hand, several approaches have been developed recently for computer-aided formal verification of the desired correctness properties, both safety and liveness, of standalone BFT protocols. On the other hand, the distributed computing community has made attempts to reduce the conceptual complexity of constructing new such protocols by showing how to assemble them from simpler building blocks. No methodology to date combines these two approaches for foundational verification of arbitrary BFT protocols.We present Bythos, the first foundational framework for compositional mechanised verification of both safety and liveness of composite BFT protocols. Bythos is implemented on top of the Coq proof assistant and uses Coq's higher-order logic to reuse proofs of common facts about knowledge and trust in BFT protocols. It allows for compact liveness specifications in the style of TLA+, and for their proofs using an embedding of TLA into Coq. Most importantly, Bythos provides a family of higher-order definitions that allow building composite BFT protocols from simpler ones, with their correctness proofs derived. We showcase Bythos by verifying in it safety and liveness properties of three basic BFT protocols: Reliable Broadcast, Provable Broadcast, and the recently proposed Accountable Byzantine Confirmer, as well as their compositions.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690355",
        "pub_year": "2024",
        "theme_label": "3.1 网络与系统安全体系结构"
    },
    {
        "title": "Towards Fine-Grained Webpage Fingerprinting at Scale",
        "authors": "Zhao, Xiyuan; Deng, Xinhao; Li, Qi; Liu, Yunpeng; Liu, Zhuotao; Sun, Kun; Xu, Ke",
        "keywords": "Webpage Fingerprinting (网页指纹识别) - 流量分析识别网页内容\nMulti-label Metric Learning (多标签度量学习) - 学习区分多标签特征空间\nEncrypted Traffic Analysis (加密流量分析) - 分析加密通信中的行为模式\n选定的主题标签名称",
        "abstract": "Website Fingerprinting (WF) attacks can effectively identify the websites visited by Tor clients via analyzing encrypted traffic patterns. Existing attacks focus on identifying different websites, but their accuracy dramatically decreases when applied to identify fine-grained webpages, especially when distinguishing among different subpages of the same website. WebPage Fingerprinting (WPF) attacks face the challenges of highly similar traffic patterns and a much larger scale of webpages. Furthermore, clients often visit multiple webpages concurrently, increasing the difficulty of extracting the traffic patterns of each webpage from the obfuscated traffic. In this paper, we propose Oscar, a WPF attack based on multi-label metric learning that identifies different webpages from obfuscated traffic by transforming the feature space. Oscar can extract the subtle differences among various webpages, even those with similar traffic patterns. In particular, Oscar combines proxy-based and sample-based metric learning losses to extract webpage features from obfuscated traffic and identify multiple webpages. We prototype Oscar and evaluate its performance using traffic collected from 1,000 monitored webpages and over 9,000 unmonitored webpages in the real world. Oscar demonstrates an 88.6% improvement in the multi-label metric Recall@5 compared to the state-of-the-art attacks.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690211",
        "pub_year": "2024",
        "theme_label": "4.9 加密流量识别与密态对抗"
    },
    {
        "title": "TabularMark: Watermarking Tabular Datasets for Machine Learning",
        "authors": "Zheng, Yihao; Xia, Haocheng; Pang, Junyuan; Liu, Jinfei; Ren, Kui; Chu, Lingyang; Cao, Yang; Xiong, Li",
        "keywords": "Watermarking (水印技术) - 数据所有权保护\nMachine Learning Utility (机器学习效用) - 保持模型训练性能\nRobustness (鲁棒性) - 抵抗攻击并保留水印\n选定的主题标签名称",
        "abstract": "Watermarking is broadly utilized to protect ownership of shared data while preserving data utility. However, existing watermarking methods for tabular datasets fall short on the desired properties (detectability, non-intrusiveness, and robustness) and only preserve data utility from the perspective of data statistics, ignoring the performance of downstream ML models trained on the datasets. Can we watermark tabular datasets without significantly compromising their utility for training ML models while preventing attackers from training usable ML models on attacked datasets?In this paper, we propose a hypothesis testing-based watermarking scheme, TabularMark. Data noise partitioning is utilized for data perturbation during embedding, which is adaptable for numerical and categorical attributes while preserving the data utility. For detection, a custom-threshold one proportion z-test is employed, which can reliably determine the presence of the watermark. Experiments on real-world and synthetic datasets demonstrate the superiority of TabularMark in detectability, non-intrusiveness, and robustness.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690373",
        "pub_year": "2024",
        "theme_label": "6.4 数字版权保护"
    },
    {
        "title": "KnowGraph: Knowledge-Enabled Anomaly Detection via Logical Reasoning on Graph Data",
        "authors": "Zhou, Andy; Xu, Xiaojun; Raghunathan, Ramesh; Lal, Alok; Guan, Xinze; Yu, Bin; Li, Bo",
        "keywords": "Graph-based Anomaly Detection (基于图的异常检测) - 利用图结构识别异常模式\nDomain Knowledge Integration (领域知识融合) - 结合专业知识提升模型效果\nLogical Reasoning (逻辑推理) - 基于逻辑规则进行推断判断\n选定的主题标签名称",
        "abstract": "Graph-based anomaly detection is pivotal in diverse security applications, such as fraud detection in transaction networks and intrusion detection for network traffic. Standard approaches, including Graph Neural Networks (GNNs), often struggle to generalize across shifting data distributions. For instance, we observe that a real-world eBay transaction dataset revealed an over 50% decline in fraud detection accuracy when adding data from only a single new day to the graph due to data distribution shifts. This highlights a critical vulnerability in purely data-driven approaches. Meanwhile, real-world domain knowledge, such as simultaneous transactions in two locations are suspicious, is more stable and a common existing component of real-world detection strategies. To explicitly integrate such knowledge into data-driven models such as GCNs, we propose KnowGraph, which integrates domain knowledge with data-driven learning for enhanced graph-based anomaly detection. KnowGraph comprises two principal components: (1) a statistical learning component that utilizes a main model for the overarching detection task, augmented by multiple specialized knowledge models that predict domain-specific semantic entities; (2) a reasoning component that employs probabilistic graphical models to execute logical inferences based on model outputs, encoding domain knowledge through weighted first-order logic formulas. In addition, KnowGraph has leveraged the Predictability-Computability-Stability (PCS) framework for veridical data science to estimate and mitigate prediction uncertainties. Empirically, KnowGraph has been rigorously evaluated on two significant real-world scenarios: collusion detection in the online marketplace eBay and intrusion detection within enterprise networks. Extensive experiments on these large-scale real-world datasets show that KnowGraph consistently outperforms state-of-the-art baselines in both transductive and inductive settings, achieving substantial gains in average precision when generalizing to completely unseen test graphs. Further ablation studies demonstrate the effectiveness of the proposed reasoning component in improving detection performance, especially under extreme class imbalance. These results highlight the potential of integrating domain knowledge into data-driven models for high-stakes, graph-based security applications.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690354",
        "pub_year": "2024",
        "theme_label": "7.1 人工智能安全"
    },
    {
        "title": "Conan: Distributed Proofs of Compliance for Anonymous Data Collection",
        "authors": "Zhou, Mingxun; Fanti, Giulia; Shi, Elaine",
        "keywords": "Anonymous Data Collection (匿名数据收集) - 匿名传输与合规验证结合\nCompliance Proof (合规证明) - 确保提交数据满足规则\nZero-Knowledge SNARKs (零知识简洁非交互证明) - 高效隐私保护验证技术\n选定的主题标签名称",
        "abstract": "We consider how to design an anonymous data collection protocol that enforces compliance rules. Imagine that each client contributes multiple data items (e.g., votes, location crumbs, or secret shares of its input) to an abstraction of an anonymous network, which mixes all clients' data items so that the receiver cannot determine which data items belong to the same user. Now, each user must prove to an auditor that the set it contributed satisfies a compliance predicate, without identifying which items it contributed. For example, the auditor may want to ensure that no voter voted for the same candidate twice, or that a user's location crumbs are not too far apart in a given time interval.Our main contribution is a novel anonymous, compliant data collection protocol that realizes the above goal. In comparison with naive approaches such as generic multi-party computation or earlier constructions of collaborative zero-knowledge proofs, the most compelling advantage of our approach is that each client's communication and computation overhead do not grow with respect to the number of clients... In this sense, we save a factor of at least.. over prior work, which allows our technique to scale to applications with a large number of clients, such as anonymous voting and privacy-preserving federated learning.We first describe our protocol using generic cryptographic primitives that can be realized from standard assumptions. We then suggest a concrete instantiation called Conan which we implement and evaluate. In this concrete instantiation, we are willing to employ SNARKs and the random oracle model for better practical efficiency. Notably, in this practical instantiation, each client's additional communication overhead (not counting the overhead of sending its data items over the anonymous network) is only (O) over tilde ( 1). We evaluated our technique in various application settings, including secure voting, and secure aggregation protocols for histogram, summation, and vector summation. Our evaluation results show that in all scenarios, each client's additional communication overhead is only 2.2KB or 2.6KB, depending on which SNARK implementation we use. Further, each client's computation only 0.2s - 0.5s for almost all cases, except for the vector summation application where the data items are high-dimensional and each client's computation is 8.5-10.6s.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690264",
        "pub_year": "2024",
        "theme_label": "2.5 密码应用技术"
    },
    {
        "title": "Shortcut: Making MPC-based Collaborative Analytics Efficient on Dynamic Databases",
        "authors": "Zhou, Peizhao; Guo, Xiaojie; Chen, Pinzhi; Li, Tong; Lv, Siyi; Liu, Zheli",
        "keywords": "Secure Multi-party Computation (安全多方计算) - 隐私保护计算技术\nDynamic Database (动态数据库) - 支持实时数据更新的数据库\nQuery Optimization (查询优化) - 提升查询效率的方法",
        "abstract": "Secure Multi-party Computation (MPC) provides a promising solution for privacy-preserving multi-source data analytics. However, existing MPC-based collaborative analytics systems (MCASs) have unsatisfying performance for scenarios with dynamic databases. Naively running an MCAS on a dynamic database would lead to significant redundant costs and raise performance concerns, due to the substantial duplicate contents between the pre-updating and post-updating databases.In this paper, we propose Shortcut, a framework that can work with MCASs to enable efficient queries on dynamic databases that support data insertion, deletion, and update. The core idea of Shortcut is to materialize previous query results and directly update them via our query result update (QRU) protocol to obtain current query results. We customize several efficient QRU protocols for common SQL operators, including Order-by-Limit, Group-by-Aggregate, Distinct, Join, Select, and Global Aggregate. These protocols are composable to implement a wide range of query functions. In particular, we propose two constant-round protocols to support data insertion and deletion. These protocols can serve as important building blocks of other protocols and are of independent interest. They address the problem of securely inserting/deleting a row into/from an ordered table while keeping the order. Our experiments show that Shortcut outperforms naive MCASs for minor updates arriving in time, which captures the need of many realistic applications (e.g., insurance services, account data management). For example, for a single query after an insertion, Shortcut achieves up to 186.8x improvement over those naive MCASs without our QRU protocols on a dynamic database with 216 similar to 220 rows, which is common in real-life applications.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690314",
        "pub_year": "2024",
        "theme_label": "6.2 安全多方计算"
    },
    {
        "title": "Untangling the Knot: Breaking Access Control in Home Wireless Mesh Networks",
        "authors": "Zhou, Xin'an; Deng, Qing; Pu, Juefei; Man, Keyu; Qian, Zhiyun; Krishnamurthy, Srikanth V.",
        "keywords": "Home Wireless Mesh Networks (家庭无线网状网络) - 网络架构与通信安全\nAccess Control Policy Synchronization (访问控制策略同步) - 安全机制与漏洞分析\nDecentralized Authentication (去中心化身份验证) - 节点协作与安全隐患",
        "abstract": "Home wireless mesh networks (WMNs) are increasingly gaining popularity for their superior extensibility and signal coverage compared to traditional single-AP wireless networks. In particular, there is a single gateway node and multiple extender nodes that cooperate to provide wireless coverage. We observe that there is no comprehensive research conducted on the security aspects of the control plane of such networks. For example, this decentralized architecture enables each extender node to independently authenticate wireless clients by synchronizing access control policies from the gateway node. However, this synchronization unexpectedly opens an attack surface which has not been scrutinized.In our research, we conduct an empirical study investigating devices and protocols of six popular home wireless mesh network vendors, focusing on the attack surface introduced by the access policy synchronization. Interestingly, we find that the exact protocols used to support such functionalities vary by vendors, despite the existence of the EasyMesh standard that vendors could opt-in. Furthermore, we find a number of serious security flaws, including but not limited to malicious clients retaining their network access indefinitely and direct compromises of gateway and extender nodes in some cases. These issues arise due to the lack of coordination across different layers of protocols that work together to support the control plane. We reported all of our findings to the affected vendors and they have acknowledged the issues and are working towards fixes (most of the vendors have released patches). Finally, we discuss trade-offs in different existing designs, suggest alternative solutions, and summarize lessons learned from the research.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670380",
        "pub_year": "2024",
        "theme_label": "网络与系统安全"
    },
    {
        "title": "Two-Tier Data Packing in RLWE-based Homomorphic Encryption for Secure Federated Learning",
        "authors": "Zhou, Yufei; Zheng, Peijia; Cao, Xiaochun; Huang, Jiwu",
        "keywords": "Homomorphic Encryption (同态加密) - 支持密文计算的加密技术\nFederated Learning (联邦学习) - 分布式隐私保护机器学习\nRing Learning with Errors (环错误学习) - 基于多项式环的密码学难题\n选定的主题标签名称",
        "abstract": "Homomorphic Encryption (HE) facilitates the preservation of privacy in federated learning (FL) aggregation. However, HE imposes significant computational and communication overhead. To address this problem, data encoding methods have been introduced that enable batch processing to improving the efficiency of ciphertext usage. The existing methods simply concatenate integer or coefficients assignment in polynomials, which do not fully make use of HE based on ring learning with errors (RLWE). We present a novel two-tier data encoding approach tailored for RLWE-based HE, effectively utilizing RLWE's polynomial structure. Our method involves a dual-level data packing strategy for batch processing at both integer and polynomial levels. At the first tier (integer level), we amalgamate those quantized model data into larger integers. Beyond existing concatenation-based encoding, we introduce a new encoding method derived from the Chinese Remainder Theorem (CRT). This CRT-based method effectively mitigates overflow and error propagation concerns. At the second tier (polynomial level), we transmute the large integers into a polynomial form. Additionally, we propose a new subring decomposition method, i.e., employing ring isomorphism mappings to project multiple large integers into varied sub-polynomial rings. Our dual-tier encoding strategy offers a more flexible and effective batch HE solution. We rigorously analyze the correctness, efficiency, and security of our approach. Our extensive experimental evaluations reveal that secure FL, empowered by our dual-tier encoding technique, markedly enhances computational and communication efficiencies over prevailing batch HE methods.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690191",
        "pub_year": "2024",
        "theme_label": "6.3 同态加密"
    },
    {
        "title": "LIFTFUZZ: Validating Binary Lifters through Context-aware Fuzzing with GPT",
        "authors": "Zhou, Yutong; Yang, Fan; Song, Zirui; Zhang, Ke; Chen, Jiongyi; Zhang, Kehuan",
        "keywords": "Binary Lifting (二进制提升) - 提升二进制代码为中间表示\nContext-aware Fuzzing (上下文感知模糊测试) - 基于指令上下文生成测试用例\nAssembly Language Model (汇编语言模型) - 利用模型学习指令交互关系",
        "abstract": "Analyzing binary code is vital for software engineering and security research, particularly when the source code is unavailable. However, understanding, modifying, and retargeting binary code can be complex tasks. To counter these difficulties, binary lifters have been introduced. These tools translate binary code into Intermediate Representations (IRs), providing several advantages, such as enabling modifications to executables without source code and facilitating code retargetability. So far, accurately developing binary lifters for modern ISAs is universally acknowledged as challenging and errorprone. Existing validation methods mainly concentrate on isolated instructions, overlooking interactions among instructions. In this paper, we introduce LIFTFUZZ, a novel framework that leverages instruction context-aware fuzzing to validate binary lifters. LIFTFUZZ harnesses an assembly language model to learn interactions among instructions and generates test cases with the knowledge. LIFTFUZZ greatly outperforms the baseline, requiring only 1/1000 of the test cases used by the baseline to identify 26 inconsistencies, including a previously uncovered category. LIFTFUZZ significantly contributes to enhancing the performance of binary lifters, which are frequently employed in binary security applications.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670276",
        "pub_year": "2024",
        "theme_label": "系统安全测评"
    },
    {
        "title": "CrossFire: Fuzzing macOS Cross-XPU Memory on Apple Silicon",
        "authors": "Zhu, Jiaxun; Lin, Minghao; Yin, Tingting; Cai, Zechao; Wang, Yu; Chang, Rui; Shen, Wenbo",
        "keywords": "CrossFire (交叉火线) - 模糊测试技术\nUnified Memory Architecture (统一内存架构) - 内存共享优化设计\nZero-day Bugs (零日漏洞) - 未公开的安全缺陷",
        "abstract": "Modern computing systems increasingly utilize XPUs, such as GPUs and NPUs, for specialized computation tasks. While these XPUs provide critical functionalities, their security protections are generally weaker than those of CPUs, making them attractive attack targets. In particular, Apple silicon optimizes memory usage by adopting a unified memory architecture (UMA), which employs shared memory regions (termed cross-XPU memory) to facilitate communication between CPUs and XPUs. Although the cross-XPU memory enhances performance, it also introduces a new attack surface. Unfortunately, the difficulty in identifying effective shared memory regions and generating valid payloads makes fuzzing cross-XPU memory a challenging problem that cannot be resolved effectively by existing fuzzing techniques.Therefore, we propose CrossFire, the first fuzzer targeting Apple silicon XPU by fuzzing cross-XPU memory, to evaluate this new attack surface. Initially, we conduct an in-depth cross-XPU memory analysis to investigate the challenges of fuzzing XPU. To address these challenges, CrossFire introduces two novel techniques to pinpoint effective fuzzing regions in cross-XPU memory and trace kernel execution information to extract data constraints. Leveraging these techniques, we develop CrossFire based on the m1n1 hypervisor to monitor cross-XPU memory accesses and perform grey-box hooking-based fuzzing. We further evaluate CrossFire on macOS Ventura, where it has identified 15 new zero-day bugs, 8 of which have been confirmed by Apple.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690376",
        "pub_year": "2024",
        "theme_label": "系统安全测评"
    },
    {
        "title": "Unveiling Collusion-Based Ad Attribution Laundering Fraud: Detection, Analysis, and Security Implications",
        "authors": "Zhu, Tong; Shou, Chaofan; Huang, Zhen; Chen, Guoxing; Zhang, Xiaokuan; Meng, Yan; Hao, Shuang; Zhu, Haojin",
        "keywords": "Ad Attribution Laundering Fraud (广告归因洗白欺诈) - 欺诈手段跨应用合谋误导广告归属\nCollusion-Based Ad Fraud (基于合谋的广告欺诈) - 多方合作实施广告欺骗行为\nDetection Framework (检测框架) - 用于识别欺诈行为的技术架构",
        "abstract": "In recent years, the growth of mobile advertising has been driven by in-app programmatic advertising and technologies like Real-Time Bidding (RTB). However, this growth has also led to an increase in ad fraud, such as click injection, background ad activity, etc. While existing studies have primarily concentrated on ad fraud within individual apps or devices, this paper introduces a new form of collusion-based ad fraud, named ad attribution laundering fraud (ALF). ALF involves multiple apps collaborating to deceive advertisers by misrepresenting the app where ads are displayed. The collusion-based approach allows lower-quality apps to exploit the reputable identities of seemingly legitimate apps. This deceives advertisers or ad networks into believing that the advertisements they place are reaching potentially valid end-users on the legitimate app. The seemingly legitimate ad events and ad attribution procedures employed by individual apps in such attacks can evade detection by existing tools.To detect ALF, we design and implement the first detection framework, AlfScan. It overcomes two challenges to extract apps' identities from diverse and obfuscated apps using both static and dynamic analysis techniques, then cross-check the identities to identify ALF. We evaluate AlfScan on a 200-app ground truth dataset, and it achieves 92% precision and 92% recall. We use AlfScan to conduct a large-scale analysis on 91, 006 apps and identify 4, 515 unique fraudulent apps and 1, 483 fraudulent clusters, exposing patterns among fraudulent developers and revealing reliability",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670314",
        "pub_year": "2024",
        "theme_label": "攻击防御"
    },
    {
        "title": "Leveraging Storage Semantics to Enhance Data Security and Privacy",
        "authors": "Zhu, Weidong",
        "keywords": "Storage Semantics (存储语义) - 存储数据含义与结构分析\nData Security (数据安全) - 保障数据免受未授权访问\nPrivacy Preservation (隐私保护) - 防止敏感信息泄露\n选定的主题标签名称",
        "abstract": "Data within a system travels through an I/O path from its generation in an application to its final storage on a device. Ensuring data security and privacy is a significant design concern, but heavily modulated storage stacks complicate understanding the data, thus presenting challenges to maintaining these properties. For example, the firmware in a storage device cannot interpret the semantics of an I/O request from the host, making it challenging to employ a semantic-aware malware defense in the storage device. Additionally, the evolution of storage media can weaken data privacy protection guarantees due to varying physical characteristics. Preserving the guarantee of data security and privacy requires understanding storage semantics, which provides insights into the data content and the architectural components within the storage system.This thesis characterizes security and privacy weaknesses in the I/O path while proposing solutions to advance data security and privacy by leveraging storage semantics. We correlate I/O requests with their semantic attributes to facilitate data security. We also demonstrate how these requests can mitigate vulnerabilities found in previous privacy-preserving storage solutions by considering the knowledge of physical storage devices. We show that data security and privacy can be vastly improved by identifying security vulnerabilities and developing new security mechanisms based on storage semantics.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3690864",
        "pub_year": "2024",
        "theme_label": "6.1 数据隐私保护"
    },
    {
        "title": "High-Throughput Three-Party DPFs with Applications to ORAM and Digital Currencies",
        "authors": "Zyskind, Guy; Yanai, Avishay; Pentland, Alex ''Sandy''",
        "keywords": "Distributed Point Functions (分布式点函数) - 用于多方安全计算的函数分发技术\nUpdatable DPF (可更新DPF) - 支持动态更新的分布式点函数扩展\nOblivious RAM (ORAM，无意识访问内存) - 实现隐私保护的数据访问机制",
        "abstract": "Distributed point functions (DPF) are increasingly becoming a foundational tool with applications for application-specific and general secure computation. While two-party DPF constructions are readily available for those applications with satisfiable performance, the three-party ones are left behind in both security and efficiency. In this paper we close this gap and propose the first three-party DPF construction that matches the state-of-the-art two-party DPF on all metrics. Namely, it is secure against a malicious adversary corrupting both the dealer and one out of the three evaluators, its function's shares are of the same size and evaluation takes the same time as in the best two-party DPF. Compared to the state-of-the-art three-party DPF, our construction enjoys 40 - 120x smaller function's share size and shorter evaluation time, for function domains of 2(16) - 2(40), respectively.Apart from DPFs as a stand-alone tool, our construction finds immediate applications to private information retrieval (PIR), writing (PIW) and oblivious RAM (ORAM). To further showcase its applicability, we design and implement an ORAM with access policy, an extension to ORAMs where a policy is being checked before accessing the underlying database. The policy we plug-in is the one suitable for account-based digital currencies, and in particular to central bank digital currencies (CBDCs). Our protocol offers the first design and implementation of a large scale privacy-preserving account-based digital currency. While previous works supported anonymity sets of 64-256 clients and less than 10 transactions per second (tps), our protocol supports anonymity sets in the millions, performing {500, 200, 58} tps for anonymity sets of {2(16), 2(18), 2(20)}, respectively.Toward that application, we introduce a new primitive called updatable DPF, which enables a direct computation of a dot product between a DPF and a vector; we believe that updatable DPF and the new dot-product protocol will find interest in other applications.",
        "doi": "https://dl.acm.org/doi/10.1145/3658644.3670292",
        "pub_year": "2024",
        "theme_label": "密码原语和范式"
    }
]